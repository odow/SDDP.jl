<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · SDDP.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SDDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">SDDP.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox"/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">Basic</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../tutorial/basic/01_first_steps/">An introduction to SDDP.jl</a></li><li><a class="tocitem" href="../tutorial/basic/03_objective_uncertainty/">Uncertainty in the objective function</a></li><li><a class="tocitem" href="../tutorial/basic/04_markov_uncertainty/">Markovian policy graphs</a></li><li><a class="tocitem" href="../tutorial/basic/05_plotting/">Plotting tools</a></li><li><a class="tocitem" href="../tutorial/basic/06_warnings/">Words of warning</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Advanced</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../tutorial/advanced/11_objective_states/">Objective states</a></li><li><a class="tocitem" href="../tutorial/advanced/12_belief_states/">Belief states</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../tutorial/theory/21_theory_intro/">Introductory theory</a></li><li><a class="tocitem" href="../tutorial/theory/22_risk/">Risk aversion</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">How-to guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../guides/acess_previous_variables/">Access variables from a previous stage</a></li><li><a class="tocitem" href="../guides/add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="tocitem" href="../guides/add_a_risk_measure/">Add a risk measure</a></li><li><a class="tocitem" href="../guides/add_integrality/">Integrality</a></li><li><a class="tocitem" href="../guides/add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="tocitem" href="../guides/add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="tocitem" href="../guides/choose_a_stopping_rule/">Choose a stopping rule</a></li><li><a class="tocitem" href="../guides/create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="tocitem" href="../guides/debug_a_model/">Debug a model</a></li><li><a class="tocitem" href="../guides/improve_computational_performance/">Improve computational performance</a></li><li><a class="tocitem" href="../guides/simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/FAST_hydro_thermal/">FAST: the hydro-thermal problem</a></li><li><a class="tocitem" href="../examples/FAST_production_management/">FAST: the production management problem</a></li><li><a class="tocitem" href="../examples/FAST_quickstart/">FAST: the quickstart problem</a></li><li><a class="tocitem" href="../examples/Hydro_thermal/">Hydro-thermal scheduling</a></li><li><a class="tocitem" href="../examples/StochDynamicProgramming.jl_multistock/">StochDynamicProgramming: the multistock problem</a></li><li><a class="tocitem" href="../examples/StochDynamicProgramming.jl_stock/">StochDynamicProgramming: the stock problem</a></li><li><a class="tocitem" href="../examples/StructDualDynProg.jl_prob5.2_2stages/">StructDualDynProg: Problem 5.2, 2 stages</a></li><li><a class="tocitem" href="../examples/StructDualDynProg.jl_prob5.2_3stages/">StructDualDynProg: Problem 5.2, 3 stages</a></li><li><a class="tocitem" href="../examples/agriculture_mccardle_farm/">The farm planning problem</a></li><li><a class="tocitem" href="../examples/air_conditioning/">Air conditioning</a></li><li><a class="tocitem" href="../examples/all_blacks/">Deterministic All Blacks</a></li><li><a class="tocitem" href="../examples/asset_management_simple/">Asset management</a></li><li><a class="tocitem" href="../examples/asset_management_stagewise/">Asset management with modifications</a></li><li><a class="tocitem" href="../examples/belief/">Partially observable inventory management</a></li><li><a class="tocitem" href="../examples/biobjective_hydro/">Biobjective hydro-thermal</a></li><li><a class="tocitem" href="../examples/booking_management/">Booking management</a></li><li><a class="tocitem" href="../examples/generation_expansion/">Generation expansion</a></li><li><a class="tocitem" href="../examples/hydro_valley/">Hydro valleys</a></li><li><a class="tocitem" href="../examples/infinite_horizon_hydro_thermal/">Infinite horizon hydro-thermal</a></li><li><a class="tocitem" href="../examples/infinite_horizon_trivial/">Infinite horizon trivial</a></li><li><a class="tocitem" href="../examples/no_strong_duality/">No strong duality</a></li><li><a class="tocitem" href="../examples/objective_state_newsvendor/">Newsvendor</a></li><li><a class="tocitem" href="../examples/sldp_example_one/">SLDP: example 1</a></li><li><a class="tocitem" href="../examples/sldp_example_two/">SLDP: example 2</a></li><li><a class="tocitem" href="../examples/stochastic_all_blacks/">Stochastic All Blacks</a></li><li><a class="tocitem" href="../examples/the_farmers_problem/">The farmer&#39;s problem</a></li><li><a class="tocitem" href="../examples/vehicle_location/">Vehicle location</a></li></ul></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Policy-graphs"><span>Policy graphs</span></a></li><li><a class="tocitem" href="#Subproblem-definition"><span>Subproblem definition</span></a></li><li><a class="tocitem" href="#Training-the-policy"><span>Training the policy</span></a></li><li><a class="tocitem" href="#Simulating-the-policy"><span>Simulating the policy</span></a></li><li><a class="tocitem" href="#Decision-rules"><span>Decision rules</span></a></li><li><a class="tocitem" href="#Visualizing-the-policy"><span>Visualizing the policy</span></a></li><li><a class="tocitem" href="#Debugging-the-model"><span>Debugging the model</span></a></li><li><a class="tocitem" href="#StochOptFormat"><span>StochOptFormat</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/apireference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="api_reference_list"><a class="docs-heading-anchor" href="#api_reference_list">API Reference</a><a id="api_reference_list-1"></a><a class="docs-heading-anchor-permalink" href="#api_reference_list" title="Permalink"></a></h1><h2 id="Policy-graphs"><a class="docs-heading-anchor" href="#Policy-graphs">Policy graphs</a><a id="Policy-graphs-1"></a><a class="docs-heading-anchor-permalink" href="#Policy-graphs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.Graph" href="#SDDP.Graph"><code>SDDP.Graph</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Graph(root_node::T) where T</code></pre><p>Create an empty graph struture with the root node <code>root_node</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L17-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_node" href="#SDDP.add_node"><code>SDDP.add_node</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_node(graph::Graph{T}, node::T) where T</code></pre><p>Add a node to the graph <code>graph</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">add_node(graph, :A)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L100-L108">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_edge" href="#SDDP.add_edge"><code>SDDP.add_edge</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_edge(graph::Graph{T}, edge::Pair{T, T}, probability::Float64) where T</code></pre><p>Add an edge to the graph <code>graph</code>.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">add_edge(graph, 1 =&gt; 2, 0.9)
add_edge(graph, :root =&gt; :A, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L120-L129">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_ambiguity_set" href="#SDDP.add_ambiguity_set"><code>SDDP.add_ambiguity_set</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_ambiguity_set(graph::Graph{T}, set::Vector{T}, lipschitz::Vector{Float64})</code></pre><p>Add <code>set</code> to the belief partition of <code>graph</code>.</p><p><code>lipschitz</code> is a vector of Lipschitz constants, with one element for each node in <code>set</code>. The Lipschitz constant is the maximum slope of the cost-to-go function with respect to the belief state associated with each node at any point in the state-space.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">graph = LinearGraph(3)
add_ambiguity_set(graph, [1, 2], [1e3, 1e2])
add_ambiguity_set(graph, [3], [1e5])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L148-L163">source</a></section><section><div><pre><code class="nohighlight hljs">add_ambiguity_set(graph::Graph{T}, set::Vector{T}, lipschitz::Float64)</code></pre><p>Add <code>set</code> to the belief partition of <code>graph</code>.</p><p><code>lipschitz</code> is a Lipschitz constant for each node in <code>set</code>. The Lipschitz constant is the maximum slope of the cost-to-go function with respect to the belief state associated with each node at any point in the state-space.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">graph = LinearGraph(3)
add_ambiguity_set(graph, [1, 2], 1e3)
add_ambiguity_set(graph, [3], 1e5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L182-L196">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.LinearGraph" href="#SDDP.LinearGraph"><code>SDDP.LinearGraph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LinearGraph(stages::Int)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L221-L223">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.MarkovianGraph" href="#SDDP.MarkovianGraph"><code>SDDP.MarkovianGraph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MarkovianGraph(transition_matrices::Vector{Matrix{Float64}})</code></pre><p>Construct a Markovian graph from the vector of transition matrices.</p><p><code>transition_matrices[t][i, j]</code> gives the probability of transitioning from Markov state <code>i</code> in stage <code>t - 1</code> to Markov state <code>j</code> in stage <code>t</code>.</p><p>The dimension of the first transition matrix should be <code>(1, N)</code>, and <code>transition_matrics[1][1, i]</code> is the probability of transitioning from the root node to the Markov state <code>i</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L232-L243">source</a></section><section><div><pre><code class="nohighlight hljs">MarkovianGraph(;
    stages::Int,
    transition_matrix::Matrix{Float64},
    root_node_transition::Vector{Float64}
)</code></pre><p>Construct a Markovian graph object with <code>stages</code> number of stages and time-independent Markov transition probabilities.</p><p><code>transition_matrix</code> must be a square matrix, and the probability of transitioning from Markov state <code>i</code> in stage <code>t</code> to Markov state <code>j</code> in stage <code>t + 1</code> is given by <code>transition_matrix[i, j]</code>.</p><p><code>root_node_transition[i]</code> is the probability of transitioning from the root node to Markov state <code>i</code> in the first stage.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L291-L307">source</a></section><section><div><pre><code class="nohighlight hljs">MarkovianGraph(
    simulator::Function; budget::Union{Int, Vector{Int}}, scenarios::Int = 1000
)</code></pre><p>Construct a Markovian graph by fitting Markov chain to scenarios generated by <code>simulator()</code>.</p><p><code>budget</code> is the total number of nodes in the resulting Markov chain. This can either be specified as a single <code>Int</code>, in which case we will attempt to intelligently distributed the nodes between stages. Alternatively, <code>budget</code> can be a <code>Vector{Int}</code>, which details the number of Markov state to have in each stage.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/modeling_aids.jl#L122-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.LinearPolicyGraph" href="#SDDP.LinearPolicyGraph"><code>SDDP.LinearPolicyGraph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LinearPolicyGraph(builder::Function; stages::Int, kwargs...)</code></pre><p>Create a linear policy graph with <code>stages</code> number of stages.</p><p>See <a href="#SDDP.PolicyGraph"><code>SDDP.PolicyGraph</code></a> for the other keyword arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L508-L514">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.MarkovianPolicyGraph" href="#SDDP.MarkovianPolicyGraph"><code>SDDP.MarkovianPolicyGraph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MarkovianPolicyGraph(
    builder::Function;
    transition_matrices::Vector{Array{Float64, 2}},
    kwargs...
)</code></pre><p>Create a Markovian policy graph based on the transition matrices given in <code>transition_matrices</code>.</p><p><code>transition_matrices[t][i, j]</code> gives the probability of transitioning from Markov state <code>i</code> in stage <code>t - 1</code> to Markov state <code>j</code> in stage <code>t</code>.</p><p>The dimension of the first transition matrix should be <code>(1, N)</code>, and <code>transition_matrics[1][1, i]</code> is the probability of transitioning from the root node to the Markov state <code>i</code>.</p><p>See <a href="#SDDP.MarkovianGraph"><code>SDDP.MarkovianGraph</code></a> for other ways of specifying a Markovian policy graph. See <a href="#SDDP.PolicyGraph"><code>SDDP.PolicyGraph</code></a> for the other keyword arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L522-L541">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.PolicyGraph" href="#SDDP.PolicyGraph"><code>SDDP.PolicyGraph</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PolicyGraph(
    builder::Function,
    graph::Graph{T};
    sense::Symbol = :Min,
    lower_bound = -Inf,
    upper_bound = Inf,
    optimizer = nothing,
    bellman_function = nothing,
    direct_mode::Bool = false,
) where {T}</code></pre><p>Construct a policy graph based on the graph structure of <code>graph</code>. (See <a href="#SDDP.Graph"><code>SDDP.Graph</code></a> for details.)</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">function builder(subproblem::JuMP.Model, index)
    # ... subproblem definition ...
end

model = PolicyGraph(
    builder,
    graph;
    lower_bound = 0.0,
    optimizer = GLPK.Optimizer,
    direct_mode = false
)</code></pre><p>Or, using the Julia <code>do ... end</code> syntax:</p><pre><code class="nohighlight hljs">model = PolicyGraph(
    graph;
    lower_bound = 0.0,
    optimizer = GLPK.Optimizer,
    direct_mode = true
) do subproblem, index
    # ... subproblem definitions ...
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L550-L589">source</a></section></article><h2 id="Subproblem-definition"><a class="docs-heading-anchor" href="#Subproblem-definition">Subproblem definition</a><a id="Subproblem-definition-1"></a><a class="docs-heading-anchor-permalink" href="#Subproblem-definition" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.@stageobjective" href="#SDDP.@stageobjective"><code>SDDP.@stageobjective</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@stageobjective(subproblem, expr)</code></pre><p>Set the stage-objective of <code>subproblem</code> to <code>expr</code>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">@stageobjective(subproblem, 2x + y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L847-L855">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.parameterize" href="#SDDP.parameterize"><code>SDDP.parameterize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">parameterize(modify::Function,
             subproblem::JuMP.Model,
             realizations::Vector{T},
             probability::Vector{Float64} = fill(1.0 / length(realizations))
                 ) where T</code></pre><p>Add a parameterization function <code>modify</code> to <code>subproblem</code>. The <code>modify</code> function takes one argument and modifies <code>subproblem</code> based on the realization of the noise sampled from <code>realizations</code> with corresponding probabilities <code>probability</code>.</p><p>In order to conduct an out-of-sample simulation, <code>modify</code> should accept arguments that are not in realizations (but still of type T).</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">SDDP.parameterize(subproblem, [1, 2, 3], [0.4, 0.3, 0.3]) do ω
    JuMP.set_upper_bound(x, ω)
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L777-L797">source</a></section><section><div><pre><code class="nohighlight hljs">parameterize(node::Node, noise)</code></pre><p>Parameterize node <code>node</code> with the noise <code>noise</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L240-L244">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_objective_state" href="#SDDP.add_objective_state"><code>SDDP.add_objective_state</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_objective_state(update::Function, subproblem::JuMP.Model; kwargs...)</code></pre><p>Add an objective state variable to <code>subproblem</code>.</p><p>Required <code>kwargs</code> are:</p><ul><li><code>initial_value</code>: The initial value of the objective state variable at the  root node.</li><li><code>lipschitz</code>: The lipschitz constant of the objective state variable.</li></ul><p>Setting a tight value for the lipschitz constant can significantly improve the speed of convergence.</p><p>Optional <code>kwargs</code> are:</p><ul><li><code>lower_bound</code>: A valid lower bound for the objective state variable. Can be  <code>-Inf</code>.</li><li><code>upper_bound</code>: A valid upper bound for the objective state variable. Can be  <code>+Inf</code>.</li></ul><p>Setting tight values for these optional variables can significantly improve the speed of convergence.</p><p>If the objective state is <code>N</code>-dimensional, each keyword argument must be an <code>NTuple{N, Float64}</code>. For example, <code>initial_value = (0.0, 1.0)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L863-L889">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.objective_state" href="#SDDP.objective_state"><code>SDDP.objective_state</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">objective_state(subproblem::JuMP.Model)</code></pre><p>Return the current objective state of the problem.</p><p>Can only be called from <a href="#SDDP.parameterize"><code>SDDP.parameterize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L957-L963">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.Noise" href="#SDDP.Noise"><code>SDDP.Noise</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Noise(support, probability)</code></pre><p>An atom of a discrete random variable at the point of support <code>support</code> and associated probability <code>probability</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/user_interface.jl#L329-L334">source</a></section></article><h2 id="Training-the-policy"><a class="docs-heading-anchor" href="#Training-the-policy">Training the policy</a><a id="Training-the-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-policy" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.numerical_stability_report" href="#SDDP.numerical_stability_report"><code>SDDP.numerical_stability_report</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">numerical_stability_report([io::IO=stdout,] model::PolicyGraph,
                           by_node::Bool=false, print=true, warn::Bool=true)</code></pre><p>Print a report identifying possible numeric stability issues.</p><ul><li>If <code>by_node</code>, print a report for each node in the graph.</li><li>If <code>print</code>, print to <code>io</code>.</li><li>If <code>warn</code>, warn if the coefficients may cause numerical issues.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/print.jl#L330-L339">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.train" href="#SDDP.train"><code>SDDP.train</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SDDP.train(model::PolicyGraph; kwargs...)</code></pre><p>Train the policy for <code>model</code>. Keyword arguments:</p><ul><li><p><code>iteration_limit::Int</code>: number of iterations to conduct before termination.</p></li><li><p><code>time_limit::Float64</code>: number of seconds to train before termination.</p></li><li><p><code>stoping_rules</code>: a vector of <a href="#SDDP.AbstractStoppingRule"><code>SDDP.AbstractStoppingRule</code></a>s.</p></li><li><p><code>print_level::Int</code>: control the level of printing to the screen. Defaults to  <code>1</code>. Set to <code>0</code> to disable all printing.</p></li><li><p><code>log_file::String</code>: filepath at which to write a log of the training progress.  Defaults to <code>SDDP.log</code>.</p></li><li><p><code>log_frequency::Int</code>: control the frequency with which the logging is  outputted (iterations/log). Defaults to <code>1</code>.</p></li><li><p><code>run_numerical_stability_report::Bool</code>: generate (and print) a numerical stability  report prior to solve. Defaults to <code>true</code>.</p></li><li><p><code>refine_at_similar_nodes::Bool</code>: if SDDP can detect that two nodes have the  same children, it can cheaply add a cut discovered at one to the other. In  almost all cases this should be set to <code>true</code>.</p></li><li><p><code>cut_deletion_minimum::Int</code>: the minimum number of cuts to cache before  deleting  cuts from the subproblem. The impact on performance is solver  specific; however, smaller values result in smaller subproblems (and therefore  quicker solves), at the expense of more time spent performing cut selection.</p></li><li><p><code>risk_measure</code>: the risk measure to use at each node. Defaults to <a href="../guides/add_a_risk_measure/#SDDP.Expectation"><code>Expectation</code></a>.</p></li><li><p><code>sampling_scheme</code>: a sampling scheme to use on the forward pass of the  algorithm. Defaults to <a href="#SDDP.InSampleMonteCarlo"><code>InSampleMonteCarlo</code></a>.</p></li><li><p><code>backward_sampling_scheme</code>: a backward pass sampling scheme to use on the  backward pass of the algorithm. Defaults to <code>CompleteSampler</code>.</p></li><li><p><code>cut_type</code>: choose between <code>SDDP.SINGLE_CUT</code> and <code>SDDP.MULTI_CUT</code> versions of SDDP.</p></li><li><p><code>dashboard::Bool</code>: open a visualization of the training over time. Defaults  to <code>false</code>.</p></li><li><p><code>parallel_scheme::AbstractParallelScheme</code>: specify a scheme for solving in parallel.  Defaults to <code>Serial()</code>.</p></li><li><p><code>forward_pass::AbstractForwardPass</code>: specify a scheme to use for the forward passes.</p></li><li><p><code>forward_pass_resampling_probability::Union{Nothing,Float64}</code>: set to a value in <code>(0, 1)</code> to enable <a href="#SDDP.RiskAdjustedForwardPass"><code>RiskAdjustedForwardPass</code></a>. Defaults to <code>nothing</code> (disabled).</p></li><li><p><code>add_to_existing_cuts::Bool</code>: set to <code>true</code> to allow training a model that was previously trained. Defaults to <code>false</code>.</p></li><li><p><code>duality_handler::AbstractDualityHandler</code>: specify a duality handler to use when creating cuts.</p></li></ul><p>There is also a special option for infinite horizon problems</p><ul><li><code>cycle_discretization_delta</code>: the maximum distance between states allowed on  the forward pass. This is for advanced users only and needs to be used in  conjunction with a different <code>sampling_scheme</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L813-L879">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.termination_status" href="#SDDP.termination_status"><code>SDDP.termination_status</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">termination_status(model::PolicyGraph)</code></pre><p>Query the reason why the training stopped.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L800-L804">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.write_cuts_to_file" href="#SDDP.write_cuts_to_file"><code>SDDP.write_cuts_to_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">write_cuts_to_file(model::PolicyGraph{T}, filename::String) where {T}</code></pre><p>Write the cuts that form the policy in <code>model</code> to <code>filename</code> in JSON format.</p><p>See also <a href="#SDDP.read_cuts_from_file"><code>SDDP.read_cuts_from_file</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/bellman_functions.jl#L544-L550">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.read_cuts_from_file" href="#SDDP.read_cuts_from_file"><code>SDDP.read_cuts_from_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_cuts_from_file(
    model::PolicyGraph{T}, filename::String;
    node_name_parser::Function = _node_name_parser) where {T}</code></pre><p>Read cuts (saved using <a href="#SDDP.write_cuts_to_file"><code>SDDP.write_cuts_to_file</code></a>) from <code>filename</code> into <code>model</code>.</p><p>Since <code>T</code> can be an arbitrary Julia type, the conversion to JSON is lossy. When reading, <code>read_cuts_from_file</code> only supports <code>T=Int</code>, <code>T=NTuple{N, Int}</code>, and <code>T=Symbol</code>. If you have manually created a policy graph with a different node type <code>T</code>, provide a function <code>node_name_parser</code> with the signature <code>node_name_parser(T, name::String)::T where {T}</code> that returns the name of each node given the string name <code>name</code>.</p><p>See also <a href="#SDDP.write_cuts_to_file"><code>SDDP.write_cuts_to_file</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/bellman_functions.jl#L615-L631">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.write_log_to_csv" href="#SDDP.write_log_to_csv"><code>SDDP.write_log_to_csv</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">write_log_to_csv(model::PolicyGraph, filename::String)</code></pre><p>Write the log of the most recent training to a csv for post-analysis.</p><p>Assumes that the model has been trained via <a href="#SDDP.train"><code>SDDP.train</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/print.jl#L390-L396">source</a></section></article><h3 id="Stopping-rules"><a class="docs-heading-anchor" href="#Stopping-rules">Stopping rules</a><a id="Stopping-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Stopping-rules" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractStoppingRule" href="#SDDP.AbstractStoppingRule"><code>SDDP.AbstractStoppingRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractStoppingRule</code></pre><p>The abstract type for the stopping-rule interface.</p><p>You need to define the following methods:</p><ul><li><a href="#SDDP.stopping_rule_status"><code>SDDP.stopping_rule_status</code></a></li><li><a href="#SDDP.convergence_test"><code>SDDP.convergence_test</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L102-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.stopping_rule_status" href="#SDDP.stopping_rule_status"><code>SDDP.stopping_rule_status</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">stopping_rule_status(::AbstractStoppingRule)::Symbol</code></pre><p>Return a symbol describing the stopping rule.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L113-L117">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.convergence_test" href="#SDDP.convergence_test"><code>SDDP.convergence_test</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">convergence_test(model::PolicyGraph, log::Vector{Log}, ::AbstractStoppingRule)::Bool</code></pre><p>Return a <code>Bool</code> indicating if the algorithm should terminate the training.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L120-L124">source</a></section></article><h3 id="Sampling-schemes"><a class="docs-heading-anchor" href="#Sampling-schemes">Sampling schemes</a><a id="Sampling-schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-schemes" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractSamplingScheme" href="#SDDP.AbstractSamplingScheme"><code>SDDP.AbstractSamplingScheme</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractSamplingScheme</code></pre><p>The abstract type for the sampling-scheme interface.</p><p>You need to define the following methods:</p><ul><li><a href="#SDDP.sample_scenario"><code>SDDP.sample_scenario</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L30-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.sample_scenario" href="#SDDP.sample_scenario"><code>SDDP.sample_scenario</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sample_scenario(graph::PolicyGraph{T}, ::AbstractSamplingScheme) where T</code></pre><p>Sample a scenario from the policy graph <code>graph</code> based on the sampling scheme.</p><p>Returns <code>::Tuple{Vector{Tuple{T, &lt;:Any}}, Bool}</code>, where the first element is the scenario, and the second element is a Boolean flag indicating if the scenario was terminated due to the detection of a cycle.</p><p>The scenario is a list of tuples (type <code>Vector{Tuple{T, &lt;:Any}}</code>) where the first component of each tuple is the index of the node, and the second component is the stagewise-independent noise term observed in that node.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L40-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.InSampleMonteCarlo" href="#SDDP.InSampleMonteCarlo"><code>SDDP.InSampleMonteCarlo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InSampleMonteCarlo(;
    max_depth::Int = 0,
    terminate_on_cycle::Function = false,
    terminate_on_dummy_leaf::Function = true,
    rollout_limit::Function = (i::Int) -&gt; typemax(Int)
)</code></pre><p>A Monte Carlo sampling scheme using the in-sample data from the policy graph definition.</p><p>If <code>terminate_on_cycle</code>, terminate the forward pass once a cycle is detected. If <code>max_depth &gt; 0</code>, return once <code>max_depth</code> nodes have been sampled. If <code>terminate_on_dummy_leaf</code>, terminate the forward pass with 1 - probability of sampling a child node.</p><p>Note that if <code>terminate_on_cycle = false</code> and <code>terminate_on_dummy_leaf = false</code> then <code>max_depth</code> must be set &gt; 0.</p><p>You can use <code>rollout_limit</code> to set iteration specific depth limits. For example:</p><pre><code class="nohighlight hljs">InSampleMonteCarlo(rollout_limit = i -&gt; 2 * i)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L15-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.OutOfSampleMonteCarlo" href="#SDDP.OutOfSampleMonteCarlo"><code>SDDP.OutOfSampleMonteCarlo</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OutOfSampleMonteCarlo(
    f::Function, graph::PolicyGraph;
    use_insample_transition::Bool = false,
    max_depth::Int = 0,
    terminate_on_cycle::Bool = false,
    terminate_on_dummy_leaf::Bool = true,
    rollout_limit::Function = i -&gt; typemax(Int),
)</code></pre><p>Create a Monte Carlo sampler using out-of-sample probabilities and/or supports for the stagewise-independent noise terms, and out-of-sample probabilities for the node-transition matrix.</p><p><code>f</code> is a function that takes the name of a node and returns a tuple containing a vector of new <a href="#SDDP.Noise"><code>SDDP.Noise</code></a> terms for the children of that node, and a vector of new <a href="#SDDP.Noise"><code>SDDP.Noise</code></a> terms for the stagewise-independent noise.</p><p>If <code>f</code> is called with the name of the root node (e.g., <code>0</code> in a linear policy graph, <code>(0, 1)</code> in a Markovian Policy Graph), then return a vector of <a href="#SDDP.Noise"><code>SDDP.Noise</code></a> for the children of the root node.</p><p>If <code>use_insample_transition</code>, the in-sample transition probabilities will be used. Therefore, <code>f</code> should only return a vector of the stagewise-independent noise terms, and <code>f</code> will not be called for the root node.</p><p>If <code>terminate_on_cycle</code>, terminate the forward pass once a cycle is detected. If <code>max_depth &gt; 0</code>, return once <code>max_depth</code> nodes have been sampled. If <code>terminate_on_dummy_leaf</code>, terminate the forward pass with 1 - probability of sampling a child node.</p><p>Note that if <code>terminate_on_cycle = false</code> and <code>terminate_on_dummy_leaf = false</code> then <code>max_depth</code> must be set &gt; 0.</p><p>You can use <code>rollout_limit</code> to set iteration specific depth limits. For example:</p><pre><code class="nohighlight hljs">OutOfSampleMonteCarlo(rollout_limit = i -&gt; 2 * i)</code></pre><p><strong>Example</strong></p><pre><code class="nohighlight hljs"># Given linear policy graph `graph` with `T` stages:
sampler = OutOfSampleMonteCarlo(graph) do node
    if node == 0
        return [SDDP.Noise(1, 1.0)]
    else
        noise_terms = [SDDP.Noise(node, 0.3), SDDP.Noise(node + 1, 0.7)]
        children = node &lt; T ? [SDDP.Noise(node + 1, 0.9)] : SDDP.Noise{Int}[]
        return children, noise_terms
    end
end

# Given linear policy graph `graph` with `T` stages:
sampler = OutOfSampleMonteCarlo(graph, use_insample_transition=true) do node
    return [SDDP.Noise(node, 0.3), SDDP.Noise(node + 1, 0.7)]
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L73-L129">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.Historical" href="#SDDP.Historical"><code>SDDP.Historical</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Historical(
    scenarios::Vector{Vector{Tuple{T,S}}},
    probability::Vector{Float64},
) where {T,S}</code></pre><p>A sampling scheme that samples a scenario from the vector of scenarios <code>scenarios</code> according to <code>probability</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">Historical(
    [
        [(1, 0.5), (2, 1.0), (3, 0.5)],
        [(1, 0.5), (2, 0.0), (3, 1.0)],
        [(1, 1.0), (2, 0.0), (3, 0.0)]
    ],
    [0.2, 0.5, 0.3],
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L307-L328">source</a></section><section><div><pre><code class="nohighlight hljs">Historical(scenarios::Vector{Vector{Tuple{T,S}}}) where {T,S}</code></pre><p>A deterministic sampling scheme that iterates through the vector of provided <code>scenarios</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">Historical([
    [(1, 0.5), (2, 1.0), (3, 0.5)],
    [(1, 0.5), (2, 0.0), (3, 1.0)],
    [(1, 1.0), (2, 0.0), (3, 0.0)],
])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L343-L358">source</a></section><section><div><pre><code class="nohighlight hljs">Historical(scenario::Vector{Tuple{T,S}}) where {T,S}</code></pre><p>A deterministic sampling scheme that always samples <code>scenario</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">Historical([(1, 0.5), (2, 1.5), (3, 0.75)])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L363-L373">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.PSRSamplingScheme" href="#SDDP.PSRSamplingScheme"><code>SDDP.PSRSamplingScheme</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PSRSamplingScheme(N::Int; sampling_scheme = InSampleMonteCarlo())</code></pre><p>A sampling scheme with <code>N</code> scenarios, similar to how PSR does it.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/sampling_schemes.jl#L393-L397">source</a></section></article><h3 id="Parallel-schemes"><a class="docs-heading-anchor" href="#Parallel-schemes">Parallel schemes</a><a id="Parallel-schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-schemes" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractParallelScheme" href="#SDDP.AbstractParallelScheme"><code>SDDP.AbstractParallelScheme</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractParallelScheme</code></pre><p>Abstract type for different parallelism schemes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L196-L200">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.Serial" href="#SDDP.Serial"><code>SDDP.Serial</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Serial()</code></pre><p>Run SDDP in serial mode.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/parallel_schemes.jl#L14-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.Asynchronous" href="#SDDP.Asynchronous"><code>SDDP.Asynchronous</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Asynchronous(init_callback::Function, slave_pids::Vector{Int} = workers())</code></pre><p>Run SDDP in asynchronous mode workers with pid&#39;s <code>slave_pids</code>.</p><p>After initializing the models on each worker, call <code>init_callback(model)</code>. Note that <code>init_callback</code> is run <em>locally on the worker</em> and <em>not</em> on the master thread.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/parallel_schemes.jl#L58-L65">source</a></section><section><div><pre><code class="nohighlight hljs">Asynchronous(slave_pids::Vector{Int} = workers())</code></pre><p>Run SDDP in asynchronous mode workers with pid&#39;s <code>slave_pids</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/parallel_schemes.jl#L74-L78">source</a></section></article><h3 id="Forward-passes"><a class="docs-heading-anchor" href="#Forward-passes">Forward passes</a><a id="Forward-passes-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-passes" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractForwardPass" href="#SDDP.AbstractForwardPass"><code>SDDP.AbstractForwardPass</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractForwardPass</code></pre><p>Abstract type for different forward passes.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L228-L232">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.DefaultForwardPass" href="#SDDP.DefaultForwardPass"><code>SDDP.DefaultForwardPass</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DefaultForwardPass()</code></pre><p>The default forward pass.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/forward_passes.jl#L6-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.RevisitingForwardPass" href="#SDDP.RevisitingForwardPass"><code>SDDP.RevisitingForwardPass</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RevisitingForwardPass(
    period::Int = 500;
    sub_pass::AbstractForwardPass = DefaultForwardPass()
)</code></pre><p>A forward pass scheme that generate <code>period</code> new forward passes (using <code>sub_pass</code>), then revisits all previously explored forward passes. This can be useful to encourage convergence at a diversity of points in the state-space.</p><p>Set <code>period = typemax(Int)</code> to disable.</p><p>For example, if <code>period = 2</code>, then the forward passes will be revisited as follows: <code>1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, ...</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/forward_passes.jl#L136-L151">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.RiskAdjustedForwardPass" href="#SDDP.RiskAdjustedForwardPass"><code>SDDP.RiskAdjustedForwardPass</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RiskAdjustedForwardPass(;
    forward_pass::AbstractForwardPass,
    risk_measure::AbstractRiskMeasure,
    resampling_probability::Float64,
    rejection_count::Int = 5,
)</code></pre><p>A forward pass that resamples a previous forward pass with <code>resampling_probability</code> probability, and otherwise samples a new forward pass using <code>forward_pass</code>.</p><p>The forward pass to revisit is chosen based on the risk-adjusted (using <code>risk_measure</code>) probability of the cumulative stage objectives.</p><p>Note that this objective corresponds to the <em>first</em> time we visited the trajectory. Subsequent visits may have improved things, but we don&#39;t have the mechanisms in-place to update it. Therefore, remove the forward pass from resampling consideration after <code>rejection_count</code> revisits.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/forward_passes.jl#L191-L210">source</a></section></article><h3 id="Risk-Measures"><a class="docs-heading-anchor" href="#Risk-Measures">Risk Measures</a><a id="Risk-Measures-1"></a><a class="docs-heading-anchor-permalink" href="#Risk-Measures" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractRiskMeasure" href="#SDDP.AbstractRiskMeasure"><code>SDDP.AbstractRiskMeasure</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractRiskMeasure</code></pre><p>The abstract type for the risk measure interface.</p><p>You need to define the following methods:</p><ul><li><a href="#SDDP.adjust_probability"><code>SDDP.adjust_probability</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L8-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.adjust_probability" href="#SDDP.adjust_probability"><code>SDDP.adjust_probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adjust_probability(measure::Expectation
                   risk_adjusted_probability::Vector{Float64},
                   original_probability::Vector{Float64},
                   noise_support::Vector{Noise{T}},
                   objective_realizations::Vector{Float64},
                   is_minimization::Bool) where T</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L18-L25">source</a></section></article><h3 id="Duality-handlers"><a class="docs-heading-anchor" href="#Duality-handlers">Duality handlers</a><a id="Duality-handlers-1"></a><a class="docs-heading-anchor-permalink" href="#Duality-handlers" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="SDDP.AbstractDualityHandler" href="#SDDP.AbstractDualityHandler"><code>SDDP.AbstractDualityHandler</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractDualityHandler</code></pre><p>The abstract type for the duality handler interface.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/headers.jl#L165-L169">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.ContinuousConicDuality" href="#SDDP.ContinuousConicDuality"><code>SDDP.ContinuousConicDuality</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ContinuousConicDuality()</code></pre><p>Compute dual variables in the backward pass using conic duality, relaxing any binary or integer restrictions as necessary.</p><p><strong>Theory</strong></p><p>Given the problem</p><pre><code class="nohighlight hljs">min Cᵢ(x̄, u, w) + θᵢ
 st (x̄, x′, u) in Xᵢ(w) ∪ S
    x̄ - x == 0          [λ]</code></pre><p>where <code>S ⊆ ℝ×ℤ</code>, we relax integrality and using conic duality to solve for <code>λ</code> in the problem:</p><pre><code class="nohighlight hljs">min Cᵢ(x̄, u, w) + θᵢ
 st (x̄, x′, u) in Xᵢ(w)
    x̄ - x == 0          [λ]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/duality_handlers.jl#L89-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.LagrangianDuality" href="#SDDP.LagrangianDuality"><code>SDDP.LagrangianDuality</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LagrangianDuality(;
    iteration_limit::Int = 100,
    atol::Float64 = 1e-8,
    rtol::Float64 = 1e-8,
    optimizer = nothing
)</code></pre><p>Obtain dual variables in the backward pass using Lagrangian duality and Kelley&#39;s cutting plane method.</p><p><strong>Arguments</strong></p><ul><li><code>iteration_limit</code> controls the maximum number of iterations</li><li><code>atol</code> and <code>rtol</code> are the absolute and relative tolerances used in the termination criteria</li><li>If <code>optimizer</code> is <code>nothing</code>, use the same solver as the main PolicyGraph. Otherwise, pass a new optimizer factory, potentially with different tolerances to ensure tighter convergence.</li></ul><p><strong>Theory</strong></p><p>Given the problem</p><pre><code class="nohighlight hljs">min Cᵢ(x̄, u, w) + θᵢ
 st (x̄, x′, u) in Xᵢ(w) ∪ S
    x̄ - x == 0          [λ]</code></pre><p>where <code>S ⊆ ℝ×ℤ</code>, we solve the problem <code>max L(λ)</code>, where:</p><pre><code class="nohighlight hljs">L(λ) = min Cᵢ(x̄, u, w) + θᵢ - λ&#39; h(x̄)
        st (x̄, x′, u) in Xᵢ(w) ∪ S</code></pre><p>and where <code>h(x̄) = x̄ - x</code>.</p><p>In the maximization case, the optimization senses are reversed, but the sign of λ stays the same.</p><p>The Lagrangian problem is computed using Kelleys cutting plane method.</p><p>We solve:</p><pre><code class="nohighlight hljs">L(λ) &lt;= max t
         st t &lt;= s * (L(λ_k) + h(x̄_k)&#39; * (λ - λ_k)) for k=1,...
            t &lt;= s * initial_bound</code></pre><p>where <code>s=1</code> for primal minimization problems and <code>s=-1</code> for primal maximization problems.</p><p>To generate a new cut we solve the cutting plane problem to generate an estimate <code>λ_k</code>. Then we solve the primal problem:</p><pre><code class="nohighlight hljs">L(λ_k) = min/max Cᵢ(x̄, u, w) + θᵢ - λ_k&#39; (x̄ - x_k)
              st (x̄, x′, u) in Xᵢ(w) ∪ S</code></pre><p>using our estimate <code>λ_k</code>.</p><p>By inspection, subgradient of <code>L(λ_k)</code> is the slack term <code>-(x̄ - x_k)</code>.</p><p>We converge once <code>L(λ_k) ≈ t</code> to the tolerance given by <code>atol</code> and <code>rtol</code>.</p><p>This gives us an optimal dual solution <code>λ_k</code>. However, since this will be used in a cut for SDDP, we can go a step further and attempt to find a dual solution that is &quot;flat&quot; by solving:</p><pre><code class="nohighlight hljs">min e
 st e &gt;= ‖λ‖
    t &lt;= s * (L(λ_k) + h(x̄_k)&#39; * (λ - λ_k)) for k=1,...
    t &lt;= s * initial_bound
    t &gt;= t_star</code></pre><p>The L1-norm is implemented as the standard abs-value reformulation:</p><pre><code class="nohighlight hljs">min Σλ⁺ + Σλ⁻
 st t &lt;= s * (L(λ_k) + h(x̄_k)&#39; * ([λ⁺ - λ⁻] - λ_k)) for k=1,...
    t &lt;= s * initial_bound
    t &gt;= t_star
    λ⁺, λ⁻ &gt;= 0</code></pre><p>If we hit the iteration limit, then we terminate because something probably went wrong.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/duality_handlers.jl#L140-L222">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.StrengthenedConicDuality" href="#SDDP.StrengthenedConicDuality"><code>SDDP.StrengthenedConicDuality</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">StrengthenedConicDuality()</code></pre><p>Obtain dual variables in the backward pass using strengthened conic duality.</p><p><strong>Theory</strong></p><p>Given the problem</p><pre><code class="nohighlight hljs">min Cᵢ(x̄, u, w) + θᵢ
 st (x̄, x′, u) in Xᵢ(w) ∪ S
    x̄ - x == 0          [λ]</code></pre><p>we first obtain an estiamte for <code>λ</code> using <a href="#SDDP.ContinuousConicDuality"><code>ContinuousConicDuality</code></a>.</p><p>Then, we evaluate the Lagrangian function:</p><pre><code class="nohighlight hljs">L(λ) = min Cᵢ(x̄, u, w) + θᵢ - λ&#39; (x̄ - x`)
        st (x̄, x′, u) in Xᵢ(w) ∪ S</code></pre><p>to obtain a better estimate of the intercept.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/duality_handlers.jl#L355-L376">source</a></section></article><h2 id="Simulating-the-policy"><a class="docs-heading-anchor" href="#Simulating-the-policy">Simulating the policy</a><a id="Simulating-the-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-the-policy" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.simulate" href="#SDDP.simulate"><code>SDDP.simulate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">simulate(
    model::PolicyGraph,
    number_replications::Int = 1,
    variables::Vector{Symbol} = Symbol[];
    sampling_scheme::AbstractSamplingScheme =
        InSampleMonteCarlo(),
    custom_recorders = Dict{Symbol, Function}(),
    duality_handler::Union{Nothing,AbstractDualityHandler} = nothing,
    skip_undefined_variables::Bool = false,
    parallel_scheme::AbstractParallelScheme = Serial(),
    incoming_state::Dict{String,Float64} = _intial_state(model),
 )::Vector{Vector{Dict{Symbol, Any}}}</code></pre><p>Perform a simulation of the policy model with <code>number_replications</code> replications using the sampling scheme <code>sampling_scheme</code>.</p><p>Use <code>incoming_state</code> to pass an initial value of the state variable, if it differs from that at the root node. Each key should be the string name of the state variable.</p><p>Returns a vector with one element for each replication. Each element is a vector with one-element for each node in the scenario that was sampled. Each element in that vector is a dictionary containing information about the subproblem that was solved.</p><p>In that dictionary there are four special keys:</p><ul><li>:node_index, which records the index of the sampled node in the policy model</li><li>:noise_term, which records the noise observed at the node</li><li>:stage_objective, which records the stage-objective of the subproblem</li><li>:bellman_term, which records the cost/value-to-go of the node.</li></ul><p>The sum of :stage<em>objective + :bellman</em>term will equal the objective value of the solved subproblem.</p><p>In addition to the special keys, the dictionary will contain the result of <code>JuMP.value(subproblem[key])</code> for each <code>key</code> in <code>variables</code>. This is useful to obtain the primal value of the state and control variables.</p><p>For more complicated data, the <code>custom_recorders</code> keyword argument can be used.</p><pre><code class="nohighlight hljs">data = Dict{Symbol, Any}()
for (key, recorder) in custom_recorders
    data[key] = foo(subproblem)
end</code></pre><p>For example, to record the dual of a constraint named <code>my_constraint</code>, pass the following:</p><pre><code class="nohighlight hljs">simulation_results = SDDP.simulate(model, 2;
    custom_recorders = Dict{Symbol, Function}(
        :constraint_dual =&gt; (sp) -&gt; JuMP.dual(sp[:my_constraint])
    )
)</code></pre><p>The value of the dual in the first stage of the second replication can be accessed as:</p><pre><code class="nohighlight hljs">simulation_results[2][1][:constraint_dual]</code></pre><p>If you do not require dual variables (or if they are not available), pass <code>duality_handler = nothing</code>.</p><p>If you attempt to simulate the value of a variable that is only defined in some of the stage problems, an error will be thrown. To over-ride this (and return a <code>NaN</code> instead), pass <code>skip_undefined_variables = true</code>.</p><p>Use <code>parallel_scheme::[AbstractParallelScheme](@ref)</code> to specify a scheme for simulating in parallel. Defaults to <a href="#SDDP.Serial"><code>Serial</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L1158-L1226">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.calculate_bound" href="#SDDP.calculate_bound"><code>SDDP.calculate_bound</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SDDP.calculate_bound(model::PolicyGraph, state::Dict{Symbol, Float64},
                       risk_measure=Expectation())</code></pre><p>Calculate the lower bound (if minimizing, otherwise upper bound) of the problem model at the point state, assuming the risk measure at the root node is risk_measure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L678-L685">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_all_cuts" href="#SDDP.add_all_cuts"><code>SDDP.add_all_cuts</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_all_cuts(model::PolicyGraph)</code></pre><p>Add all cuts that may have been deleted back into the model.</p><p><strong>Explanation</strong></p><p>During the solve, SDDP.jl may decide to remove cuts for a variety of reasons.</p><p>These can include cuts that define the optimal value function, particularly around the extremes of the state-space (e.g., reservoirs empty).</p><p>This function ensures that all cuts discovered are added back into the model.</p><p>You should call this after <a href="#SDDP.train"><code>train</code></a> and before <a href="#SDDP.simulate"><code>simulate</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/plugins/bellman_functions.jl#L706-L721">source</a></section></article><h2 id="Decision-rules"><a class="docs-heading-anchor" href="#Decision-rules">Decision rules</a><a id="Decision-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-rules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.DecisionRule" href="#SDDP.DecisionRule"><code>SDDP.DecisionRule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DecisionRule(model::PolicyGraph{T}; node::T)</code></pre><p>Create a decision rule for node <code>node</code> in <code>model</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L1251-L1255">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.evaluate" href="#SDDP.evaluate"><code>SDDP.evaluate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">evaluate(
    rule::DecisionRule;
    incoming_state::Dict{Symbol, Float64},
    noise = nothing,
    controls_to_record = Symbol[],
)</code></pre><p>Evalute the decision rule <code>rule</code> at the point described by the <code>incoming_state</code> and <code>noise</code>.</p><p>If the node is deterministic, omit the <code>noise</code> argument.</p><p>Pass a list of symbols to <code>controls_to_record</code> to save the optimal primal solution corresponding to the names registered in the model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L1269-L1284">source</a></section><section><div><pre><code class="language-julia hljs">evaluate(
    V::ValueFunction,
    point::Dict{Union{Symbol,String},&lt;:Real}
    objective_state = nothing,
    belief_state = nothing
)</code></pre><p>Evaluate the value function <code>V</code> at <code>point</code> in the state-space.</p><p>Returns a tuple containing the height of the function, and the subgradient w.r.t. the convex state-variables.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">evaluate(V, Dict(:volume =&gt; 1.0))</code></pre><p>If the state variable is constructed like <code>@variable(sp, volume[1:4] &gt;= 0, SDDP.State, initial_value = 0.0)</code>, use <code>[i]</code> to index the state variable:</p><pre><code class="language-julia hljs">evaluate(V, Dict(Symbol(&quot;volume[1]&quot;) =&gt; 1.0))</code></pre><p>You can also use strings or symbols for the keys.</p><pre><code class="language-julia hljs">evaluate(V, Dict(&quot;volume[1]&quot; =&gt; 1))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/value_functions.jl#L183-L213">source</a></section><section><div><pre><code class="nohighlight hljs">evalute(V::ValueFunction{Nothing, Nothing}; kwargs...)</code></pre><p>Evalute the value function <code>V</code> at the point in the state-space specified by <code>kwargs</code>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">evaluate(V; volume = 1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/value_functions.jl#L256-L265">source</a></section><section><div><pre><code class="language-julia hljs">evaluate(
    model::PolicyGraph{T}, test_scenarios::TestScenarios{T, S}
) where {T, S}</code></pre><p>Evaluate the performance of the policy contained in <code>model</code> after a call to <a href="#SDDP.train"><code>train</code></a> on the scenarios specified by <code>test_scenarios</code>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">model, test_scenarios = read_from_file(&quot;my_model.sof.json&quot;)
train(model; iteration_limit = 100)
simulations = evaluate(model, test_scenarios)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L874-L887">source</a></section></article><h2 id="Visualizing-the-policy"><a class="docs-heading-anchor" href="#Visualizing-the-policy">Visualizing the policy</a><a id="Visualizing-the-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-policy" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.SpaghettiPlot" href="#SDDP.SpaghettiPlot"><code>SDDP.SpaghettiPlot</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SDDP.SpaghettiPlot(; stages, scenarios)</code></pre><p>Initialize a new <code>SpaghettiPlot</code> with <code>stages</code> stages and <code>scenarios</code> number of replications.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/spaghetti_plot.jl#L21-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.add_spaghetti" href="#SDDP.add_spaghetti"><code>SDDP.add_spaghetti</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SDDP.add_spaghetti(data_function::Function, plt::SpaghettiPlot; kwargs...)</code></pre><p><strong>Description</strong></p><p>Add a new figure to the SpaghettiPlot <code>plt</code>, where the y-value of the <code>scenario</code>th line when x = <code>stage</code> is given by <code>data_function(plt.simulations[scenario][stage])</code>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>xlabel</code>: set the xaxis label</li><li><code>ylabel</code>: set the yaxis label</li><li><code>title</code>: set the title of the plot</li><li><code>ymin</code>: set the minimum y value</li><li><code>ymax</code>: set the maximum y value</li><li><code>cumulative</code>: plot the additive accumulation of the value across the stages</li><li><code>interpolate</code>: interpolation method for lines between stages.</li></ul><p>Defaults to <code>&quot;linear&quot;</code> see <a href="https://github.com/d3/d3-3.x-api-reference/blob/master/SVG-Shapes.md#line_interpolate">the d3 docs</a> 	for all options.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">simulations = simulate(model, 10)
plt = SDDP.spaghetti_plot(simulations)
SDDP.add_spaghetti(plt; title = &quot;Stage objective&quot;) do data
	return data[:stage_objective]
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/spaghetti_plot.jl#L49-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.publication_plot" href="#SDDP.publication_plot"><code>SDDP.publication_plot</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SDDP.publication_plot(
    data_function, simulations;
    quantile = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0],
    kwargs...)</code></pre><p>Create a <code>Plots.jl</code> recipe plot of the simulations.</p><p>See <code>Plots.jl</code> for the list of keyword arguments.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">SDDP.publication_plot(simulations; title = &quot;My title&quot;) do data
    return data[:stage_objective]
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/publication_plot.jl#L22-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.ValueFunction" href="#SDDP.ValueFunction"><code>SDDP.ValueFunction</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ValueFunction</code></pre><p>A representation of the value function. SDDP.jl uses the following unique representation of the value function that is undocumented in the literature.</p><p>It supports three types of state variables:</p><ol><li>x - convex &quot;resource&quot; states</li><li>b - concave &quot;belief&quot; states</li><li>y - concave &quot;objective&quot; states</li></ol><p>In addition, we have three types of cuts:</p><ol><li>Single-cuts (also called &quot;average&quot; cuts in the literature), which involve the risk-adjusted expectation of the cost-to-go.</li><li>Multi-cuts, which use a different cost-to-go term for each realization w.</li><li>Risk-cuts, which correspond to the facets of the dual interpretation of a coherent risk measure.</li></ol><p>Therefore, ValueFunction returns a JuMP model of the following form:</p><pre><code class="nohighlight hljs">V(x, b, y) = min: μᵀb + νᵀy + θ
             s.t. # &quot;Single&quot; / &quot;Average&quot; cuts
                  μᵀb(j) + νᵀy(j) + θ &gt;= α(j) + xᵀβ(j), ∀ j ∈ J
                  # &quot;Multi&quot; cuts
                  μᵀb(k) + νᵀy(k) + φ(w) &gt;= α(k, w) + xᵀβ(k, w), ∀w ∈ Ω, k ∈ K
                  # &quot;Risk-set&quot; cuts
                  θ ≥ Σ{p(k, w) * φ(w)}_w - μᵀb(k) - νᵀy(k), ∀ k ∈ K</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/value_functions.jl#L6-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.evaluate-Tuple{SDDP.ValueFunction, Dict{Symbol, Float64}}" href="#SDDP.evaluate-Tuple{SDDP.ValueFunction, Dict{Symbol, Float64}}"><code>SDDP.evaluate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">evaluate(
    V::ValueFunction,
    point::Dict{Union{Symbol,String},&lt;:Real}
    objective_state = nothing,
    belief_state = nothing
)</code></pre><p>Evaluate the value function <code>V</code> at <code>point</code> in the state-space.</p><p>Returns a tuple containing the height of the function, and the subgradient w.r.t. the convex state-variables.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">evaluate(V, Dict(:volume =&gt; 1.0))</code></pre><p>If the state variable is constructed like <code>@variable(sp, volume[1:4] &gt;= 0, SDDP.State, initial_value = 0.0)</code>, use <code>[i]</code> to index the state variable:</p><pre><code class="language-julia hljs">evaluate(V, Dict(Symbol(&quot;volume[1]&quot;) =&gt; 1.0))</code></pre><p>You can also use strings or symbols for the keys.</p><pre><code class="language-julia hljs">evaluate(V, Dict(&quot;volume[1]&quot; =&gt; 1))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/value_functions.jl#L183-L213">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.plot" href="#SDDP.plot"><code>SDDP.plot</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">plot(plt::SpaghettiPlot[, filename::String]; open::Bool = true)</code></pre><p>The SpaghettiPlot plot <code>plt</code> to <code>filename</code>. If <code>filename</code> is not given, it will be saved to a temporary directory. If <code>open = true</code>, then a browser window will be opened to display the resulting HTML file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/visualization/spaghetti_plot.jl#L133-L139">source</a></section></article><h2 id="Debugging-the-model"><a class="docs-heading-anchor" href="#Debugging-the-model">Debugging the model</a><a id="Debugging-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Debugging-the-model" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.write_subproblem_to_file" href="#SDDP.write_subproblem_to_file"><code>SDDP.write_subproblem_to_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">write_subproblem_to_file(node::Node, filename::String; throw_error::Bool = false)</code></pre><p>Write the subproblem contained in <code>node</code> to the file <code>filename</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/algorithm.jl#L214-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.deterministic_equivalent" href="#SDDP.deterministic_equivalent"><code>SDDP.deterministic_equivalent</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">deterministic_equivalent(
    pg::PolicyGraph{T},
    optimizer = nothing;
    time_limit::Union{Real, Nothing} = 60.0
)</code></pre><p>Form a JuMP model that represents the deterministic equivalent of the problem.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">deterministic_equivalent(model)
deterministic_equivalent(model, GLPK.Optimizer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/deterministic_equivalent.jl#L178-L191">source</a></section></article><h2 id="StochOptFormat"><a class="docs-heading-anchor" href="#StochOptFormat">StochOptFormat</a><a id="StochOptFormat-1"></a><a class="docs-heading-anchor-permalink" href="#StochOptFormat" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SDDP.write_to_file" href="#SDDP.write_to_file"><code>SDDP.write_to_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">write_to_file(
    model::PolicyGraph,
    filename::String;
    compression::MOI.FileFormats.AbstractCompressionScheme =
        MOI.FileFormats.AutomaticCompression(),
    kwargs...
)</code></pre><p>Write <code>model</code> to <code>filename</code> in the StochOptFormat file format.</p><p>Pass an argument to <code>compression</code> to override the default of automatically detecting the file compression to use based on the extension of <code>filename</code>.</p><p>See <a href="#Base.write-Tuple{IO, SDDP.PolicyGraph}"><code>Base.write(::IO, ::PolicyGraph)</code></a> for information on the keyword arguments that can be provided.</p><p>WARNING: THIS FUNCTION IS EXPERIMENTAL. SEE THE FULL WARNING IN <a href="#Base.write-Tuple{IO, SDDP.PolicyGraph}"><code>Base.write(::IO, ::PolicyGraph)</code></a>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">write_to_file(model, &quot;my_model.sof.json&quot;; test_scenarios = 10)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L805-L828">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.read_from_file" href="#SDDP.read_from_file"><code>SDDP.read_from_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_from_file(
    filename::String;
    compression::MOI.FileFormats.AbstractCompressionScheme =
        MOI.FileFormats.AutomaticCompression(),
    kwargs...
)::Tuple{PolicyGraph, TestScenarios}</code></pre><p>Return a tuple containing a <a href="#SDDP.PolicyGraph"><code>PolicyGraph</code></a> object and a <a href="#SDDP.TestScenarios"><code>TestScenarios</code></a> read from <code>filename</code> in the StochOptFormat file format.</p><p>Pass an argument to <code>compression</code> to override the default of automatically detecting the file compression to use based on the extension of <code>filename</code>.</p><p>See <a href="#Base.read-Tuple{IO, Type{SDDP.PolicyGraph}}"><code>Base.read(::IO, ::Type{PolicyGraph})</code></a> for information on the keyword arguments that can be provided.</p><p>WARNING: THIS FUNCTION IS EXPERIMENTAL. SEE THE FULL WARNING IN <a href="#Base.read-Tuple{IO, Type{SDDP.PolicyGraph}}"><code>Base.read(::IO, ::Type{PolicyGraph})</code></a>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">model, test_scenarios = read_from_file(&quot;my_model.sof.json&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L840-L863">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.write-Tuple{IO, SDDP.PolicyGraph}" href="#Base.write-Tuple{IO, SDDP.PolicyGraph}"><code>Base.write</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Base.write(
    io::IO,
    model::PolicyGraph;
    test_scenarios::Union{Int, TestScenarios} = 1_000,
    kwargs...
)</code></pre><p>Write <code>model</code> to <code>io</code> in the StochOptFormat file format.</p><p>Pass an <code>Int</code> to <code>test_scenarios</code> (default <code>1_000</code>) to specify the number of test scenarios to generate using the <a href="#SDDP.InSampleMonteCarlo"><code>InSampleMonteCarlo</code></a> sampling scheme. Alternatively, pass a <a href="#SDDP.TestScenarios"><code>TestScenarios</code></a> object to manually specify the test scenarios to use.</p><p>Any additional <code>kwargs</code> passed to <code>write</code> will be stored in the top-level of the resulting StochOptFormat file. Valid arguments include <code>name</code>, <code>author</code>, <code>date</code>, and <code>description</code>.</p><p>WARNING: THIS FUNCTION IS EXPERIMENTAL. THINGS MAY CHANGE BETWEEN COMMITS. YOU SHOULD NOT RELY ON THIS FUNCTIONALITY AS A LONG-TERM FILE FORMAT (YET).</p><p>In addition to potential changes to the underlying format, only a subset of possible modifications are supported. These include:</p><ul><li><code>JuMP.fix</code></li><li><code>JuMP.set_lower_bound</code></li><li><code>JuMP.set_upper_bound</code></li><li><code>JuMP.set_normalized_rhs</code></li><li>Changes to the constant or affine terms in a stage objective</li></ul><p>If your model uses something other than this, this function will silently write an incorrect formulation of the problem.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">open(&quot;my_model.sof.json&quot;, &quot;w&quot;) do io
    write(
        io,
        model;
        test_scenarios = 10,
        name = &quot;MyModel&quot;,
        author = &quot;@odow&quot;,
        date = &quot;2020-07-20&quot;,
        description = &quot;Example problem for the SDDP.jl documentation&quot;,
    )
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L109-L155">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.read-Tuple{IO, Type{SDDP.PolicyGraph}}" href="#Base.read-Tuple{IO, Type{SDDP.PolicyGraph}}"><code>Base.read</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Base.read(
    io::IO,
    ::Type{PolicyGraph};
    bound::Float64 = 1e6,
)::Tuple{PolicyGraph, TestScenarios}</code></pre><p>Return a tuple containing a <a href="#SDDP.PolicyGraph"><code>PolicyGraph</code></a> object and a <a href="#SDDP.TestScenarios"><code>TestScenarios</code></a> read from <code>io</code> in the StochOptFormat file format.</p><p>See also: <a href="#SDDP.evaluate"><code>evaluate</code></a>.</p><p>WARNING: THIS FUNCTION IS EXPERIMENTAL. THINGS MAY CHANGE BETWEEN COMMITS. YOU SHOULD NOT RELY ON THIS FUNCTIONALITY AS A LONG-TERM FILE FORMAT (YET).</p><p>In addition to potential changes to the underlying format, only a subset of possible modifications are supported. These include:</p><ul><li>Additive random variables in the constraints or in the objective</li><li>Multiplicative random variables in the objective</li></ul><p>If your model uses something other than this, this function may throw an error or silently build a non-convex model.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">open(&quot;my_model.sof.json&quot;, &quot;r&quot;) do io
    model, test_scenarios = read(io, PolicyGraph)
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L646-L674">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.evaluate-Union{Tuple{T}, Tuple{SDDP.PolicyGraph{T}, SDDP.TestScenarios{T, S} where S}} where T" href="#SDDP.evaluate-Union{Tuple{T}, Tuple{SDDP.PolicyGraph{T}, SDDP.TestScenarios{T, S} where S}} where T"><code>SDDP.evaluate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">evaluate(
    model::PolicyGraph{T}, test_scenarios::TestScenarios{T, S}
) where {T, S}</code></pre><p>Evaluate the performance of the policy contained in <code>model</code> after a call to <a href="#SDDP.train"><code>train</code></a> on the scenarios specified by <code>test_scenarios</code>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">model, test_scenarios = read_from_file(&quot;my_model.sof.json&quot;)
train(model; iteration_limit = 100)
simulations = evaluate(model, test_scenarios)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L874-L887">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.TestScenarios" href="#SDDP.TestScenarios"><code>SDDP.TestScenarios</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TestScenarios{T, S}(scenarios::Vector{TestScenario{T, S}})</code></pre><p>An <a href="#SDDP.AbstractSamplingScheme"><code>AbstractSamplingScheme</code></a> based on a vector of scenarios.</p><p>Each scenario is a vector of <code>Tuple{T, S}</code> where the first element is the node to visit and the second element is the realization of the stagewise-independent noise term. Pass <code>nothing</code> if the node is deterministic.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L20-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SDDP.TestScenario" href="#SDDP.TestScenario"><code>SDDP.TestScenario</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TestScenario{T, S}(probability::Float64, scenario::Vector{Tuple{T, S}})</code></pre><p>A single scenario for testing.</p><p>See also: <a href="#SDDP.TestScenarios"><code>TestScenarios</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/odow/SDDP.jl/blob/39fc9bf1d3e56f683e610d01cdd50350a13992d8/src/Experimental.jl#L8-L14">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/vehicle_location/">« Vehicle location</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Sunday 22 August 2021 23:54">Sunday 22 August 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
