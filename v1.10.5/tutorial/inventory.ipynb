{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example: inventory management"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this tutorial is to demonstrate a well-known inventory\n",
    "management problem with a finite- and infinite-horizon policy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Required packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial requires the following packages:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP\n",
    "import Distributions\n",
    "import HiGHS\n",
    "import Plots\n",
    "import Statistics"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Consider a periodic review inventory problem involving a single product. The\n",
    "initial inventory is denoted by $x_0 \\geq 0$, and a decision-maker can place\n",
    "an order at the start of each stage. The objective is to minimize expected\n",
    "costs over the planning horizon. The following parameters define the cost\n",
    "structure:\n",
    "\n",
    " * `c` is the unit cost for purchasing each unit\n",
    " * `h` is the holding cost per unit remaining at the end of each stage\n",
    " * `p` is the shortage cost per unit of unsatisfied demand at the end of each\n",
    "   stage\n",
    "\n",
    "There are no fixed ordering costs, and the demand at each stage is assumed to\n",
    "follow an independent and identically distributed random variable with\n",
    "cumulative distribution function (CDF) $\\Phi(\\cdot)$. Any unsatisfied demand\n",
    "is backlogged and carried forward to the next stage."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "At each stage, an agent must decide how many items to order. The per-stage\n",
    "costs are the sum of the order costs, shortage and holding costs incurred at\n",
    "the end of the stage, after demand is realized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following Chapter 19 of Introduction to Operations Research by Hillier and\n",
    "Lieberman (7th edition), we use the following parameters: $c=15, h=1, p=15$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x_0 = 10        # initial inventory\n",
    "c = 35          # unit inventory cost\n",
    "h = 1           # unit inventory holding cost\n",
    "p = 15          # unit order cost"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Demand follows a continuous uniform distribution between 0 and 800. We\n",
    "construct a sample average approximation with 20 scenarios:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Ω = range(0, 800; length = 20);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a well-known inventory problem with a closed-form solution. The\n",
    "optimal policy is a simple order-up-to policy: if the inventory level is\n",
    "below a certain number of units, the decision-maker orders up to that number\n",
    "of units. Otherwise, no order is placed. For a detailed analysis, refer\n",
    "to Foundations of Stochastic Inventory Theory by Evan Porteus (Stanford\n",
    "Business Books, 2002)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finite horizon"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a finite horizon of length $T$,  the problem is to minimize the total\n",
    "expected cost over all stages."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the last stage, the decision-maker can recover the unit cost `c` for each\n",
    "leftover item, or buy out any remaining backlog, also at the unit cost `c`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "T = 10 # number of stages\n",
    "model = SDDP.LinearPolicyGraph(;\n",
    "    stages = T + 1,\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do sp, t\n",
    "    @variable(sp, x_inventory >= 0, SDDP.State, initial_value = x_0)\n",
    "    @variable(sp, x_demand >= 0, SDDP.State, initial_value = 0)\n",
    "    # u_buy is a Decision-Hazard control variable. We decide u.out for use in\n",
    "    # the next stage\n",
    "    @variable(sp, u_buy >= 0, SDDP.State, initial_value = 0)\n",
    "    @variable(sp, u_sell >= 0)\n",
    "    @variable(sp, w_demand == 0)\n",
    "    @constraint(sp, x_inventory.out == x_inventory.in + u_buy.in - u_sell)\n",
    "    @constraint(sp, x_demand.out == x_demand.in + w_demand - u_sell)\n",
    "    if t == 1\n",
    "        fix(u_sell, 0; force = true)\n",
    "        @stageobjective(sp, c * u_buy.out)\n",
    "    elseif t == T + 1\n",
    "        fix(u_buy.out, 0; force = true)\n",
    "        @stageobjective(sp, -c * x_inventory.out + c * x_demand.out)\n",
    "        SDDP.parameterize(ω -> JuMP.fix(w_demand, ω), sp, Ω)\n",
    "    else\n",
    "        @stageobjective(sp, c * u_buy.out + h * x_inventory.out + p * x_demand.out)\n",
    "        SDDP.parameterize(ω -> JuMP.fix(w_demand, ω), sp, Ω)\n",
    "    end\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and simulate the policy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "SDDP.train(model)\n",
    "simulations = SDDP.simulate(model, 200, [:x_inventory, :u_buy])\n",
    "objective_values = [sum(t[:stage_objective] for t in s) for s in simulations]\n",
    "μ, ci = round.(SDDP.confidence_interval(objective_values, 1.96); digits = 2)\n",
    "lower_bound = round(SDDP.calculate_bound(model); digits = 2)\n",
    "println(\"Confidence interval: \", μ, \" ± \", ci)\n",
    "println(\"Lower bound: \", lower_bound)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the optimal inventory levels:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = SDDP.publication_plot(\n",
    "    simulations;\n",
    "    title = \"x_inventory.out + u_buy.out\",\n",
    "    xlabel = \"Stage\",\n",
    "    ylabel = \"Quantity\",\n",
    "    ylims = (0, 1_000),\n",
    ") do data\n",
    "    return data[:x_inventory].out + data[:u_buy].out\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the early stages, we indeed recover an order-up-to policy. However,\n",
    "there are end-of-horizon effects as the agent tries to optimize their\n",
    "decision making knowing that they have 10 realizations of demand."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Infinite horizon"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can remove the end-of-horizonn effects by considering an infinite\n",
    "horizon model. We assume a discount factor $\\alpha=0.95$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "α = 0.95\n",
    "graph = SDDP.LinearGraph(2)\n",
    "SDDP.add_edge(graph, 2 => 2, α)\n",
    "graph"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The objective in this case is to minimize the discounted expected costs over\n",
    "an infinite planning horizon."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.PolicyGraph(\n",
    "    graph;\n",
    "    sense = :Min,\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do sp, t\n",
    "    @variable(sp, x_inventory >= 0, SDDP.State, initial_value = x_0)\n",
    "    @variable(sp, x_demand >= 0, SDDP.State, initial_value = 0)\n",
    "    # u_buy is a Decision-Hazard control variable. We decide u.out for use in\n",
    "    # the next stage\n",
    "    @variable(sp, u_buy >= 0, SDDP.State, initial_value = 0)\n",
    "    @variable(sp, u_sell >= 0)\n",
    "    @variable(sp, w_demand == 0)\n",
    "    @constraint(sp, x_inventory.out == x_inventory.in + u_buy.in - u_sell)\n",
    "    @constraint(sp, x_demand.out == x_demand.in + w_demand - u_sell)\n",
    "    if t == 1\n",
    "        fix(u_sell, 0; force = true)\n",
    "        @stageobjective(sp, c * u_buy.out)\n",
    "    else\n",
    "        @stageobjective(sp, c * u_buy.out + h * x_inventory.out + p * x_demand.out)\n",
    "        SDDP.parameterize(ω -> JuMP.fix(w_demand, ω), sp, Ω)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "SDDP.train(model; iteration_limit = 400)\n",
    "simulations = SDDP.simulate(\n",
    "    model,\n",
    "    200,\n",
    "    [:x_inventory, :u_buy];\n",
    "    sampling_scheme = SDDP.InSampleMonteCarlo(;\n",
    "        max_depth = 50,\n",
    "        terminate_on_dummy_leaf = false,\n",
    "    ),\n",
    ");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the optimal inventory levels:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = SDDP.publication_plot(\n",
    "    simulations;\n",
    "    title = \"x_inventory.out + u_buy.out\",\n",
    "    xlabel = \"Stage\",\n",
    "    ylabel = \"Quantity\",\n",
    "    ylims = (0, 1_000),\n",
    ") do data\n",
    "    return data[:x_inventory].out + data[:u_buy].out\n",
    "end\n",
    "Plots.hline!(plt, [662]; label = \"Analytic solution\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We again recover an order-up-to policy. The analytic solution is to\n",
    "order-up-to 662 units. We do not precisely recover this solution because\n",
    "we used a sample average approximation of 20 elements. If we increased the\n",
    "number of samples, our solution would approach the analytic solution."
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
