{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example: two-stage newsvendor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this tutorial is to demonstrate how to model and solve a\n",
    "two-stage stochastic program."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is based on the [Two stage stochastic programs](https://jump.dev/JuMP.jl/dev/tutorials/applications/two_stage_stochastic/)\n",
    "tutorial in JuMP."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial uses the following packages"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JuMP\n",
    "using SDDP\n",
    "import Distributions\n",
    "import ForwardDiff\n",
    "import HiGHS\n",
    "import Plots\n",
    "import StatsPlots\n",
    "import Statistics"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data for this problem is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "D = Distributions.TriangularDist(150.0, 250.0, 200.0)\n",
    "N = 100\n",
    "d = sort!(rand(D, N));\n",
    "Ω = 1:N\n",
    "P = fill(1 / N, N);\n",
    "StatsPlots.histogram(d; bins = 20, label = \"\", xlabel = \"Demand\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kelley's cutting plane algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kelley's cutting plane algorithm is an iterative method for maximizing concave\n",
    "functions. Given a concave function $f(x)$, Kelley's constructs an\n",
    "outer-approximation of the function at the minimum by a set of first-order\n",
    "Taylor series approximations (called **cuts**) constructed at a set of points\n",
    "$k = 1,\\ldots,K$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f^K = \\max\\limits_{\\theta \\in \\mathbb{R}, x \\in \\mathbb{R}^N} \\;\\; & \\theta\\\\\n",
    "& \\theta \\le f(x_k) + \\nabla f(x_k)^\\top (x - x_k),\\quad k=1,\\ldots,K\\\\\n",
    "& \\theta \\le M,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $M$ is a sufficiently large number that is an upper bound for $f$ over\n",
    "the domain of $x$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kelley's cutting plane algorithm is a structured way of choosing points $x_k$\n",
    "to visit, so that as more cuts are added:\n",
    "$$\n",
    "\\lim_{K \\rightarrow \\infty} f^K = \\max\\limits_{x \\in \\mathbb{R}^N} f(x)\n",
    "$$\n",
    "However, before we introduce the algorithm, we need to introduce some bounds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By convexity, $f(x) \\le f^K$ for all $x$. Thus, if $x^*$ is a maximizer of\n",
    "$f$, then at any point in time we can construct an upper bound for $f(x^*)$ by\n",
    "solving $f^K$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moreover, we can use the primal solutions $x_k^*$ returned by solving $f^k$ to\n",
    "evaluate $f(x_k^*)$ to generate a lower bound."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Therefore, $\\max\\limits_{k=1,\\ldots,K} f(x_k^*) \\le f(x^*) \\le f^K$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the lower bound is sufficiently close to the upper bound, we can\n",
    "terminate the algorithm and declare that we have found an solution that is\n",
    "close to optimal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is pseudo-code fo the Kelley algorithm:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Take as input a convex function $f(x)$ and a iteration limit $K_{max}$.\n",
    "   Set $K = 1$, and initialize $f^{K-1}$. Set $lb = -\\infty$ and $ub = \\infty$.\n",
    "2. Solve $f^{K-1}$ to obtain a candidate solution $x_{K}$.\n",
    "3. Update $ub = f^{K-1}$ and $lb = \\max\\{lb, f(x_{K})\\}$.\n",
    "4. Add a cut $\\theta \\ge f(x_{K}) + \\nabla f\\left(x_{K}\\right)^\\top (x - x_{K})$ to form $f^{K}$.\n",
    "5. Increment $K$.\n",
    "6. If $K > K_{max}$ or $|ub - lb| < \\epsilon$, STOP, otherwise, go to step 2."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here's a complete implementation:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function kelleys_cutting_plane(\n",
    "    # The function to be minimized.\n",
    "    f::Function,\n",
    "    # The gradient of `f`. By default, we use automatic differentiation to\n",
    "    # compute the gradient of f so the user doesn't have to!\n",
    "    ∇f::Function = x -> ForwardDiff.gradient(f, x);\n",
    "    # The number of arguments to `f`.\n",
    "    input_dimension::Int,\n",
    "    # An upper bound for the function `f` over its domain.\n",
    "    upper_bound::Float64,\n",
    "    # The number of iterations to run Kelley's algorithm for before stopping.\n",
    "    iteration_limit::Int,\n",
    "    # The absolute tolerance ϵ to use for convergence.\n",
    "    tolerance::Float64 = 1e-6,\n",
    ")\n",
    "    # Step (1):\n",
    "    K = 1\n",
    "    model = JuMP.Model(HiGHS.Optimizer)\n",
    "    JuMP.set_silent(model)\n",
    "    JuMP.@variable(model, θ <= upper_bound)\n",
    "    JuMP.@variable(model, x[1:input_dimension])\n",
    "    JuMP.@objective(model, Max, θ)\n",
    "    x_k = fill(NaN, input_dimension)\n",
    "    lower_bound, upper_bound = -Inf, Inf\n",
    "    while true\n",
    "        # Step (2):\n",
    "        JuMP.optimize!(model)\n",
    "        x_k .= JuMP.value.(x)\n",
    "        # Step (3):\n",
    "        upper_bound = JuMP.objective_value(model)\n",
    "        lower_bound = min(upper_bound, f(x_k))\n",
    "        println(\"K = $K : $(lower_bound) <= f(x*) <= $(upper_bound)\")\n",
    "        # Step (4):\n",
    "        JuMP.@constraint(model, θ <= f(x_k) + ∇f(x_k)' * (x .- x_k))\n",
    "        # Step (5):\n",
    "        K = K + 1\n",
    "        # Step (6):\n",
    "        if K > iteration_limit\n",
    "            println(\"-- Termination status: iteration limit --\")\n",
    "            break\n",
    "        elseif abs(upper_bound - lower_bound) < tolerance\n",
    "            println(\"-- Termination status: converged --\")\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    println(\"Found solution: x_K = \", x_k)\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's run our algorithm to see what happens:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "kelleys_cutting_plane(;\n",
    "    input_dimension = 2,\n",
    "    upper_bound = 10.0,\n",
    "    iteration_limit = 20,\n",
    ") do x\n",
    "    return -(x[1] - 1)^2 + -(x[2] + 2)^2 + 1.0\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L-Shaped theory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The L-Shaped method is a way of solving two-stage stochastic programs by\n",
    "Benders' decomposition. It takes the problem:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "V = \\max\\limits_{x,y_\\omega} \\;\\; & -2x + \\mathbb{E}_\\omega[5y_\\omega - 0.1(x - y_\\omega)] \\\\\n",
    "  & y_\\omega \\le x              & \\quad \\forall \\omega \\in \\Omega \\\\\n",
    "  & 0 \\le y_\\omega \\le d_\\omega & \\quad \\forall \\omega \\in \\Omega \\\\\n",
    "  & x \\ge 0.\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "and decomposes it into a second-stage problem:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "V_2(\\bar{x}, d_\\omega) = \\max\\limits_{x,x^\\prime,y_\\omega} \\;\\; & 5y_\\omega - x^\\prime \\\\\n",
    "  & y_\\omega \\le x \\\\\n",
    "  & x^\\prime = x - y_\\omega \\\\\n",
    "  & 0 \\le y_\\omega \\le d_\\omega \\\\\n",
    "  & x = \\bar{x} & [\\lambda]\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "and a first-stage problem:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "V = \\max\\limits_{x,\\theta} \\;\\; & -2x + \\theta \\\\\n",
    "  & \\theta \\le \\mathbb{E}_\\omega[V_2(x, \\omega)] \\\\\n",
    "  & x \\ge 0\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, because $V_2$ is convex with respect to $\\bar{x}$ for fixed $\\omega$,\n",
    "we can use a set of feasible points $\\{x^k\\}$ construct an outer approximation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V^K = \\max\\limits_{x,\\theta} \\;\\; & -2x + \\theta \\\\\n",
    "  & \\theta \\le \\mathbb{E}_\\omega[V_2(x^k, \\omega) + \\nabla V_2(x^k, \\omega)^\\top(x - x^k)] & \\quad k = 1,\\ldots,K\\\\\n",
    "  & x \\ge 0 \\\\\n",
    "  & \\theta \\le M\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $M$ is an upper bound on possible values of $V_2$ so that the problem\n",
    "has a bounded solution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is also useful to see that because $\\bar{x}$ appears only on the right-hand\n",
    "side of a linear program, $\\nabla V_2(x^k, \\omega) = \\lambda^k$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ignoring how we choose $x^k$ for now, we can construct a lower and upper bound\n",
    "on the optimal solution:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$-2x^K + \\mathbb{E}_\\omega[V_2(x^K, \\omega)] = \\underbar{V} \\le V \\le \\overline{V} = V^K$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, we need some way of cleverly choosing a sequence of $x^k$ so that the\n",
    "lower bound converges to the upper bound."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Start with $K=1$\n",
    "2. Solve $V^{K-1}$ to get $x^K$\n",
    "3. Set $\\overline{V} = V^k$\n",
    "4. Solve $V_2(x^K, \\omega)$ for all $\\omega$ and store the optimal objective\n",
    "   value and dual solution $\\lambda^K$\n",
    "5. Set $\\underbar{V} = -2x^K + \\mathbb{E}_\\omega[V_2(x^k, \\omega)]$\n",
    "6. If $\\underbar{V} \\approx \\overline{V}$, STOP\n",
    "7. Add new constraint $\\theta \\le \\mathbb{E}_\\omega[V_2(x^K, \\omega) +\\lambda^K (x - x^K)]$\n",
    "8. Increment $K$, GOTO 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next section implements this algorithm in Julia."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L-Shaped implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a function to compute the second-stage problem;"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function solve_second_stage(x̅, d_ω)\n",
    "    model = Model(HiGHS.Optimizer)\n",
    "    set_silent(model)\n",
    "    @variable(model, x_in)\n",
    "    @variable(model, x_out >= 0)\n",
    "    fix(x_in, x̅)\n",
    "    @variable(model, 0 <= u_sell <= d_ω)\n",
    "    @constraint(model, x_out == x_in - u_sell)\n",
    "    @constraint(model, u_sell <= x_in)\n",
    "    @objective(model, Max, 5 * u_sell - 0.1 * x_out)\n",
    "    optimize!(model)\n",
    "    return (\n",
    "        V = objective_value(model),\n",
    "        λ = reduced_cost(x_in),\n",
    "        x = value(x_out),\n",
    "        u = value(u_sell),\n",
    "    )\n",
    "end\n",
    "\n",
    "solve_second_stage(200, 170)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's the first-stage subproblem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@variable(model, x_in == 0)\n",
    "@variable(model, x_out >= 0)\n",
    "@variable(model, u_make >= 0)\n",
    "@constraint(model, x_out == x_in + u_make)\n",
    "M = 5 * maximum(d)\n",
    "@variable(model, θ <= M)\n",
    "@objective(model, Max, -2 * u_make + θ)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importantly, to ensure we have a bounded solution, we need to add an upper\n",
    "bound to the variable `θ`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "kIterationLimit = 100\n",
    "for k in 1:kIterationLimit\n",
    "    println(\"Solving iteration k = $k\")\n",
    "    # Step 2\n",
    "    optimize!(model)\n",
    "    xᵏ = value(x_out)\n",
    "    println(\"  xᵏ = $xᵏ\")\n",
    "    # Step 3\n",
    "    ub = objective_value(model)\n",
    "    println(\"  V̅ = $ub\")\n",
    "    # Step 4\n",
    "    ret = [solve_second_stage(xᵏ, d[ω]) for ω in Ω]\n",
    "    # Step 5\n",
    "    lb = value(-2 * u_make) + sum(p * r.V for (p, r) in zip(P, ret))\n",
    "    println(\"  V̲ = $lb\")\n",
    "    # Step 6\n",
    "    if ub - lb < 1e-6\n",
    "        println(\"Terminating with near-optimal solution\")\n",
    "        break\n",
    "    end\n",
    "    # Step 7\n",
    "    c = @constraint(\n",
    "        model,\n",
    "        θ <= sum(p * (r.V + r.λ * (x_out - xᵏ)) for (p, r) in zip(P, ret)),\n",
    "    )\n",
    "    println(\"  Added cut: $c\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get the first-stage solution, we do:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "optimize!(model)\n",
    "xᵏ = value(x_out)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To compute a second-stage solution, we do:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_second_stage(xᵏ, 170.0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Policy Graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's see how we can formulate and train a policy for the two-stage\n",
    "newsvendor problem using `SDDP.jl`. Under the hood, `SDDP.jl` implements the\n",
    "exact algorithm that we just wrote by hand."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.LinearPolicyGraph(;\n",
    "    stages = 2,\n",
    "    sense = :Max,\n",
    "    upper_bound = 5 * maximum(d),  # The `M` in θ <= M\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem::JuMP.Model, stage::Int\n",
    "    @variable(subproblem, x >= 0, SDDP.State, initial_value = 0)\n",
    "    if stage == 1\n",
    "        @variable(subproblem, u_make >= 0)\n",
    "        @constraint(subproblem, x.out == x.in + u_make)\n",
    "        @stageobjective(subproblem, -2 * u_make)\n",
    "    else\n",
    "        @variable(subproblem, u_sell >= 0)\n",
    "        @constraint(subproblem, u_sell <= x.in)\n",
    "        @constraint(subproblem, x.out == x.in - u_sell)\n",
    "        SDDP.parameterize(subproblem, d, P) do ω\n",
    "            set_upper_bound(u_sell, ω)\n",
    "            return\n",
    "        end\n",
    "        @stageobjective(subproblem, 5 * u_sell - 0.1 * x.out)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "SDDP.train(model; log_every_iteration = true)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way to query the optimal policy is with `SDDP.DecisionRule`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first_stage_rule = SDDP.DecisionRule(model; node = 1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution_1 = SDDP.evaluate(first_stage_rule; incoming_state = Dict(:x => 0.0))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's the second stage:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "second_stage_rule = SDDP.DecisionRule(model; node = 2)\n",
    "solution = SDDP.evaluate(\n",
    "    second_stage_rule;\n",
    "    incoming_state = Dict(:x => solution_1.outgoing_state[:x]),\n",
    "    noise = 170.0,  # A value of d[ω], can be out-of-sample.\n",
    "    controls_to_record = [:u_sell],\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Querying the decision rules is tedious. It's often more useful to simulate the\n",
    "policy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simulations = SDDP.simulate(\n",
    "    model,\n",
    "    10,  #= number of replications =#\n",
    "    [:x, :u_sell, :u_make];  #= variables to record =#\n",
    "    skip_undefined_variables = true,\n",
    ");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`simulations` is a vector with 10 elements"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "length(simulations)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and each element is a vector with two elements (one for each stage)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "length(simulations[1])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first stage contains:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simulations[1][1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second stage contains:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "simulations[1][2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compute aggregated statistics across the simulations:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "objectives = map(simulations) do simulation\n",
    "    return sum(data[:stage_objective] for data in simulation)\n",
    "end\n",
    "μ, t = SDDP.confidence_interval(objectives)\n",
    "println(\"Simulation ci : $μ ± $t\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk aversion revisited"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SDDP.jl contains a number of risk measures. One example is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "0.5 * SDDP.Expectation() + 0.5 * SDDP.WorstCase()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can construct a risk-averse policy by passing a risk measure to the\n",
    "`risk_measure` keyword argument of `SDDP.train`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can explore how the optimal decision changes with risk by creating a\n",
    "function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function solve_newsvendor(risk_measure::SDDP.AbstractRiskMeasure)\n",
    "    model = SDDP.LinearPolicyGraph(;\n",
    "        stages = 2,\n",
    "        sense = :Max,\n",
    "        upper_bound = 5 * maximum(d),\n",
    "        optimizer = HiGHS.Optimizer,\n",
    "    ) do subproblem, node\n",
    "        @variable(subproblem, x >= 0, SDDP.State, initial_value = 0)\n",
    "        if node == 1\n",
    "            @stageobjective(subproblem, -2 * x.out)\n",
    "        else\n",
    "            @variable(subproblem, u_sell >= 0)\n",
    "            @constraint(subproblem, u_sell <= x.in)\n",
    "            @constraint(subproblem, x.out == x.in - u_sell)\n",
    "            SDDP.parameterize(subproblem, d, P) do ω\n",
    "                set_upper_bound(u_sell, ω)\n",
    "                return\n",
    "            end\n",
    "            @stageobjective(subproblem, 5 * u_sell - 0.1 * x.out)\n",
    "        end\n",
    "        return\n",
    "    end\n",
    "    SDDP.train(model; risk_measure = risk_measure, print_level = 0)\n",
    "    first_stage_rule = SDDP.DecisionRule(model; node = 1)\n",
    "    solution = SDDP.evaluate(first_stage_rule; incoming_state = Dict(:x => 0.0))\n",
    "    return solution.outgoing_state[:x]\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can see how many units a decision maker would order using `CVaR`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_newsvendor(SDDP.CVaR(0.4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "as well as a decision-maker who cares only about the worst-case outcome:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_newsvendor(SDDP.WorstCase())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, the decision-maker will be somewhere between the two extremes.\n",
    "The `SDDP.Entropic` risk measure is a risk measure that has a single\n",
    "parameter that lets us explore the space of policies between the two extremes.\n",
    "When the parameter is small, the measure acts like `SDDP.Expectation`,\n",
    "and when it is large, it acts like `SDDP.WorstCase`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is what we get if we solve our problem multiple times for different\n",
    "values of the risk aversion parameter $\\gamma$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Γ = [10^i for i in -4:0.5:1]\n",
    "buy = [solve_newsvendor(SDDP.Entropic(γ)) for γ in Γ]\n",
    "Plots.plot(\n",
    "    Γ,\n",
    "    buy;\n",
    "    xaxis = :log,\n",
    "    xlabel = \"Risk aversion parameter γ\",\n",
    "    ylabel = \"Number of pies to make\",\n",
    "    legend = false,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things to try"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a number of things you can try next:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Experiment with different buy and sales prices\n",
    " * Experiment with different distributions of demand\n",
    " * Explore how the optimal policy changes if you use a different risk measure\n",
    " * What happens if you can only buy and sell integer numbers of newspapers?\n",
    "   Try this by adding `Int` to the variable definitions:\n",
    "   `@variable(subproblem, buy >= 0, Int)`\n",
    " * What happens if you use a different upper bound? Try an invalid one like\n",
    "   `-100`, and a very large one like `1e12`."
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
