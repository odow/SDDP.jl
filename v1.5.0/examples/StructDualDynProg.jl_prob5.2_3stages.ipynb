{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# StructDualDynProg: Problem 5.2, 3 stages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example comes from [StochasticDualDynamicProgramming.jl](https://github.com/blegat/StochasticDualDynamicProgramming.jl/blob/fe5ef82db6befd7c8f11c023a639098ecb85737d/test/prob5.2_3stages.jl)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP, HiGHS, Test\n",
    "\n",
    "function test_prob52_3stages()\n",
    "    model = SDDP.LinearPolicyGraph(\n",
    "        stages = 3,\n",
    "        lower_bound = 0.0,\n",
    "        optimizer = HiGHS.Optimizer,\n",
    "    ) do sp, t\n",
    "        n = 4\n",
    "        m = 3\n",
    "        i_c = [16, 5, 32, 2]\n",
    "        C = [25, 80, 6.5, 160]\n",
    "        T = [8760, 7000, 1500] / 8760\n",
    "        D2 = [diff([0, 3919, 7329, 10315]) diff([0, 7086, 9004, 11169])]\n",
    "        p2 = [0.9, 0.1]\n",
    "        @variable(sp, x[i = 1:n] >= 0, SDDP.State, initial_value = 0.0)\n",
    "        @variables(sp, begin\n",
    "            y[1:n, 1:m] >= 0\n",
    "            v[1:n] >= 0\n",
    "            penalty >= 0\n",
    "            ξ[j = 1:m]\n",
    "        end)\n",
    "        @constraints(sp, begin\n",
    "            [i = 1:n], x[i].out == x[i].in + v[i]\n",
    "            [i = 1:n], sum(y[i, :]) <= x[i].in\n",
    "            [j = 1:m], sum(y[:, j]) + penalty >= ξ[j]\n",
    "        end)\n",
    "        @stageobjective(sp, i_c'v + C' * y * T + 1e5 * penalty)\n",
    "        if t != 1 # no uncertainty in first stage\n",
    "            SDDP.parameterize(sp, 1:size(D2, 2), p2) do ω\n",
    "                for j in 1:m\n",
    "                    JuMP.fix(ξ[j], D2[j, ω])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        if t == 3\n",
    "            @constraint(sp, sum(v) == 0)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    det = SDDP.deterministic_equivalent(model, HiGHS.Optimizer)\n",
    "    set_silent(det)\n",
    "    JuMP.optimize!(det)\n",
    "    @test JuMP.objective_value(det) ≈ 406712.49 atol = 0.1\n",
    "\n",
    "    SDDP.train(\n",
    "        model;\n",
    "        stopping_rules = [SDDP.SimulationStoppingRule()],\n",
    "        log_frequency = 10,\n",
    "    )\n",
    "    @test SDDP.calculate_bound(model) ≈ 406712.49 atol = 0.1\n",
    "    return\n",
    "end\n",
    "\n",
    "test_prob52_3stages()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
