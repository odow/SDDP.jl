<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · SDDP.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>SDDP.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Home</a><ul class="internal"><li><a class="toctext" href="#Getting-started-1">Getting started</a></li><li><a class="toctext" href="#Citing-SDDP.jl-1">Citing SDDP.jl</a></li><li><a class="toctext" href="#FAQ-1">FAQ</a></li></ul></li><li><span class="toctext">Tutorials</span><ul><li><a class="toctext" href="tutorial/01_first_steps.html">Tutorial One: first steps</a></li><li><a class="toctext" href="tutorial/02_rhs_noise.html">Tutorial Two: RHS noise</a></li><li><a class="toctext" href="tutorial/03_objective_noise.html">Tutorial Three: objective noise</a></li><li><a class="toctext" href="tutorial/04_markovian_policygraphs.html">Tutorial Four: Markovian policy graphs</a></li><li><a class="toctext" href="tutorial/05_risk.html">Tutorial Five: risk</a></li><li><a class="toctext" href="tutorial/06_cut_selection.html">Tutorial Six: cut selection</a></li><li><a class="toctext" href="tutorial/07_plotting.html">Tutorial Seven: plotting</a></li><li><a class="toctext" href="tutorial/08_odds_and_ends.html">Tutorial Eight: odds and ends</a></li><li><a class="toctext" href="tutorial/09_nonlinear.html">Tutorial Nine: nonlinear models</a></li><li><a class="toctext" href="tutorial/10_parallel.html">Tutorial Ten: parallelism</a></li><li><a class="toctext" href="tutorial/11_DRO.html">Tutorial Eleven: distributionally robust SDDP</a></li><li><a class="toctext" href="tutorial/12_price_interpolation.html">Tutorial Twelve: price interpolation</a></li><li><a class="toctext" href="tutorial/13_constraint_noise.html">Tutorial Thirteen: constraint noise</a></li></ul></li><li><a class="toctext" href="readings.html">Readings</a></li><li><a class="toctext" href="apireference.html">Reference</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Home</a></li></ul><a class="edit-page" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="SDDP.jl-Documentation-1" href="#SDDP.jl-Documentation-1">SDDP.jl Documentation</a></h1><p>SDDP.jl is a package for solving large multistage convex stochastic optimization problems using <em>stochastic dual dynamic programming</em>. In this manual, we&#39;re going to assume a reasonable amount of background knowledge about stochastic optimization, the SDDP algorithm, Julia, and JuMP.</p><div class="admonition note"><div class="admonition-title">Note</div><div class="admonition-text"><p>If you don&#39;t have that background, you may want to brush up on some <a href="readings.html#Readings-1">Readings</a>. Part I of my <a href="assets/dowson_thesis.pdf">thesis</a> may also be useful as it contains a primer on how to formulate multistage stochastic optimization problems (Chapter One), as well as an introduction and literature review of the SDDP algorithm (Chapter Two).</p></div></div><h2><a class="nav-anchor" id="Getting-started-1" href="#Getting-started-1">Getting started</a></h2><p>This package is unregistered so you will need to <code>Pkg.clone</code> it as follows:</p><pre><code class="language-julia">Pkg.clone(&quot;https://github.com/odow/SDDP.jl.git&quot;)</code></pre><p>If you want to use the parallel features of SDDP.jl, you should start Julia with some worker processes (<code>julia -p N</code>), or add by running <code>julia&gt; addprocs(N)</code> in a running Julia session.</p><p>Once you&#39;ve got SDDP.jl installed, you should read some tutorials, beginning with <a href="tutorial/01_first_steps.html#Tutorial-One:-first-steps-1">Tutorial One: first steps</a>.</p><h2><a class="nav-anchor" id="Citing-SDDP.jl-1" href="#Citing-SDDP.jl-1">Citing SDDP.jl</a></h2><p>If you use SDDP.jl, we ask that you please cite the following <a href="http://www.optimization-online.org/DB_FILE/2017/12/6388.pdf">paper</a>:</p><pre><code class="language-none">@article{dowson_sddp.jl,
	title = {{SDDP}.jl: a {Julia} package for stochastic dual dynamic programming},
	url = {http://www.optimization-online.org/DB_HTML/2017/12/6388.html},
	journal = {Optimization Online},
	author = {Dowson, Oscar and Kapelevich, Lea},
	year = {2017}
}</code></pre><h2><a class="nav-anchor" id="FAQ-1" href="#FAQ-1">FAQ</a></h2><p><strong>Q.</strong> How do I make the constraint coefficients random?</p><p><strong>A.</strong> Due to the design of JuMP, it&#39;s difficult to efficiently modify constraint coefficients. Therefore, you can only vary the right hand-side of a constraint using the <code>@rhsnoise</code> macro.</p><p>As a work around, we suggest you either reformulate the model so the uncertainty appears in the RHS, or model the uncertainty as a Markov process. <a href="tutorial/04_markovian_policygraphs.html#Tutorial-Four:-Markovian-policy-graphs-1">Tutorial Four: Markovian policy graphs</a> explains how to implement this. You might also want to take a look at the <a href="https://github.com/odow/SDDP.jl/blob/master/examples/AssetManagement/asset_management.jl">asset management example</a> to see an example of this. Make sure you keep in mind that a new value function is built at each Markov state which increases the computation time and memory requirements.</p><footer><hr/><a class="next" href="tutorial/01_first_steps.html"><span class="direction">Next</span><span class="title">Tutorial One: first steps</span></a></footer></article></body></html>
