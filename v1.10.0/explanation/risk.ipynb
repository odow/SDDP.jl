{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Risk aversion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In Introductory theory, we implemented a basic version of the\n",
    "SDDP algorithm. This tutorial extends that implementation to add\n",
    "**risk-aversion**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Packages**\n",
    "\n",
    "This tutorial uses the following packages. For clarity, we call\n",
    "`import PackageName` so that we must prefix `PackageName.` to all functions\n",
    "and structs provided by that package. Everything not prefixed is either part\n",
    "of base Julia, or we wrote it."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import ForwardDiff\n",
    "import HiGHS\n",
    "import Ipopt\n",
    "import JuMP\n",
    "import Statistics"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk aversion: what and why?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Often, the agents making decisions in complex systems are **risk-averse**,\n",
    "that is, they care more about avoiding very bad outcomes, than they do about\n",
    "having a good average outcome."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example, consumers in a hydro-thermal problem may be willing to pay a\n",
    "slightly higher electricity price on average, if it means that there is a\n",
    "lower probability of blackouts."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Risk aversion in multistage stochastic programming has been well studied in\n",
    "the academic literature, and is widely used in production implementations\n",
    "around the world."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk measures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way to add risk aversion to models is to use a **risk measure**. A risk\n",
    "measure is a function that maps a random variable to a real number.\n",
    "\n",
    "You are probably already familiar with lots of different risk measures. For\n",
    "example, the mean, median, mode, and maximum are all risk measures.\n",
    "\n",
    "We call the act of applying a risk measure to a random variable \"computing the\n",
    "risk\" of a random variable.\n",
    "\n",
    "To keep things simple, and because we need it for SDDP, we restrict our\n",
    "attention to random variables $Z$ with a finite sample space $\\Omega$\n",
    "and positive probabilities $p_{\\omega}$ for all $\\omega \\in \\Omega$. We denote\n",
    "the realizations of $Z$ by $Z(\\omega) = z_{\\omega}$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A risk measure, $\\mathbb{F}[Z]$, is a **convex risk measure** if it satisfies\n",
    "the following axioms:\n",
    "\n",
    "**Axiom 1: monotonicity**\n",
    "\n",
    "Given two random variables $Z_1$ and $Z_2$, with $Z_1 \\le Z_2$ almost surely,\n",
    "then $\\mathbb{F}[Z_1] \\le F[Z_2]$.\n",
    "\n",
    "**Axiom 2: translation equivariance**\n",
    "\n",
    "Given two random variables $Z_1$ and $Z_2$, then for all $a \\in \\mathbb{R}$,\n",
    "$\\mathbb{F}[Z + a] = \\mathbb{F}[Z] + a$.\n",
    "\n",
    "**Axiom 3: convexity**\n",
    "\n",
    "Given two random variables $Z_1$ and $Z_2$, then for all $a \\in [0, 1]$,\n",
    "$$\n",
    "\\mathbb{F}[a Z_1 + (1 - a) Z_2] \\le a \\mathbb{F}[Z_1] + (1-a)\\mathbb{F}[Z_2].\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we know what a risk measure is, let's see how we can use them to form\n",
    "risk-averse decision rules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk-averse decision rules: Part I"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We started this tutorial by explaining that we are interested in risk aversion\n",
    "because some agents are risk-averse. What that really means, is that they\n",
    "want a policy that is also risk-averse. The question then becomes, how do we\n",
    "create risk-averse decision rules and policies?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recall from Introductory theory that we can form an optimal\n",
    "decision rule using the recursive formulation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V_i(x, \\omega) = \\min\\limits_{\\bar{x}, x^\\prime, u} \\;\\; & C_i(\\bar{x}, u, \\omega) + \\mathbb{E}_{j \\in i^+, \\varphi \\in \\Omega_j}[V_j(x^\\prime, \\varphi)]\\\\\n",
    "& x^\\prime = T_i(\\bar{x}, u, \\omega) \\\\\n",
    "& u \\in U_i(\\bar{x}, \\omega) \\\\\n",
    "& \\bar{x} = x,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where our decision rule, $\\pi_i(x, \\omega)$, solves this optimization problem\n",
    "and returns a $u^*$ corresponding to an optimal solution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we can replace the expectation operator $\\mathbb{E}$ with another (more\n",
    "risk-averse) risk measure $\\mathbb{F}$, then our decision rule will attempt to\n",
    "choose a control decision now that minimizes the risk of the future costs, as\n",
    "opposed to the expectation of the future costs. This makes our decisions more\n",
    "risk-averse, because we care more about the worst outcomes than we do about\n",
    "the average."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Therefore, we can form a risk-averse decision rule using the formulation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "V_i(x, \\omega) = \\min\\limits_{\\bar{x}, x^\\prime, u} \\;\\; & C_i(\\bar{x}, u, \\omega) + \\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}[V_j(x^\\prime, \\varphi)]\\\\\n",
    "& x^\\prime = T_i(\\bar{x}, u, \\omega) \\\\\n",
    "& u \\in U_i(\\bar{x}, \\omega) \\\\\n",
    "& \\bar{x} = x.\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To convert this problem into a tractable equivalent, we apply Kelley's\n",
    "algorithm to the risk-averse cost-to-go term\n",
    "$\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}[V_j(x^\\prime, \\varphi)]$, to\n",
    "obtain the approximated problem:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "V_i^K(x, \\omega) = \\min\\limits_{\\bar{x}, x^\\prime, u} \\;\\; & C_i(\\bar{x}, u, \\omega) + \\theta\\\\\n",
    "& x^\\prime = T_i(\\bar{x}, u, \\omega) \\\\\n",
    "& u \\in U_i(\\bar{x}, \\omega) \\\\\n",
    "& \\bar{x} = x \\\\\n",
    "& \\theta \\ge \\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right] + \\frac{d}{dx^\\prime}\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right]^\\top (x^\\prime - x^\\prime_k)\\quad k=1,\\ldots,K.\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Warning**\n",
    ">\n",
    "> Note how we need to explicitly compute a risk-averse subgradient! (We\n",
    "> need a subgradient because the function might not be differentiable.) When\n",
    "> constructing cuts with the expectation operator in Introductory theory,\n",
    "> we implicitly used the law of total expectation to combine the two\n",
    "> expectations; we can't do that for a general risk measure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Homework challenge**\n",
    ">\n",
    "> If it's not obvious why we can use Kelley's here, try to use the axioms of\n",
    "> a convex risk measure to show that\n",
    "> $\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}[V_j(x^\\prime, \\varphi)]$\n",
    "> is a convex function w.r.t. $x^\\prime$ if $V_j$ is also a convex function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our challenge is now to find a way to compute the risk-averse cost-to-go\n",
    "function $\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right]$,\n",
    "and a way to compute a subgradient of the risk-averse cost-to-go function\n",
    "with respect to $x^\\prime$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Primal risk measures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we know what a risk measure is, and how we will use it, let's implement\n",
    "some code to see how we can compute the risk of some random variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Note**\n",
    ">\n",
    "> We're going to start by implementing the **primal** version of each risk\n",
    "> measure. We implement the **dual** version in the next section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need some data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Z = [1.0, 2.0, 3.0, 4.0]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "with probabilities:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = [0.1, 0.2, 0.4, 0.3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to implement a number of different risk measures, so to leverage\n",
    "Julia's multiple dispatch, we create an abstract type:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "abstract type AbstractRiskMeasure end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and function to overload:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    primal_risk(F::AbstractRiskMeasure, Z::Vector{<:Real}, p::Vector{Float64})\n",
    "\n",
    "Use `F` to compute the risk of the random variable defined by a vector of costs\n",
    "`Z` and non-zero probabilities `p`.\n",
    "\"\"\"\n",
    "function primal_risk end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Note**\n",
    ">\n",
    "> We want `Vector{<:Real}` instead of `Vector{Float64}` because we're going\n",
    "> to automatically differentiate this function in the next section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expectation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The expectation, $\\mathbb{E}$, also called the mean or the average, is the\n",
    "most widely used convex risk measure. The expectation of a random variable is\n",
    "just the sum of $Z$ weighted by the probability:\n",
    "$$\n",
    "\\mathbb{F}[Z] = \\mathbb{E}_p[Z] = \\sum\\limits_{\\omega\\in\\Omega} p_{\\omega} z_{\\omega}.\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct Expectation <: AbstractRiskMeasure end\n",
    "\n",
    "function primal_risk(::Expectation, Z::Vector{<:Real}, p::Vector{Float64})\n",
    "    return sum(p[i] * Z[i] for i in 1:length(p))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try it out:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "primal_risk(Expectation(), Z, p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### WorstCase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The worst-case risk measure, also called the maximum, is another widely used\n",
    "convex risk measure. This risk measure doesn't care about the probability\n",
    "vector `p`, only the cost vector `Z`:\n",
    "$$\n",
    "\\mathbb{F}[Z] = \\max[Z] = \\max\\limits_{\\omega\\in\\Omega} z_{\\omega}.\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct WorstCase <: AbstractRiskMeasure end\n",
    "\n",
    "function primal_risk(::WorstCase, Z::Vector{<:Real}, ::Vector{Float64})\n",
    "    return maximum(Z)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try it out:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "primal_risk(WorstCase(), Z, p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entropic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A more interesting, and less widely used risk measure is the entropic risk\n",
    "measure. The entropic risk measure is parameterized by a value $\\gamma > 0$,\n",
    "and computes the risk of a random variable as:\n",
    "$$\n",
    "\\mathbb{F}_\\gamma[Z] = \\frac{1}{\\gamma}\\log\\left(\\mathbb{E}_p[e^{\\gamma Z}]\\right) = \\frac{1}{\\gamma}\\log\\left(\\sum\\limits_{\\omega\\in\\Omega}p_{\\omega} e^{\\gamma z_{\\omega}}\\right).\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Homework challenge**\n",
    ">\n",
    "> Prove that the entropic risk measure satisfies the three axioms of a\n",
    "> convex risk measure."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct Entropic <: AbstractRiskMeasure\n",
    "    γ::Float64\n",
    "    function Entropic(γ)\n",
    "        if !(γ > 0)\n",
    "            throw(DomainError(γ, \"Entropic risk measure must have γ > 0.\"))\n",
    "        end\n",
    "        return new(γ)\n",
    "    end\n",
    "end\n",
    "\n",
    "function primal_risk(F::Entropic, Z::Vector{<:Real}, p::Vector{Float64})\n",
    "    return 1 / F.γ * log(sum(p[i] * exp(F.γ * Z[i]) for i in 1:length(p)))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Warning**\n",
    ">\n",
    "> `exp(x)` overflows when $x > 709$. Therefore, if we are passed a vector of\n",
    "> `Float64`, use arbitrary precision arithmetic with `big.(Z)`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function primal_risk(F::Entropic, Z::Vector{Float64}, p::Vector{Float64})\n",
    "    return Float64(primal_risk(F, big.(Z), p))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try it out for different values of $\\gamma$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for γ in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1_000.0]\n",
    "    println(\"γ = $(γ), F[Z] = \", primal_risk(Entropic(γ), Z, p))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Info**\n",
    ">\n",
    "> The entropic has two extremes. As $\\gamma \\rightarrow 0$, the entropic\n",
    "> acts like the expectation risk measure, and as $\\gamma \\rightarrow \\infty$,\n",
    "> the entropic acts like the worst-case risk measure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computing risk measures this way works well for computing the primal value.\n",
    "However, there isn't an obvious way to compute a subgradient of the\n",
    "risk-averse cost-to-go function, which we need for our cut calculation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is a nice solution to this problem, and that is to use the dual\n",
    "representation of a risk measure, instead of the primal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dual risk measures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convex risk measures have a dual representation as follows:\n",
    "$$\n",
    "\\mathbb{F}[Z] = \\sup\\limits_{q \\in\\mathcal{M}(p)} \\mathbb{E}_q[Z] - \\alpha(p, q),\n",
    "$$\n",
    "where $\\alpha$ is a concave function that maps the probability vectors $p$ and\n",
    "$q$ to a real number, and $\\mathcal{M}(p) \\subseteq \\mathcal{P}$ is a convex\n",
    "subset of the probability simplex:\n",
    "$$\n",
    "\\mathcal{P} = \\{p \\ge 0\\;|\\;\\sum\\limits_{\\omega\\in\\Omega}p_{\\omega} = 1\\}.\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dual of a convex risk measure can be interpreted as taking the expectation\n",
    "of the random variable $Z$ with respect to the worst probability vector $q$\n",
    "that lies within the set $\\mathcal{M}$, less some concave penalty term\n",
    "$\\alpha(p, q)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we define a function `dual_risk_inner` that computes `q` and `α`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dual_risk_inner(\n",
    "        F::AbstractRiskMeasure, Z::Vector{Float64}, p::Vector{Float64}\n",
    "    )::Tuple{Vector{Float64},Float64}\n",
    "\n",
    "Return a tuple formed by the worst-case probability vector `q` and the\n",
    "corresponding evaluation `α(p, q)`.\n",
    "\"\"\"\n",
    "function dual_risk_inner end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "then we can write a generic `dual_risk` function as:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk(\n",
    "    F::AbstractRiskMeasure,\n",
    "    Z::Vector{Float64},\n",
    "    p::Vector{Float64},\n",
    ")\n",
    "    q, α = dual_risk_inner(F, Z, p)\n",
    "    return sum(q[i] * Z[i] for i in 1:length(q)) - α\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expectation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the expectation risk measure, $\\mathcal{M}(p) = \\{p\\}$, and\n",
    "$\\alpha(\\cdot, \\cdot) = 0$. Therefore:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk_inner(::Expectation, ::Vector{Float64}, p::Vector{Float64})\n",
    "    return p, 0.0\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check we get the same result as the primal version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dual_risk(Expectation(), Z, p) == primal_risk(Expectation(), Z, p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Worst-case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the worst-case risk measure, $\\mathcal{M}(p) = \\mathcal{P}$, and\n",
    "$\\alpha(\\cdot, \\cdot) = 0$. Therefore, the dual representation just puts\n",
    "all of the probability weight on the maximum outcome:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk_inner(::WorstCase, Z::Vector{Float64}, ::Vector{Float64})\n",
    "    q = zeros(length(Z))\n",
    "    _, index = findmax(Z)\n",
    "    q[index] = 1.0\n",
    "    return q, 0.0\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check we get the same result as the primal version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dual_risk(WorstCase(), Z, p) == primal_risk(WorstCase(), Z, p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entropic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the entropic risk measure, $\\mathcal{M}(p) = \\mathcal{P}$, and:\n",
    "$$\n",
    "\\alpha(p, q) = \\frac{1}{\\gamma}\\sum\\limits_{\\omega\\in\\Omega} q_\\omega \\log\\left(\\frac{q_\\omega}{p_{\\omega}}\\right).\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way to solve the dual problem is to explicitly solve a nonlinear\n",
    "optimization problem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk_inner(F::Entropic, Z::Vector{Float64}, p::Vector{Float64})\n",
    "    N = length(p)\n",
    "    model = JuMP.Model(Ipopt.Optimizer)\n",
    "    JuMP.set_silent(model)\n",
    "    # For this problem, the solve is more accurate if we turn off problem\n",
    "    # scaling.\n",
    "    JuMP.set_optimizer_attribute(model, \"nlp_scaling_method\", \"none\")\n",
    "    JuMP.@variable(model, 0 <= q[1:N] <= 1)\n",
    "    JuMP.@constraint(model, sum(q) == 1)\n",
    "    JuMP.@NLexpression(\n",
    "        model,\n",
    "        α,\n",
    "        1 / F.γ * sum(q[i] * log(q[i] / p[i]) for i in 1:N),\n",
    "    )\n",
    "    JuMP.@NLobjective(model, Max, sum(q[i] * Z[i] for i in 1:N) - α)\n",
    "    JuMP.optimize!(model)\n",
    "    return JuMP.value.(q), JuMP.value(α)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check we get the same result as the primal version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for γ in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    primal = primal_risk(Entropic(γ), Z, p)\n",
    "    dual = dual_risk(Entropic(γ), Z, p)\n",
    "    success = primal ≈ dual ? \"✓\" : \"×\"\n",
    "    println(\"$(success) γ = $(γ), primal = $(primal), dual = $(dual)\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Info**\n",
    ">\n",
    "> This method of solving the dual problem \"on-the-side\" is used by SDDP.jl\n",
    "> for a number of risk measures, including a distributionally robust risk\n",
    "> measure with the Wasserstein distance. Check out all the risk measures\n",
    "> that SDDP.jl supports in Add a risk measure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"on-the-side\" method is very general, and it lets us incorporate any\n",
    "convex risk measure into SDDP. However, this comes at an increased\n",
    "computational cost and potential numerical issues (e.g., not converging to the\n",
    "exact solution)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, for the entropic risk measure, [Dowson, Morton, and Pagnoncelli (2020)](http://www.optimization-online.org/DB_HTML/2020/08/7984.html)\n",
    "derive the following closed form solution for $q^*$:\n",
    "$$\n",
    "q_\\omega^* = \\frac{p_{\\omega} e^{\\gamma z_{\\omega}}}{\\sum\\limits_{\\varphi \\in \\Omega} p_{\\varphi} e^{\\gamma z_{\\varphi}}}.\n",
    "$$\n",
    "This is faster because we don't need to use Ipopt, and it avoids some of the\n",
    "numerical issues associated with solving a nonlinear program."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk_inner(F::Entropic, Z::Vector{Float64}, p::Vector{Float64})\n",
    "    q, α = zeros(length(p)), big(0.0)\n",
    "    peγz = p .* exp.(F.γ .* big.(Z))\n",
    "    sum_peγz = sum(peγz)\n",
    "    for i in 1:length(q)\n",
    "        big_q = peγz[i] / sum_peγz\n",
    "        α += big_q * log(big_q / p[i])\n",
    "        q[i] = Float64(big_q)\n",
    "    end\n",
    "    return q, Float64(α / F.γ)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Warning**\n",
    ">\n",
    "> Again, note that we use `big` to avoid introducing overflow errors, before\n",
    "> explicitly casting back to `Float64` for the values we return."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can check we get the same result as the primal version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for γ in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    primal = primal_risk(Entropic(γ), Z, p)\n",
    "    dual = dual_risk(Entropic(γ), Z, p)\n",
    "    success = primal ≈ dual ? \"✓\" : \"×\"\n",
    "    println(\"$(success) γ = $(γ), primal = $(primal), dual = $(dual)\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk-averse subgradients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We ended the section on primal risk measures by explaining how we couldn't\n",
    "use the primal risk measure in the cut calculation because we needed some way\n",
    "of computing a risk-averse subgradient:\n",
    "$$\n",
    "\\theta \\ge \\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right] + \\frac{d}{dx^\\prime}\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right]^\\top (x^\\prime - x^\\prime_k).\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The reason we use the dual representation is because of the following theorem,\n",
    "which explains how to compute a risk-averse gradient."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **The risk-averse subgradient theorem**\n",
    ">\n",
    "> Let $\\omega \\in \\Omega$ index a random vector with finite support and with\n",
    "> nominal probability mass function, $p \\in \\mathcal{P}$, which satisfies\n",
    "> $p > 0$.\n",
    "\n",
    "    Consider a convex risk measure, $\\mathbb{F}$, with a convex risk set,\n",
    "    $\\mathcal{M}(p)$, so that $\\mathbb{F}$ can be expressed as the dual form.\n",
    "\n",
    "    Let $V(x,\\omega)$ be convex with respect to $x$ for all fixed\n",
    "    $\\omega\\in\\Omega$, and let $\\lambda(\\tilde{x}, \\omega)$ be a subgradient\n",
    "    of $V(x,\\omega)$ with respect to $x$ at $x = \\tilde{x}$ for each\n",
    "    $\\omega \\in \\Omega$.\n",
    "\n",
    "    Then, $\\sum_{\\omega\\in\\Omega}q^*_{\\omega} \\lambda(\\tilde{x},\\omega)$ is a\n",
    "    subgradient of $\\mathbb{F}[V(x,\\omega)]$ at $\\tilde{x}$, where\n",
    "    $$\n",
    "    q^* \\in \\argmax_{q \\in \\mathcal{M}(p)}\\left\\{{\\mathbb{E}}_q[V(\\tilde{x},\\omega)] - \\alpha(p, q)\\right\\}.\n",
    "    $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This theorem can be a little hard to unpack, so let's see an example:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function dual_risk_averse_subgradient(\n",
    "    V::Function,\n",
    "    # Use automatic differentiation to compute the gradient of V w.r.t. x,\n",
    "    # given a fixed ω.\n",
    "    λ::Function = (x, ω) -> ForwardDiff.gradient(x -> V(x, ω), x);\n",
    "    F::AbstractRiskMeasure,\n",
    "    Ω::Vector,\n",
    "    p::Vector{Float64},\n",
    "    x̃::Vector{Float64},\n",
    ")\n",
    "    # Evaluate the function at x=x̃ for all ω ∈ Ω.\n",
    "    V_ω = [V(x̃, ω) for ω in Ω]\n",
    "    # Solve the dual problem to obtain an optimal q^*.\n",
    "    q, α = dual_risk_inner(F, V_ω, p)\n",
    "    # Compute the risk-averse subgradient by taking the expectation of the\n",
    "    # subgradients w.r.t. q^*.\n",
    "    dVdx = sum(q[i] * λ(x̃, ω) for (i, ω) in enumerate(Ω))\n",
    "    return dVdx\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compare the subgradient obtained with the dual form against the\n",
    "automatic differentiation of the `primal_risk` function."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function primal_risk_averse_subgradient(\n",
    "    V::Function;\n",
    "    F::AbstractRiskMeasure,\n",
    "    Ω::Vector,\n",
    "    p::Vector{Float64},\n",
    "    x̃::Vector{Float64},\n",
    ")\n",
    "    inner(x) = primal_risk(F, [V(x, ω) for ω in Ω], p)\n",
    "    return ForwardDiff.gradient(inner, x̃)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As our example function, we use:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "V(x, ω) = ω * x[1]^2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "with:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Ω = [1.0, 2.0, 3.0]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " and:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "p = [0.3, 0.4, 0.3]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "at the point:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x̃ = [3.0]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $\\mathbb{F}$ is the expectation risk-measure, then:\n",
    "$$\n",
    "\\mathbb{F}[V(x, \\omega)] =  2 x^2.\n",
    "$$\n",
    "The function evaluation $x=3$ is $18$ and the subgradient is $12$. Let's check\n",
    "we get it right with the dual form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dual_risk_averse_subgradient(V; F = Expectation(), Ω = Ω, p = p, x̃ = x̃)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and the primal form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "primal_risk_averse_subgradient(V; F = Expectation(), Ω = Ω, p = p, x̃ = x̃)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $\\mathbb{F}$ is the worst-case risk measure, then:\n",
    "$$\n",
    "\\mathbb{F}[V(x, \\omega)] = 3 x^2.\n",
    "$$\n",
    "The function evaluation at $x=3$ is $27$, and the subgradient is $18$. Let's\n",
    "check we get it right with the dual form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dual_risk_averse_subgradient(V; F = WorstCase(), Ω = Ω, p = p, x̃ = x̃)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and the primal form:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "primal_risk_averse_subgradient(V; F = WorstCase(), Ω = Ω, p = p, x̃ = x̃)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $\\mathbb{F}$ is the entropic risk measure, the math is a little more\n",
    "difficult to derive analytically. However, we can check against our primal\n",
    "version:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "for γ in [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    dual =\n",
    "        dual_risk_averse_subgradient(V; F = Entropic(γ), Ω = Ω, p = p, x̃ = x̃)\n",
    "    primal = primal_risk_averse_subgradient(\n",
    "        V;\n",
    "        F = Entropic(γ),\n",
    "        Ω = Ω,\n",
    "        p = p,\n",
    "        x̃ = x̃,\n",
    "    )\n",
    "    success = primal ≈ dual ? \"✓\" : \"×\"\n",
    "    println(\"$(success) γ = $(γ), primal = $(primal), dual = $(dual)\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uh oh! What happened with the last line? It looks our `primal_risk_averse_subgradient`\n",
    "encountered an error and returned a subgradient of `NaN`. This is because of\n",
    "the overflow issue with `exp(x)`. However, we can be confident that our dual\n",
    "method of computing the risk-averse subgradient is both correct and more\n",
    "numerically robust than the primal version."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Info**\n",
    ">\n",
    "> As another sanity check, notice how as $\\gamma \\rightarrow 0$, we tend\n",
    "> toward the solution of the expectation risk-measure `[12]`, and as\n",
    "> $\\gamma \\rightarrow \\infty$, we tend toward the solution of the worse-case\n",
    "> risk measure `[18]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Risk-averse decision rules: Part II"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why is the risk-averse subgradient theorem helpful? Using the dual\n",
    "representation of a convex risk measure, we can re-write the cut:\n",
    "$$\n",
    "\\theta \\ge \\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right] + \\frac{d}{dx^\\prime}\\mathbb{F}_{j \\in i^+, \\varphi \\in \\Omega_j}\\left[V_j^k(x^\\prime_k, \\varphi)\\right]^\\top (x^\\prime - x^\\prime_k),\\quad k=1,\\ldots,K\n",
    "$$\n",
    "as:\n",
    "$$\n",
    "\\theta \\ge \\mathbb{E}_{q_k}\\left[V_j^k(x^\\prime_k, \\varphi) + \\frac{d}{dx^\\prime}V_j^k(x^\\prime_k, \\varphi)^\\top (x^\\prime - x^\\prime_k)\\right] - \\alpha(p, q_k),\\quad k=1,\\ldots,K,\n",
    "$$\n",
    "where $q_k = \\mathrm{arg}\\sup\\limits_{q \\in\\mathcal{M}(p)} \\mathbb{E}_q[V_j^k(x_k^\\prime, \\varphi)] - \\alpha(p, q)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Therefore, we can formulate a risk-averse decision rule as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V_i^K(x, \\omega) = \\min\\limits_{\\bar{x}, x^\\prime, u} \\;\\; & C_i(\\bar{x}, u, \\omega) + \\theta\\\\\n",
    "& x^\\prime = T_i(\\bar{x}, u, \\omega) \\\\\n",
    "& u \\in U_i(\\bar{x}, \\omega) \\\\\n",
    "& \\bar{x} = x \\\\\n",
    "& \\theta \\ge \\mathbb{E}_{q_k}\\left[V_j^k(x^\\prime_k, \\varphi) + \\frac{d}{dx^\\prime}V_j^k(x^\\prime_k, \\varphi)^\\top (x^\\prime - x^\\prime_k)\\right] - \\alpha(p, q_k),\\quad k=1,\\ldots,K \\\\\n",
    "& \\theta \\ge M.\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $q_k = \\mathrm{arg}\\sup\\limits_{q \\in\\mathcal{M}(p)} \\mathbb{E}_q[V_j^k(x_k^\\prime, \\varphi)] - \\alpha(p, q)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, to implement risk-averse SDDP, all we need to do is modify the backward\n",
    "pass to include this calculation of $q_k$, form the cut using $q_k$ instead of\n",
    "$p$, and subtract the penalty term $\\alpha(p, q_k)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're ready to implement our risk-averse version of SDDP."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a prerequisite, we need most of the code from Introductory theory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p><details>\n",
    "<summary>Click to view code from the tutorial \"Introductory theory\".</summary>"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct State\n",
    "    in::JuMP.VariableRef\n",
    "    out::JuMP.VariableRef\n",
    "end\n",
    "\n",
    "struct Uncertainty\n",
    "    parameterize::Function\n",
    "    Ω::Vector{Any}\n",
    "    P::Vector{Float64}\n",
    "end\n",
    "\n",
    "struct Node\n",
    "    subproblem::JuMP.Model\n",
    "    states::Dict{Symbol,State}\n",
    "    uncertainty::Uncertainty\n",
    "    cost_to_go::JuMP.VariableRef\n",
    "end\n",
    "\n",
    "struct PolicyGraph\n",
    "    nodes::Vector{Node}\n",
    "    arcs::Vector{Dict{Int,Float64}}\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, model::PolicyGraph)\n",
    "    println(io, \"A policy graph with $(length(model.nodes)) nodes\")\n",
    "    println(io, \"Arcs:\")\n",
    "    for (from, arcs) in enumerate(model.arcs)\n",
    "        for (to, probability) in arcs\n",
    "            println(io, \"  $(from) => $(to) w.p. $(probability)\")\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function PolicyGraph(\n",
    "    subproblem_builder::Function;\n",
    "    graph::Vector{Dict{Int,Float64}},\n",
    "    lower_bound::Float64,\n",
    "    optimizer,\n",
    ")\n",
    "    nodes = Node[]\n",
    "    for t in 1:length(graph)\n",
    "        model = JuMP.Model(optimizer)\n",
    "        states, uncertainty = subproblem_builder(model, t)\n",
    "        JuMP.@variable(model, cost_to_go >= lower_bound)\n",
    "        obj = JuMP.objective_function(model)\n",
    "        JuMP.@objective(model, Min, obj + cost_to_go)\n",
    "        if length(graph[t]) == 0\n",
    "            JuMP.fix(cost_to_go, 0.0; force = true)\n",
    "        end\n",
    "        push!(nodes, Node(model, states, uncertainty, cost_to_go))\n",
    "    end\n",
    "    return PolicyGraph(nodes, graph)\n",
    "end\n",
    "\n",
    "function sample_uncertainty(uncertainty::Uncertainty)\n",
    "    r = rand()\n",
    "    for (p, ω) in zip(uncertainty.P, uncertainty.Ω)\n",
    "        r -= p\n",
    "        if r < 0.0\n",
    "            return ω\n",
    "        end\n",
    "    end\n",
    "    return error(\"We should never get here because P should sum to 1.0.\")\n",
    "end\n",
    "\n",
    "function sample_next_node(model::PolicyGraph, current::Int)\n",
    "    if length(model.arcs[current]) == 0\n",
    "        return nothing\n",
    "    else\n",
    "        r = rand()\n",
    "        for (to, probability) in model.arcs[current]\n",
    "            r -= probability\n",
    "            if r < 0.0\n",
    "                return to\n",
    "            end\n",
    "        end\n",
    "        return nothing\n",
    "    end\n",
    "end\n",
    "\n",
    "function forward_pass(model::PolicyGraph, io::IO = stdout)\n",
    "    incoming_state =\n",
    "        Dict(k => JuMP.fix_value(v.in) for (k, v) in model.nodes[1].states)\n",
    "    simulation_cost = 0.0\n",
    "    trajectory = Tuple{Int,Dict{Symbol,Float64}}[]\n",
    "    t = 1\n",
    "    while t !== nothing\n",
    "        node = model.nodes[t]\n",
    "        ω = sample_uncertainty(node.uncertainty)\n",
    "        node.uncertainty.parameterize(ω)\n",
    "        for (k, v) in incoming_state\n",
    "            JuMP.fix(node.states[k].in, v; force = true)\n",
    "        end\n",
    "        JuMP.optimize!(node.subproblem)\n",
    "        if JuMP.termination_status(node.subproblem) != JuMP.MOI.OPTIMAL\n",
    "            error(\"Something went terribly wrong!\")\n",
    "        end\n",
    "        outgoing_state = Dict(k => JuMP.value(v.out) for (k, v) in node.states)\n",
    "        stage_cost =\n",
    "            JuMP.objective_value(node.subproblem) - JuMP.value(node.cost_to_go)\n",
    "        simulation_cost += stage_cost\n",
    "        incoming_state = outgoing_state\n",
    "        push!(trajectory, (t, outgoing_state))\n",
    "        t = sample_next_node(model, t)\n",
    "    end\n",
    "    return trajectory, simulation_cost\n",
    "end\n",
    "\n",
    "function upper_bound(model::PolicyGraph; replications::Int)\n",
    "    simulations = [forward_pass(model, devnull) for i in 1:replications]\n",
    "    z = [s[2] for s in simulations]\n",
    "    μ = Statistics.mean(z)\n",
    "    tσ = 1.96 * Statistics.std(z) / sqrt(replications)\n",
    "    return μ, tσ\n",
    "end\n",
    "\n",
    "function lower_bound(model::PolicyGraph)\n",
    "    node = model.nodes[1]\n",
    "    bound = 0.0\n",
    "    for (p, ω) in zip(node.uncertainty.P, node.uncertainty.Ω)\n",
    "        node.uncertainty.parameterize(ω)\n",
    "        JuMP.optimize!(node.subproblem)\n",
    "        bound += p * JuMP.objective_value(node.subproblem)\n",
    "    end\n",
    "    return bound\n",
    "end\n",
    "\n",
    "function evaluate_policy(\n",
    "    model::PolicyGraph;\n",
    "    node::Int,\n",
    "    incoming_state::Dict{Symbol,Float64},\n",
    "    random_variable,\n",
    ")\n",
    "    the_node = model.nodes[node]\n",
    "    the_node.uncertainty.parameterize(random_variable)\n",
    "    for (k, v) in incoming_state\n",
    "        JuMP.fix(the_node.states[k].in, v; force = true)\n",
    "    end\n",
    "    JuMP.optimize!(the_node.subproblem)\n",
    "    return Dict(\n",
    "        k => JuMP.value.(v) for\n",
    "        (k, v) in JuMP.object_dictionary(the_node.subproblem)\n",
    "    )\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "</details></p>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need to modify the backward pass to compute the cuts using the\n",
    "risk-averse subgradient theorem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function backward_pass(\n",
    "    model::PolicyGraph,\n",
    "    trajectory::Vector{Tuple{Int,Dict{Symbol,Float64}}},\n",
    "    io::IO = stdout;\n",
    "    risk_measure::AbstractRiskMeasure,\n",
    ")\n",
    "    println(io, \"| Backward pass\")\n",
    "    for i in reverse(1:length(trajectory))\n",
    "        index, outgoing_states = trajectory[i]\n",
    "        node = model.nodes[index]\n",
    "        println(io, \"| | Visiting node $(index)\")\n",
    "        if length(model.arcs[index]) == 0\n",
    "            continue\n",
    "        end\n",
    "        # =====================================================================\n",
    "        # New! Create vectors to store the cut expressions, V(x,ω) and p:\n",
    "        cut_expressions, V_ω, p = JuMP.AffExpr[], Float64[], Float64[]\n",
    "        # =====================================================================\n",
    "        for (j, P_ij) in model.arcs[index]\n",
    "            next_node = model.nodes[j]\n",
    "            for (k, v) in outgoing_states\n",
    "                JuMP.fix(next_node.states[k].in, v; force = true)\n",
    "            end\n",
    "            for (pφ, φ) in zip(next_node.uncertainty.P, next_node.uncertainty.Ω)\n",
    "                next_node.uncertainty.parameterize(φ)\n",
    "                JuMP.optimize!(next_node.subproblem)\n",
    "                V = JuMP.objective_value(next_node.subproblem)\n",
    "                dVdx = Dict(\n",
    "                    k => JuMP.reduced_cost(v.in) for (k, v) in next_node.states\n",
    "                )\n",
    "                # =============================================================\n",
    "                # New! Construct and append the expression\n",
    "                # `V_j^K(x_k, φ) + dVdx_j^K(x'_k, φ)ᵀ(x - x_k)` to the list of\n",
    "                # cut expressions.\n",
    "                push!(\n",
    "                    cut_expressions,\n",
    "                    JuMP.@expression(\n",
    "                        node.subproblem,\n",
    "                        V + sum(\n",
    "                            dVdx[k] * (x.out - outgoing_states[k]) for\n",
    "                            (k, x) in node.states\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "                # Add the objective value to Z:\n",
    "                push!(V_ω, V)\n",
    "                # Add the probability to p:\n",
    "                push!(p, P_ij * pφ)\n",
    "                # =============================================================\n",
    "            end\n",
    "        end\n",
    "        # =====================================================================\n",
    "        # New! Using the solutions in V_ω, compute q and α:\n",
    "        q, α = dual_risk_inner(risk_measure, V_ω, p)\n",
    "        println(io, \"| | | Z = \", Z)\n",
    "        println(io, \"| | | p = \", p)\n",
    "        println(io, \"| | | q = \", q)\n",
    "        println(io, \"| | | α = \", α)\n",
    "        # Then add the cut:\n",
    "        c = JuMP.@constraint(\n",
    "            node.subproblem,\n",
    "            node.cost_to_go >=\n",
    "            sum(q[i] * cut_expressions[i] for i in 1:length(q)) - α\n",
    "        )\n",
    "        # =====================================================================\n",
    "        println(io, \"| | | Adding cut : \", c)\n",
    "    end\n",
    "    return nothing\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also need to update the `train` loop of SDDP to pass a risk measure to the\n",
    "backward pass:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train(\n",
    "    model::PolicyGraph;\n",
    "    iteration_limit::Int,\n",
    "    replications::Int,\n",
    "    # =========================================================================\n",
    "    # New! Add a risk_measure argument\n",
    "    risk_measure::AbstractRiskMeasure,\n",
    "    # =========================================================================\n",
    "    io::IO = stdout,\n",
    ")\n",
    "    for i in 1:iteration_limit\n",
    "        println(io, \"Starting iteration $(i)\")\n",
    "        outgoing_states, _ = forward_pass(model, io)\n",
    "        # =====================================================================\n",
    "        # New! Pass the risk measure to the backward pass.\n",
    "        backward_pass(model, outgoing_states, io; risk_measure = risk_measure)\n",
    "        # =====================================================================\n",
    "        println(io, \"| Finished iteration\")\n",
    "        println(io, \"| | lower_bound = \", lower_bound(model))\n",
    "    end\n",
    "    μ, tσ = upper_bound(model; replications = replications)\n",
    "    println(io, \"Upper bound = $(μ) ± $(tσ)\")\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Risk-averse bounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Warning**\n",
    ">\n",
    "> This section is important."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we had a risk-neutral policy (i.e., we only used the expectation risk\n",
    "measure), we discussed how we could form valid lower and upper bounds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The upper bound is still valid as a Monte Carlo simulation of the expected\n",
    "cost of the policy. (Although this upper bound doesn't capture the change in\n",
    "the policy we wanted to achieve, namely that the impact of the worst outcomes\n",
    "were reduced.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, if we use a different risk measure, the lower bound is no longer\n",
    "valid!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can still calculate a \"lower bound\" as the objective of the first-stage\n",
    "approximated subproblem, and this will converge to a finite value. However,\n",
    "we can't meaningfully interpret it as a bound with respect to the optimal\n",
    "policy. Therefore, it's best to just ignore the lower bound when training a\n",
    "risk-averse policy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example: risk-averse hydro-thermal scheduling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time for an example. We create the same problem as\n",
    "Introductory theory:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = PolicyGraph(;\n",
    "    graph = [Dict(2 => 1.0), Dict(3 => 1.0), Dict{Int,Float64}()],\n",
    "    lower_bound = 0.0,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem, t\n",
    "    JuMP.set_silent(subproblem)\n",
    "    JuMP.@variable(subproblem, volume_in == 200)\n",
    "    JuMP.@variable(subproblem, 0 <= volume_out <= 200)\n",
    "    states = Dict(:volume => State(volume_in, volume_out))\n",
    "    JuMP.@variables(subproblem, begin\n",
    "        thermal_generation >= 0\n",
    "        hydro_generation >= 0\n",
    "        hydro_spill >= 0\n",
    "        inflow\n",
    "    end)\n",
    "    JuMP.@constraints(\n",
    "        subproblem,\n",
    "        begin\n",
    "            volume_out == volume_in + inflow - hydro_generation - hydro_spill\n",
    "            demand_constraint, thermal_generation + hydro_generation == 150.0\n",
    "        end\n",
    "    )\n",
    "    fuel_cost = [50.0, 100.0, 150.0]\n",
    "    JuMP.@objective(subproblem, Min, fuel_cost[t] * thermal_generation)\n",
    "    uncertainty =\n",
    "        Uncertainty([0.0, 50.0, 100.0], [1 / 3, 1 / 3, 1 / 3]) do ω\n",
    "            return JuMP.fix(inflow, ω)\n",
    "        end\n",
    "    return states, uncertainty\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we train a risk-averse policy, passing a risk measure to `train`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train(\n",
    "    model;\n",
    "    iteration_limit = 3,\n",
    "    replications = 100,\n",
    "    risk_measure = Entropic(1.0),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, evaluate the decision rule:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "evaluate_policy(\n",
    "    model;\n",
    "    node = 1,\n",
    "    incoming_state = Dict(:volume => 150.0),\n",
    "    random_variable = 75,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Info**\n",
    ">\n",
    "> For this trivial example, the risk-averse policy isn't very different from\n",
    "> the policy obtained using the expectation risk-measure. If you try it on\n",
    "> some bigger/more interesting problems, you should see the expected cost\n",
    "> increase, and the upper tail of the policy decrease."
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
