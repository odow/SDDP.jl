{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Duality handlers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this tutorial is to demonstrate trivial examples that expose\n",
    "the strengths and weaknesses of each duality handler."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For more information on SDDP.jl's duality handlers, see Integrality."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial uses the following packages:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP\n",
    "import HiGHS"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that these trivial examples exposed a bug in HiGHS, which we work-around\n",
    "by turning off presolve. In real examples, you should probably leave the\n",
    "default options."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Optimizer = optimizer_with_attributes(HiGHS.Optimizer, \"presolve\" => \"off\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need a function to simplify our testing:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function train_and_evaluate_bounds(\n",
    "    model_fn::Function,\n",
    "    duality_handler::SDDP.AbstractDualityHandler;\n",
    "    print_level::Int = 0,\n",
    "    kwargs...,\n",
    ")\n",
    "    model = model_fn()\n",
    "    SDDP.train(model; print_level, duality_handler, kwargs...)\n",
    "    simulations = SDDP.simulate(model, 1)\n",
    "    lower_bound = SDDP.calculate_bound(model)\n",
    "    println(\"lower_bound: $(lower_bound)\")\n",
    "    upper_bound = sum(data[:stage_objective] for data in only(simulations))\n",
    "    println(\"upper_bound: $(upper_bound)\")\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function builds a new model, trains it using the provided `duality_handler`,\n",
    "and then prints the lower and upper bounds. We'll assume that the models we\n",
    "pass in are deterministic so we need to conduct only a single simulation to\n",
    "evaluate the upper bound."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Danger**\n",
    ">\n",
    "> The most important thing to keep in mind when reading this tutorial is\n",
    "> that SDDP.jl is not guaranteed to find a globally optimal policy. No\n",
    "> matter what options we select, there may be a gap between the lower and\n",
    "> upper bound."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `ContinuousConicDuality`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default duality handler in SDDP.jl is `ContinuousConicDuality`.\n",
    "To compute a cut, it solves the continuous relaxation of the MIP."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the same way that solution to a relaxed linear program may be far from the\n",
    "optimal MIP solution, the biggest downside to `ContinuousConicDuality`\n",
    "is that many models have large gaps between the lower and upper bound:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function model_1()\n",
    "    return SDDP.LinearPolicyGraph(;\n",
    "        stages = 2,\n",
    "        lower_bound = 0.0,\n",
    "        optimizer = Optimizer,\n",
    "    ) do sp, t\n",
    "        @variable(sp, x, Bin, SDDP.State, initial_value = 1.0)\n",
    "        @variable(sp, y, Bin)\n",
    "        @constraint(sp, x.out == x.in)\n",
    "        if t == 1\n",
    "            @stageobjective(sp, x.out)\n",
    "        else\n",
    "            @stageobjective(sp, y)\n",
    "            @constraint(sp, y >= x.in - 0.5)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "train_and_evaluate_bounds(model_1, SDDP.ContinuousConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `StrengthenedConicDuality`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One technique to improve upon `ContinuousConicDuality` is\n",
    "`StrengthenedConicDuality`. Without going into the technical details,\n",
    "both use the continuous relaxation to compute a valid subgradient for the cut.\n",
    "`StrengthenedConicDuality` then tries to improve the cut by solving an\n",
    "additional integer program."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, `StrengthenedConicDuality` can improve upon the lower\n",
    "bound and prove that the upper bound of `2.0` is optimal:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_1, SDDP.StrengthenedConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sometimes, however, `StrengthenedConicDuality` cannot improve upon\n",
    "`ContinuousConicDuality`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function model_2()\n",
    "    return SDDP.LinearPolicyGraph(;\n",
    "        stages = 2,\n",
    "        lower_bound = 0.0,\n",
    "        optimizer = Optimizer,\n",
    "    ) do sp, t\n",
    "        @variable(sp, x, SDDP.State, initial_value = 0.1)\n",
    "        @variable(sp, y, Int)\n",
    "        @constraint(sp, x.out == x.in)\n",
    "        if t == 1\n",
    "            @stageobjective(sp, x.out)\n",
    "        else\n",
    "            @stageobjective(sp, y)\n",
    "            @constraint(sp, y >= x.in + 0.1)\n",
    "            @constraint(sp, y >= -x.in + 0.1)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "train_and_evaluate_bounds(model_2, SDDP.ContinuousConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_2, SDDP.StrengthenedConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though it is sometimes tighter than `ContinuousConicDuality` and\n",
    "it can never be worse, `StrengthenedConicDuality` is not the default\n",
    "duality handler because it is more expensive to compute; it solves a\n",
    "mixed-integer program whereas `ContinuousConicDuality` solves a\n",
    "continuous relaxation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `LagrangianDuality`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A technique to improve upon `StrengthenedConicDuality` is\n",
    "`LagrangianDuality`. Without going into the technical details,\n",
    "both use the continuous relaxation to compute a valid subgradient for the cut,\n",
    "but, where `StrengthenedConicDuality` tries to improve the cut by\n",
    "solving a single additional integer program, `LagrangianDuality` may\n",
    "solve many integer programs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`LagrangianDuality` finds the optimal policy for `model_1`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_1, SDDP.LagrangianDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and also for `model_2`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_2, SDDP.LagrangianDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sometimes, however, `LagrangianDuality` does not close the gap:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function model_3()\n",
    "    return SDDP.LinearPolicyGraph(;\n",
    "        stages = 2,\n",
    "        lower_bound = -1.0,\n",
    "        optimizer = Optimizer,\n",
    "    ) do sp, t\n",
    "        @variable(sp, -1 <= x <= 0.5, SDDP.State, initial_value = 0.0)\n",
    "        @variable(sp, y)\n",
    "        @stageobjective(sp, y)\n",
    "        if t == 1\n",
    "            @constraint(sp, y >= x.out)\n",
    "            @constraint(sp, y >= -x.out)\n",
    "        else\n",
    "            @variable(sp, z, Bin)\n",
    "            @constraint(sp, y >= 1 - x.in - 3 * z)\n",
    "            @constraint(sp, y >= 1 + x.in - 3 * (1 - z))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "train_and_evaluate_bounds(model_3, SDDP.LagrangianDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "but it may still be better than `StrengthenedConicDuality`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_3, SDDP.StrengthenedConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The algorithm behind `LagrangianDuality` is significantly more\n",
    "complicated than `StrengthenedConicDuality`. For some models it can\n",
    "be helpful, for others, the increased computational cost is not worth the\n",
    "improvement in the tightness of the value function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Different policies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So far, the different duality handlers have led to different lower bounds, but\n",
    "identical upper bounds. This is an artifact of our trivial examples. Using a\n",
    "more sophisticated duality handler can improve the lower bound _and_ lead to\n",
    "a cheaper policy (the upper bound). Here's an example:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function model_4()\n",
    "    return SDDP.LinearPolicyGraph(;\n",
    "        stages = 2,\n",
    "        lower_bound = -1.0,\n",
    "        optimizer = Optimizer,\n",
    "    ) do sp, t\n",
    "        @variable(sp, -1 <= x <= 0.5, SDDP.State, initial_value = 0.0)\n",
    "        @variable(sp, y)\n",
    "        @variable(sp, z, Bin)\n",
    "        if t == 1\n",
    "            @stageobjective(sp, -0.1 * x.out)\n",
    "        else\n",
    "            @stageobjective(sp, y)\n",
    "            @constraint(sp, y >= 1 - x.in - 3 * z)\n",
    "            @constraint(sp, y >= 1 + x.in - 3 * (1 - z))\n",
    "        end\n",
    "    end\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`ContinuousConicDuality` finds in a policy that costs `0.45`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_4, SDDP.ContinuousConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "whereas `LagrangianDuality` finds a policy that costs `0.1`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_4, SDDP.LagrangianDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This relationship is not guaranteed to hold. In some models\n",
    "`ContinuousConicDuality` may find a cheaper policy than\n",
    "`LagrangianDuality`, even though the latter finds a tighter lower\n",
    "bound. In general, you should experiment with different duality handlers to\n",
    "see what works best for your problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `BanditDuality`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The trade-off between the computational cost and the tightness of a\n",
    "formulation can be tricky to manage. SDDP.jl includes `BanditDuality`,\n",
    "which is an algorithm that does not appear in the published academic\n",
    "literature. The `BanditDuality` duality handler treats the problem of\n",
    "choosing a duality handler for each iteration of the SDDP algorithm as a\n",
    "multi-armed bandit problem, where the reward is the change in the lower bound\n",
    "after each iteration per second of computation time. The multi-armed bandit\n",
    "problem allows us to trade off many fast but weak iterations of\n",
    "`ContinuousConicDuality` against a small number of relatively strong\n",
    "iterations of `LagrangianDuality`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "duality_handler = SDDP.BanditDuality(\n",
    "    SDDP.ContinuousConicDuality(),\n",
    "    SDDP.StrengthenedConicDuality(),\n",
    "    SDDP.LagrangianDuality(),\n",
    ")\n",
    "train_and_evaluate_bounds(model_1, duality_handler)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_2, duality_handler)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_3, duality_handler)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `BanditDuality` is often a very good choice to use in practice.\n",
    "It is not the default because a tighter lower bound does not always lead to a\n",
    "better policy, so we opt for the simplest and fastest duality handler as the\n",
    "default."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `FixedDiscreteDuality`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An alternative to `StrengthenedConicDuality` is `FixedDiscreteDuality`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It works by first solving the mixed-integer problem, fixing the discrete\n",
    "variables to their optimal value, and then solving the continuous relaxation.\n",
    "The cut from the continuous relaxation is then modified by solving another\n",
    "mixed-integer problem to ensure that it remains globally valid."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For some models, `FixedDiscreteDuality` can find solutions that are\n",
    "tighter than `StrengthenedConicDuality`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_2, SDDP.FixedDiscreteDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_2, SDDP.StrengthenedConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other times, it is weaker:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_1, SDDP.FixedDiscreteDuality())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_and_evaluate_bounds(model_1, SDDP.StrengthenedConicDuality())"
   ],
   "metadata": {},
   "execution_count": null
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
