{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Partially observable inventory management"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP, HiGHS, Random, Statistics, Test\n",
    "\n",
    "function inventory_management_problem()\n",
    "    demand_values = [1.0, 2.0]\n",
    "    demand_prob = Dict(:Ah => [0.2, 0.8], :Bh => [0.8, 0.2])\n",
    "    graph = SDDP.Graph(\n",
    "        :root_node,\n",
    "        [:Ad, :Ah, :Bd, :Bh],\n",
    "        [\n",
    "            (:root_node => :Ad, 0.5),\n",
    "            (:root_node => :Bd, 0.5),\n",
    "            (:Ad => :Ah, 1.0),\n",
    "            (:Ah => :Ad, 0.8),\n",
    "            (:Ah => :Bd, 0.1),\n",
    "            (:Bd => :Bh, 1.0),\n",
    "            (:Bh => :Bd, 0.8),\n",
    "            (:Bh => :Ad, 0.1),\n",
    "        ],\n",
    "    )\n",
    "    SDDP.add_ambiguity_set(graph, [:Ad, :Bd], 1e2)\n",
    "    SDDP.add_ambiguity_set(graph, [:Ah, :Bh], 1e2)\n",
    "\n",
    "    model = SDDP.PolicyGraph(\n",
    "        graph;\n",
    "        lower_bound = 0.0,\n",
    "        optimizer = HiGHS.Optimizer,\n",
    "    ) do subproblem, node\n",
    "        @variables(\n",
    "            subproblem,\n",
    "            begin\n",
    "                0 <= inventory <= 2, (SDDP.State, initial_value = 0.0)\n",
    "                buy >= 0\n",
    "                demand\n",
    "            end\n",
    "        )\n",
    "        @constraint(subproblem, demand == inventory.in - inventory.out + buy)\n",
    "        if node == :Ad || node == :Bd || node == :D\n",
    "            JuMP.fix(demand, 0)\n",
    "            @stageobjective(subproblem, buy)\n",
    "        else\n",
    "            SDDP.parameterize(subproblem, demand_values, demand_prob[node]) do ω\n",
    "                return JuMP.fix(demand, ω)\n",
    "            end\n",
    "            @stageobjective(subproblem, 2 * buy + inventory.out)\n",
    "        end\n",
    "    end\n",
    "    # Train the policy.\n",
    "    Random.seed!(123)\n",
    "    SDDP.train(\n",
    "        model;\n",
    "        iteration_limit = 100,\n",
    "        cut_type = SDDP.SINGLE_CUT,\n",
    "        log_frequency = 10,\n",
    "        parallel_scheme = SDDP.Serial(),\n",
    "    )\n",
    "    results = SDDP.simulate(model, 500; parallel_scheme = SDDP.Serial())\n",
    "    objectives =\n",
    "        [sum(s[:stage_objective] for s in simulation) for simulation in results]\n",
    "    sample_mean = round(Statistics.mean(objectives); digits = 2)\n",
    "    sample_ci = round(1.96 * Statistics.std(objectives) / sqrt(500); digits = 2)\n",
    "    @test SDDP.calculate_bound(model) ≈ sample_mean atol = sample_ci\n",
    "    return\n",
    "end\n",
    "\n",
    "inventory_management_problem()"
   ],
   "metadata": {},
   "execution_count": null
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
