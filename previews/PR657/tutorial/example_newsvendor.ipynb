{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example: Two-stage Newsvendor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example is based on the classical newsvendor problem."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SDDP\n",
    "import HiGHS\n",
    "import Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need some discretized distribution of demand. For simplicity, we're\n",
    "going to sample 10 points from the uniform `[0, 1)` distribution three times\n",
    "and add them together. This is a rough approximation of a normal distribution."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Ω = rand(10) .+ rand(10) .+ rand(10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also need some price data. We assume the agent can buy a newspaper for \\$1\n",
    "and sell it for \\$1.20."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "buy_price, sales_price = 1.0, 1.2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can formulate and train a policy for the two-stage newsvendor problem:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.LinearPolicyGraph(\n",
    "    stages = 2,\n",
    "    sense = :Max,\n",
    "    upper_bound = maximum(Ω) * sales_price,\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem, stage\n",
    "    @variable(subproblem, inventory >= 0, SDDP.State, initial_value = 0)\n",
    "    if stage == 1\n",
    "        @variable(subproblem, buy >= 0)\n",
    "        @constraint(subproblem, inventory.out == inventory.in + buy)\n",
    "        @stageobjective(subproblem, -buy_price * buy)\n",
    "    else\n",
    "        @variable(subproblem, sell >= 0)\n",
    "        @constraint(subproblem, sell <= inventory.in)\n",
    "        SDDP.parameterize(subproblem, Ω) do ω\n",
    "            return JuMP.set_upper_bound(sell, ω)\n",
    "        end\n",
    "        @stageobjective(subproblem, sales_price * sell)\n",
    "    end\n",
    "end\n",
    "\n",
    "SDDP.train(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check the first-stage buy decision, we need to obtain a decision rule for\n",
    "the first-stage node `1`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first_stage_rule = SDDP.DecisionRule(model, node = 1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can evaluate it, passing in a starting point for the incoming state:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution = SDDP.evaluate(\n",
    "    first_stage_rule;\n",
    "    incoming_state = Dict(:inventory => 0.0),\n",
    "    controls_to_record = [:buy],\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal value of the `buy` variable is stored here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution.controls[:buy]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducing risk"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The solution of a single newsvendor problem offers little insight about how\n",
    "a decision-maker should act. In particular, they may be averse to bad\n",
    "outcomes, such as when they purchase a larger number of newspapers only for\n",
    "there to be little demand."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can explore how the optimal decision changes with risk by creating a\n",
    "function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function solve_risk_averse_newsvendor(Ω, risk_measure)\n",
    "    model = SDDP.LinearPolicyGraph(\n",
    "        stages = 2,\n",
    "        sense = :Max,\n",
    "        upper_bound = maximum(Ω) * sales_price,\n",
    "        optimizer = HiGHS.Optimizer,\n",
    "    ) do subproblem, stage\n",
    "        @variable(subproblem, inventory >= 0, SDDP.State, initial_value = 0)\n",
    "        if stage == 1\n",
    "            @variable(subproblem, buy >= 0)\n",
    "            @constraint(subproblem, inventory.out == inventory.in + buy)\n",
    "            @stageobjective(subproblem, -buy_price * buy)\n",
    "        else\n",
    "            @variable(subproblem, sell >= 0)\n",
    "            @constraint(subproblem, sell <= inventory.in)\n",
    "            SDDP.parameterize(subproblem, Ω) do ω\n",
    "                return JuMP.set_upper_bound(sell, ω)\n",
    "            end\n",
    "            @stageobjective(subproblem, sales_price * sell)\n",
    "        end\n",
    "    end\n",
    "    SDDP.train(model; risk_measure = risk_measure, print_level = 0)\n",
    "    first_stage_rule = SDDP.DecisionRule(model, node = 1)\n",
    "    solution = SDDP.evaluate(\n",
    "        first_stage_rule;\n",
    "        incoming_state = Dict(:inventory => 0.0),\n",
    "        controls_to_record = [:buy],\n",
    "    )\n",
    "    return solution.controls[:buy]\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can see how many units a risk-neutral decision maker would order:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_risk_averse_newsvendor(Ω, SDDP.Expectation())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "as well as a decision-maker who cares only about the worst-case outcome:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_risk_averse_newsvendor(Ω, SDDP.WorstCase())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, the decision-maker will be somewhere between the two extremes.\n",
    "The `SDDP.Entropic` risk measure is a risk measure that has a single\n",
    "parameter that lets us explore the space of policies between the two extremes.\n",
    "When the parameter is small, the measure acts like `SDDP.Expectation`,\n",
    "and when it is large, it acts like `SDDP.WorstCase`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is what we get if we solve our problem multiple times for different\n",
    "values of the risk aversion parameter $\\gamma$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Γ = [10^i for i in -3:0.2:3]\n",
    "buy = [solve_risk_averse_newsvendor(Ω, SDDP.Entropic(γ)) for γ in Γ]\n",
    "Plots.plot(\n",
    "    Γ,\n",
    "    buy;\n",
    "    xaxis = :log,\n",
    "    xlabel = \"Risk aversion parameter γ\",\n",
    "    ylabel = \"First-stage buy decision\",\n",
    "    legend = false,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things to try"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a number of things you can try next:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Experiment with different buy and sales prices\n",
    " * Experiment with different distributions of demand\n",
    " * Explore how the optimal policy changes if you use a different risk measure\n",
    " * What happens if you can only buy and sell integer numbers of newspapers?\n",
    "   Try this by adding `Int` to the variable definitions:\n",
    "   `@variable(subproblem, buy >= 0, Int)`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
