{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Two-stage stochastic programs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this tutorial is to demonstrate how to model and solve a\n",
    "two-stage stochastic program."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial uses the following packages"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JuMP\n",
    "using SDDP\n",
    "import Distributions\n",
    "import HiGHS\n",
    "import Plots\n",
    "import StatsPlots\n",
    "import Statistics"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "During the week, you are a busy practitioner of Operations Research. To escape\n",
    "the drudgery of mathematics, you decide to invest in a food truck that you\n",
    "park at a popular park on a Saturday afternoon. Your delicacy of choice is\n",
    "a creamy mushroom pie with puff pastry. After a few weeks, it quickly becomes\n",
    "apparent that operating a food business is not so easy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pies must be prepared on a Saturday morning, _before_ you arrive at the\n",
    "location and can gauge the level of demand. If you bake too many, the unsold\n",
    "pies at the end of the day must be discarded and you have wasted time and\n",
    "money on their production. But if you bake too few, then there may be\n",
    "un-served customers and you could have made more money by baking more pies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After a few weeks of poor decision making, you decide to put your knowledge of\n",
    "Operations Research to good use, starting with some data collection."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each pie costs you \\$2 to make, and you sell them at \\$5 each. Disposal of an\n",
    "unsold pie costs \\$0.10. Based on three weeks of data collected, in which you\n",
    "made 200 pies each week, you sold 150, 190, and 200 pies. Thus, as a guess,\n",
    "you assume a triangular distribution of demand with a minimum of 150, a median\n",
    "of 200, and a maximum of 250."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can model this problem by a two-stage stochastic program. In the first\n",
    "stage, we decide a quantity of pies to make $x$. We make this decision\n",
    "before we observe the demand $d_\\omega$. In the second stage, we sell\n",
    "$y_\\omega$ pies, and incur any costs for unsold pies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can formulate this problem as follows:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max\\limits_{x,y_\\omega} \\;\\; & -2x + \\mathbb{E}_\\omega[5y_\\omega - 0.1(x - y_\\omega)] \\\\\n",
    "  & y_\\omega \\le x              & \\quad \\forall \\omega \\in \\Omega \\\\\n",
    "  & 0 \\le y_\\omega \\le d_\\omega & \\quad \\forall \\omega \\in \\Omega \\\\\n",
    "  & x \\ge 0.\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Average approximation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the distribution of demand is continuous, then our problem has an infinite\n",
    "number of variables and constraints. To form a computationally tractable\n",
    "problem, we instead use a finite set of samples drawn from the distribution.\n",
    "This is called sample average approximation (SAA)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "D = Distributions.TriangularDist(150.0, 250.0, 200.0)\n",
    "N = 100\n",
    "d = sort!(rand(D, N));\n",
    "Ω = 1:N\n",
    "P = fill(1 / N, N);\n",
    "StatsPlots.histogram(d; bins = 20, label = \"\", xlabel = \"Demand\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## JuMP model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The implementation of our two-stage stochastic program in JuMP is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@variable(model, x >= 0)\n",
    "@variable(model, 0 <= y[ω in Ω] <= d[ω])\n",
    "@constraint(model, [ω in Ω], y[ω] <= x)\n",
    "@expression(model, z[ω in Ω], 5y[ω] - 0.1 * (x - y[ω]))\n",
    "@objective(model, Max, -2x + sum(P[ω] * z[ω] for ω in Ω))\n",
    "optimize!(model)\n",
    "solution_summary(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal number of pies to make is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "value(x)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distribution of total profit is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "total_profit = [-2 * value(x) + value(z[ω]) for ω in Ω]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    bin_distribution(x::Vector{Float64}, N::Int)\n",
    "\n",
    "A helper function that discretizes `x` into bins of width `N`.\n",
    "\"\"\"\n",
    "bin_distribution(x, N) = N * (floor(minimum(x) / N):ceil(maximum(x) / N))\n",
    "\n",
    "plot = StatsPlots.histogram(\n",
    "    total_profit;\n",
    "    bins = bin_distribution(total_profit, 25),\n",
    "    label = \"\",\n",
    "    xlabel = \"Profit [\\$]\",\n",
    "    ylabel = \"Number of outcomes\",\n",
    ")\n",
    "μ = Statistics.mean(total_profit)\n",
    "Plots.vline!(\n",
    "    plot,\n",
    "    [μ];\n",
    "    label = \"Expected profit (\\$$(round(Int, μ)))\",\n",
    "    linewidth = 3,\n",
    ")\n",
    "plot"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Try solving this problem for different numbers of samples and different\n",
    "   distributions.\n",
    " * Refactor the example to avoid hard-coding the costs. What happens to the\n",
    "   solution if the cost of disposing unsold pies increases?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk measures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A risk measure is a function which maps a random variable to a real number.\n",
    "Common risk measures include the mean (expectation), median, mode, and\n",
    "maximum. We need a risk measure to convert the distribution of second stage\n",
    "costs into a single number that can be optimized."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our model currently uses the expectation risk measure, but others are possible\n",
    "too. One popular risk measure is the conditional value at risk (CVaR)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "CVaR has a parameter $\\gamma$, and it computes the expectation of the worst\n",
    "$\\gamma$ fraction of outcomes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we are maximizing, so that small outcomes are bad, the definition of CVaR\n",
    "is:\n",
    "$$\n",
    "CVaR_{\\gamma}[Z] = \\max\\limits_{\\xi} \\;\\; \\xi - \\frac{1}{\\gamma}\\mathbb{E}_\\omega\\left[(\\xi - Z)_+\\right]\n",
    "$$\n",
    "which can be formulated as the linear program:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "CVaR_{\\gamma}[Z] = \\max\\limits_{\\xi, z_\\omega} \\;\\; & \\xi - \\frac{1}{\\gamma}\\sum P_\\omega z_\\omega\\\\\n",
    " & z_\\omega \\ge \\xi - Z_\\omega & \\quad \\forall \\omega \\\\\n",
    " & z_\\omega \\ge 0 & \\quad \\forall \\omega.\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function CVaR(Z::Vector{Float64}, P::Vector{Float64}; γ::Float64)\n",
    "    @assert 0 < γ <= 1\n",
    "    N = length(Z)\n",
    "    model = Model(HiGHS.Optimizer)\n",
    "    set_silent(model)\n",
    "    @variable(model, ξ)\n",
    "    @variable(model, z[1:N] >= 0)\n",
    "    @constraint(model, [i in 1:N], z[i] >= ξ - Z[i])\n",
    "    @objective(model, Max, ξ - 1 / γ * sum(P[i] * z[i] for i in 1:N))\n",
    "    optimize!(model)\n",
    "    return objective_value(model)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "When `γ` is `1.0`, we compute the mean of the profit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cvar_10 = CVaR(total_profit, P; γ = 1.0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Statistics.mean(total_profit)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As `γ` approaches `0.0`, we compute the worst-case (minimum) profit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cvar_00 = CVaR(total_profit, P; γ = 0.0001)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "minimum(total_profit)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "By varying `γ` between `0` and `1` we can compute some trade-off of these two\n",
    "extremes:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cvar_05 = CVaR(total_profit, P; γ = 0.5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot these outcomes on our distribution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot = StatsPlots.histogram(\n",
    "    total_profit;\n",
    "    bins = bin_distribution(total_profit, 25),\n",
    "    label = \"\",\n",
    "    xlabel = \"Profit [\\$]\",\n",
    "    ylabel = \"Number of outcomes\",\n",
    ")\n",
    "Plots.vline!(\n",
    "    plot,\n",
    "    [cvar_10 cvar_05 cvar_00];\n",
    "    label = [\"γ = 1.0\" \"γ = 0.5\" \"γ = 0.0\"],\n",
    "    linewidth = 3,\n",
    ")\n",
    "plot"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk averse sample average approximation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because CVaR can be formulated as a linear program, we can form a risk averse\n",
    "sample average approximation model by combining the two formulations:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "γ = 0.4\n",
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@variable(model, x >= 0)\n",
    "@variable(model, 0 <= y[ω in Ω] <= d[ω])\n",
    "@constraint(model, [ω in Ω], y[ω] <= x)\n",
    "@expression(model, Z[ω in Ω], 5 * y[ω] - 0.1(x - y[ω]))\n",
    "@variable(model, ξ)\n",
    "@variable(model, z[ω in Ω] >= 0)\n",
    "@constraint(model, [ω in Ω], z[ω] >= ξ - Z[ω])\n",
    "@objective(model, Max, -2x + ξ - 1 / γ * sum(P[ω] * z[ω] for ω in Ω))\n",
    "optimize!(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "When $\\gamma = 0.4$, the optimal number of pies to bake is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "value(x)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distribution of total profit is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "risk_averse_total_profit = [value(-2x + Z[ω]) for ω in Ω]\n",
    "bins = bin_distribution([total_profit; risk_averse_total_profit], 25)\n",
    "plot = StatsPlots.histogram(total_profit; label = \"Expectation\", bins = bins)\n",
    "StatsPlots.histogram!(\n",
    "    plot,\n",
    "    risk_averse_total_profit;\n",
    "    label = \"CV@R\",\n",
    "    bins = bins,\n",
    "    alpha = 0.5,\n",
    ")\n",
    "plot"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Policy Graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can formulate and train a policy for the two-stage newsvendor problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we need to construct the graph:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "graph = SDDP.LinearGraph(2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we need to write a function which builds a JuMP model for each node in\n",
    "the graph:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function build_subproblem(subproblem::JuMP.Model, stage::Int)\n",
    "    @variable(subproblem, x >= 0, SDDP.State, initial_value = 0)\n",
    "    if stage == 1\n",
    "        @stageobjective(subproblem, -2 * x.out)\n",
    "    else\n",
    "        @variable(subproblem, y >= 0)\n",
    "        @constraint(subproblem, y <= x.in)\n",
    "        SDDP.parameterize(subproblem, d, P) do ω\n",
    "            set_upper_bound(y, ω)\n",
    "            return\n",
    "        end\n",
    "        @stageobjective(subproblem, 5 * y - 0.1 * (x.in - y))\n",
    "    end\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we can combine the graph and the subproblem builder into a policy graph:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.PolicyGraph(\n",
    "    build_subproblem,\n",
    "    graph;\n",
    "    sense = :Max,\n",
    "    upper_bound = 5 * maximum(d),\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `SDDP.train` to construct the policy:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "SDDP.train(model)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check the first-stage buy decision, we need to obtain a decision rule for\n",
    "the first-stage node `1`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "first_stage_rule = SDDP.DecisionRule(model, node = 1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can evaluate it, passing in a starting point for the incoming state:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution = SDDP.evaluate(first_stage_rule; incoming_state = Dict(:x => 0.0))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal value of the `buy` variable is stored here:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solution.outgoing_state[:x]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can simplify the model construction by using `SDDP.LinearPolicyGraph`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.LinearPolicyGraph(\n",
    "    build_subproblem;\n",
    "    stages = 2,\n",
    "    sense = :Max,\n",
    "    upper_bound = 5 * maximum(d),\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and we can use Julia's `do` syntax to avoid writing a separate function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "model = SDDP.LinearPolicyGraph(;\n",
    "    stages = 2,\n",
    "    sense = :Max,\n",
    "    upper_bound = 5 * maximum(d),\n",
    "    optimizer = HiGHS.Optimizer,\n",
    ") do subproblem::JuMP.Model, stage::Int\n",
    "    @variable(subproblem, x >= 0, SDDP.State, initial_value = 0)\n",
    "    if stage == 1\n",
    "        @stageobjective(subproblem, -2 * x.out)\n",
    "    else\n",
    "        @variable(subproblem, y >= 0)\n",
    "        @constraint(subproblem, y <= x.in)\n",
    "        SDDP.parameterize(subproblem, d, P) do ω\n",
    "            set_upper_bound(y, ω)\n",
    "            return\n",
    "        end\n",
    "        @stageobjective(subproblem, 5 * y - 0.1 * (x.in - y))\n",
    "    end\n",
    "    return\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Risk aversion revisited"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SDDP.jl contains a number of risk measures. One example is:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "0.5 * SDDP.Expectation() + 0.5 * SDDP.WorstCase()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can construct a risk-averse policy by passing a risk measure to the\n",
    "`risk_measure` keyword argument of `SDDP.train`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can explore how the optimal decision changes with risk by creating a\n",
    "function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function solve_newsvendor(risk_measure::SDDP.AbstractRiskMeasure)\n",
    "    model = SDDP.LinearPolicyGraph(\n",
    "        stages = 2,\n",
    "        sense = :Max,\n",
    "        upper_bound = 5 * maximum(d),\n",
    "        optimizer = HiGHS.Optimizer,\n",
    "    ) do subproblem, stage\n",
    "        @variable(subproblem, x >= 0, SDDP.State, initial_value = 0)\n",
    "        if stage == 1\n",
    "            @stageobjective(subproblem, -2 * x.out)\n",
    "        else\n",
    "            @variable(subproblem, y >= 0)\n",
    "            @constraint(subproblem, y <= x.in)\n",
    "            SDDP.parameterize(subproblem, d, P) do ω\n",
    "                set_upper_bound(y, ω)\n",
    "                return\n",
    "            end\n",
    "            @stageobjective(subproblem, 5 * y - 0.1 * (x.in - y))\n",
    "        end\n",
    "        return\n",
    "    end\n",
    "    SDDP.train(model; risk_measure = risk_measure, print_level = 0)\n",
    "    first_stage_rule = SDDP.DecisionRule(model; node = 1)\n",
    "    solution = SDDP.evaluate(first_stage_rule; incoming_state = Dict(:x => 0.0))\n",
    "    return solution.outgoing_state[:x]\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can see how many units a decision maker would order using `CVaR`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_newsvendor(SDDP.CVaR(0.4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "as well as a decision-maker who cares only about the worst-case outcome:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solve_newsvendor(SDDP.WorstCase())"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general, the decision-maker will be somewhere between the two extremes.\n",
    "The `SDDP.Entropic` risk measure is a risk measure that has a single\n",
    "parameter that lets us explore the space of policies between the two extremes.\n",
    "When the parameter is small, the measure acts like `SDDP.Expectation`,\n",
    "and when it is large, it acts like `SDDP.WorstCase`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is what we get if we solve our problem multiple times for different\n",
    "values of the risk aversion parameter $\\gamma$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Γ = [10^i for i in -4:0.5:1]\n",
    "buy = [solve_newsvendor(SDDP.Entropic(γ)) for γ in Γ]\n",
    "Plots.plot(\n",
    "    Γ,\n",
    "    buy;\n",
    "    xaxis = :log,\n",
    "    xlabel = \"Risk aversion parameter γ\",\n",
    "    ylabel = \"Number of pies to make\",\n",
    "    legend = false,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things to try"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a number of things you can try next:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Experiment with different buy and sales prices\n",
    " * Experiment with different distributions of demand\n",
    " * Explore how the optimal policy changes if you use a different risk measure\n",
    " * What happens if you can only buy and sell integer numbers of newspapers?\n",
    "   Try this by adding `Int` to the variable definitions:\n",
    "   `@variable(subproblem, buy >= 0, Int)`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
