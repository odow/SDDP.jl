<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Basic I: first steps · SDDP.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SDDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SDDP.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Basic I: first steps</a><ul class="internal"><li><a class="tocitem" href="#Mathematical-formulation"><span>Mathematical formulation</span></a></li><li><a class="tocitem" href="#Creating-a-model"><span>Creating a model</span></a></li><li><a class="tocitem" href="#Training-a-policy"><span>Training a policy</span></a></li><li><a class="tocitem" href="#Saving-the-policy"><span>Saving the policy</span></a></li><li><a class="tocitem" href="#Simulating-the-policy"><span>Simulating the policy</span></a></li></ul></li><li><a class="tocitem" href="../02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="tocitem" href="../03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="tocitem" href="../04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="tocitem" href="../05_plotting/">Basic V: plotting</a></li><li><a class="tocitem" href="../06_warnings/">Basic VI: words of warning</a></li><li><a class="tocitem" href="../11_objective_states/">Advanced I: objective states</a></li><li><a class="tocitem" href="../12_belief_states/">Advanced II: belief states</a></li><li><a class="tocitem" href="../13_integrality/">Advanced III: integrality</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">How-to guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../guides/add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="tocitem" href="../../guides/add_a_risk_measure/">Add a risk measure</a></li><li><a class="tocitem" href="../../guides/add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="tocitem" href="../../guides/add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="tocitem" href="../../guides/choose_a_stopping_rule/">Choose a stopping rule</a></li><li><a class="tocitem" href="../../guides/create_a_general_policy_graph/">Create a general policy graph</a></li><li><a class="tocitem" href="../../guides/debug_a_model/">Debug a model</a></li><li><a class="tocitem" href="../../guides/improve_computational_performance/">Improve computational performance</a></li><li><a class="tocitem" href="../../guides/simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="tocitem" href="../../guides/upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/simple_hydro_thermal/">Hydro-thermal scheduling</a></li><li><a class="tocitem" href="../../examples/the_farmers_problem/">The farmer&#39;s problem</a></li></ul></li><li><a class="tocitem" href="../../apireference/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Basic I: first steps</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Basic I: first steps</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/tutorial/01_first_steps.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Basic-I:-first-steps"><a class="docs-heading-anchor" href="#Basic-I:-first-steps">Basic I: first steps</a><a id="Basic-I:-first-steps-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-I:-first-steps" title="Permalink"></a></h1><p>Hydrothermal scheduling is the most common application of stochastic dual dynamic programming. To illustrate some of the basic functionality of <code>SDDP.jl</code>, we implement a very simple model of the hydrothermal scheduling problem.</p><p>We consider the problem of scheduling electrical generation over three time periods in order to meet a known demand of 150 MWh in each period.</p><p>There are two generators: a thermal generator, and a hydro generator. The thermal generator has a short-run marginal cost of \$50/MWh in the first stage, \$100/MWh in the second stage, and \$150/MWh in the third stage. The hydro generator has a short-run marginal cost of \$0/MWh.</p><p>The hydro generator draws water from a reservoir which has a maximum capacity of 200 units. We assume that at the start of the first time period, the reservoir is full. In addition to the ability to generate electricity by passing water through the hydroelectric turbine, the hydro generator can also spill water down a spillway (bypassing the turbine) in order to prevent the water from over-topping the dam. We assume that there is no cost of spillage.</p><p>The objective of the optimization is to minimize the expected cost of generation over the three time periods.</p><h2 id="Mathematical-formulation"><a class="docs-heading-anchor" href="#Mathematical-formulation">Mathematical formulation</a><a id="Mathematical-formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-formulation" title="Permalink"></a></h2><p>Let&#39;s take the problem described above and form a mathematical model. In any multistage stochastic programming problem, we need to identify five key features:</p><ol><li>The <em>stages</em></li><li>The <em>state</em> variables</li><li>The <em>control</em> variables</li><li>The <em>dynamics</em></li><li>The <em>stage-objective</em></li></ol><h4 id="Stages"><a class="docs-heading-anchor" href="#Stages">Stages</a><a id="Stages-1"></a><a class="docs-heading-anchor-permalink" href="#Stages" title="Permalink"></a></h4><p>From the description, we have three stages: <code>t = 1, 2, 3</code>. Here is a picture of what this looks like:</p><p><img src="../../assets/deterministic_linear_policy_graph.png" alt="Linear policy graph"/></p><p>Notice that the boxes form a <em>linear graph</em>. This will be important when we get to the code. (We&#39;ll get to more complicated graphs in future tutorials.)</p><h4 id="State-variables"><a class="docs-heading-anchor" href="#State-variables">State variables</a><a id="State-variables-1"></a><a class="docs-heading-anchor-permalink" href="#State-variables" title="Permalink"></a></h4><p>State variables capture the information that flows between stages. These can be harder to identify. However, in our model, the state variable is the volume of water stored in the reservoir over time.</p><p>In the model below, we&#39;re going to call the state variable <code>volume</code>.</p><p>Each stage <code>t</code> is an interval in time. Thus, we need to record the value of the state variable in each stage at two points in time: at the beginning of the stage, which we  refer to as the <em>incoming</em> value of the state variable; and at the end of the  state, which we refer to as the <em>outgoing</em> state variable.</p><p>We&#39;re going to refer to the incoming value of <code>volume</code> by <code>volume.in</code> and the outgoing value by <code>volume.out</code>.</p><p>Note that <code>volume.out</code> when <code>t=1</code> is equal to <code>volume.in</code> when <code>t=2</code>.</p><p>The problem description also mentions some constraints on the volume of water in the reservoir. It cannot be negative, and the maximum level is 200 units. Thus, we have <code>0 &lt;= volume &lt;= 200</code>. Also, the description says that the initial value of water in the reservoir (i.e., <code>volume.in</code> when <code>t = 1</code>) is 200 units.</p><h4 id="Control-variables"><a class="docs-heading-anchor" href="#Control-variables">Control variables</a><a id="Control-variables-1"></a><a class="docs-heading-anchor-permalink" href="#Control-variables" title="Permalink"></a></h4><p>Control variables are the actions that the agent can take during a stage to change the value of the state variables. (Hence the name <em>control</em>.)</p><p>There are three control variables in our problem.</p><ol><li>The quantity of thermal generation, which we&#39;re going to call <code>thermal_generation</code>.</li><li>The quantity of hydro generation, which we&#39;re going to call <code>hydro_generation</code>.</li><li>The quatity of water to spill, which we&#39;re going to call <code>hydro_spill</code>.</li></ol><p>All of these variables are non-negative.</p><h4 id="The-dynamics"><a class="docs-heading-anchor" href="#The-dynamics">The dynamics</a><a id="The-dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#The-dynamics" title="Permalink"></a></h4><p>The dynamics of a problem describe how the state variables evolve through time in response to the controls chosen by the agent.</p><p>For our problem, the state variable is the volume of water in the reservoir. The volume of water decreases in response to water being used for hydro generation and spillage. So the dynamics for our problem are:</p><p><code>volume.out = volume.in - hydro_generation - hydro_spill</code></p><p>We can also put constraints on the values of the state and control variables. For example, in our problem, there is also a constraint that the total generation must meet the demand of 150 MWh in each stage. So, we have a constraint that: <code>hydro_generation + thermal_generation = 150</code>.</p><h4 id="The-stage-objective"><a class="docs-heading-anchor" href="#The-stage-objective">The stage-objective</a><a id="The-stage-objective-1"></a><a class="docs-heading-anchor-permalink" href="#The-stage-objective" title="Permalink"></a></h4><p>The agent&#39;s objective is to minimize the cost of generation. So in each stage, the agent wants to minimize the quantity of thermal generation multiplied by the short-run marginal cost of thermal generation.</p><p>In stage <code>t</code>, they want to minimize <code>fuel_cost[t] * thermal_generation</code>, where <code>fuel_cost[t]</code> is \$50 when <code>t=1</code>, \$100 when <code>t=2</code>, and \$150 when <code>t=3</code>.</p><p>We&#39;re now ready to construct a model. Since <code>SDDP.jl</code> is intended to be very user-friendly, we&#39;re going to give the full code first, and then walk through some of the details. However, you should be able to read through and understand most of what is happening.</p><h2 id="Creating-a-model"><a class="docs-heading-anchor" href="#Creating-a-model">Creating a model</a><a id="Creating-a-model-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-model" title="Permalink"></a></h2><pre><code class="language-julia">using SDDP, GLPK

model = SDDP.LinearPolicyGraph(
    stages = 3,
    sense = :Min,
    lower_bound = 0.0,
    optimizer = GLPK.Optimizer
) do subproblem, t
    # Define the state variable.
    @variable(subproblem, 0 &lt;= volume &lt;= 200, SDDP.State, initial_value = 200)
    # Define the control variables.
    @variables(subproblem, begin
        thermal_generation &gt;= 0
        hydro_generation   &gt;= 0
        hydro_spill        &gt;= 0
    end)
    # Define the constraints
    @constraints(subproblem, begin
        volume.out == volume.in - hydro_generation - hydro_spill
        thermal_generation + hydro_generation == 150.0
    end)
    # Define the objective for each stage `t`. Note that we can use `t` as an
    # index for t = 1, 2, 3.
    fuel_cost = [50.0, 100.0, 150.0]
    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)
end</code></pre><pre class="documenter-example-output">A policy graph with 3 nodes.
 Node indices: 1, 2, 3
</pre><p>Wasn&#39;t that easy! Let&#39;s walk through some of the non-obvious features.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For more information on <a href="../../apireference/#SDDP.LinearPolicyGraph"><code>SDDP.LinearPolicyGraph</code></a>s, read <a href="../../guides/create_a_general_policy_graph/#Create-a-general-policy-graph">Create a general policy graph</a>.</p></div></div><h4 id="What&#39;s-this-weird-do-syntax?"><a class="docs-heading-anchor" href="#What&#39;s-this-weird-do-syntax?">What&#39;s this weird <code>do</code> syntax?</a><a id="What&#39;s-this-weird-do-syntax?-1"></a><a class="docs-heading-anchor-permalink" href="#What&#39;s-this-weird-do-syntax?" title="Permalink"></a></h4><p>Julia&#39;s <code>do</code> syntax looks a little weird at first, but it&#39;s just a nice way of making a function that can be passed to another function. For example:</p><pre><code class="language-julia">function outer(inner::Function)
    inner(2)
end

outer() do x
    println(&quot;x^2 = &quot;, x^2)
end</code></pre><pre class="documenter-example-output">x^2 = 4</pre><p>is equivalent to</p><pre><code class="language-julia">inner(x) = println(&quot;x^2 = &quot;, x^2)
outer(inner)</code></pre><pre class="documenter-example-output">x^2 = 4</pre><p>So, in our case, we could have gone:</p><pre><code class="language-julia">function subproblem_builder(subproblem::JuMP.Model, t::Int)
    # Define the state variable.
    @variable(subproblem, 0 &lt;= volume &lt;= 200, SDDP.State, initial_value = 200)
    # Define the control variables.
    @variables(subproblem, begin
        thermal_generation &gt;= 0
        hydro_generation   &gt;= 0
        hydro_spill        &gt;= 0
    end)
    # Define the constraints
    @constraints(subproblem, begin
        volume.out == volume.in - hydro_generation - hydro_spill
        thermal_generation + hydro_generation == 150.0
    end)
    # Define the objective for each stage `t`. Note that we can use `t` as an
    # index for t = 1, 2, 3.
    fuel_cost = [50.0, 100.0, 150.0]
    @stageobjective(subproblem, fuel_cost[t] * thermal_generation)
end

model = SDDP.LinearPolicyGraph(
    subproblem_builder,
    stages = 3,
    sense = :Min,
    lower_bound = 0.0,
    optimizer = GLPK.Optimizer
)</code></pre><pre class="documenter-example-output">A policy graph with 3 nodes.
 Node indices: 1, 2, 3
</pre><h4 id="The-keywords-in-the-[SDDP.LinearPolicyGraph](@ref)-constructor"><a class="docs-heading-anchor" href="#The-keywords-in-the-[SDDP.LinearPolicyGraph](@ref)-constructor">The keywords in the <a href="../../apireference/#SDDP.LinearPolicyGraph"><code>SDDP.LinearPolicyGraph</code></a> constructor</a><a id="The-keywords-in-the-[SDDP.LinearPolicyGraph](@ref)-constructor-1"></a><a class="docs-heading-anchor-permalink" href="#The-keywords-in-the-[SDDP.LinearPolicyGraph](@ref)-constructor" title="Permalink"></a></h4><p>Hopefully <code>stages</code> and <code>sense</code> are obvious. However, the other two are not so clear.</p><p><code>lower_bound</code>: you <em>must</em> supply a valid bound on the objective. For our problem, we know that we cannot incur a negative cost so \$0 is a valid lower bound.</p><p><code>optimizer</code>: This is borrowed directly from JuMP&#39;s <code>Model</code> constructor: (<code>Model(GLPK.Optimizer)</code>)</p><h4 id="Creating-state-variables"><a class="docs-heading-anchor" href="#Creating-state-variables">Creating state variables</a><a id="Creating-state-variables-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-state-variables" title="Permalink"></a></h4><p>State variables can be created like any other JuMP variables. Think of them as another type of variable like binary or integer. For example, to create a binary variable in JuMP, you go:</p><pre><code class="language-julia">@variable(subproblem, x, Bin)</code></pre><p>whereas to create a state variable you go</p><pre><code class="language-julia">@variable(subproblem, x, SDDP.State)</code></pre><p>Also note that you have to pass a keyword argument called <code>initial_value</code> that gives the incoming value of the state variable in the first stage.</p><h4 id="Defining-the-stage-objective"><a class="docs-heading-anchor" href="#Defining-the-stage-objective">Defining the stage-objective</a><a id="Defining-the-stage-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-the-stage-objective" title="Permalink"></a></h4><p>In a JuMP model, we can set the objective using <code>@objective</code>. For example:</p><pre><code class="language-julia">@objective(subproblem, Min, fuel_cost[t] * thermal_generation)</code></pre><p>Since we only need to define the objective for each stage, rather than the whole problem, we use the <code>SDDP.jl</code>-provided <a href="../../apireference/#SDDP.@stageobjective"><code>@stageobjective</code></a>.</p><pre><code class="language-julia">@stageobjective(subproblem, fuel_cost[t] * thermal_generation)</code></pre><p>Note that we don&#39;t have to specify the optimization sense (<code>Max</code> of <code>Min</code>) since this is done via the <code>sense</code> keyword argument of <a href="../../apireference/#SDDP.LinearPolicyGraph"><code>SDDP.LinearPolicyGraph</code></a>.</p><h2 id="Training-a-policy"><a class="docs-heading-anchor" href="#Training-a-policy">Training a policy</a><a id="Training-a-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Training-a-policy" title="Permalink"></a></h2><p>Models can be trained using the <a href="../../apireference/#SDDP.train"><code>SDDP.train</code></a> function. It accepts a number of keyword arguments. <code>iteration_limit</code> terminates the training after the provided number of iterations.</p><pre><code class="language-julia">SDDP.train(model; iteration_limit = 3)</code></pre><pre class="documenter-example-output">--------------------------------------------------------------------------------
                      SDDP.jl (c) Oscar Dowson, 2017-20

Numerical stability report
  Non-zero Matrix range     [1e+00, 1e+00]
  Non-zero Objective range  [1e+00, 2e+02]
  Non-zero Bounds range     [2e+02, 2e+02]
  Non-zero RHS range        [2e+02, 2e+02]
No problems detected

Solver: serial mode

 Iteration    Simulation       Bound         Time (s)    Proc. ID   # Solves
        1    3.250000e+04   1.500000e+04   7.106709e-02          1          6
        2    1.750000e+04   1.750000e+04   7.145596e-02          1         12
        3    1.750000e+04   1.750000e+04   7.172203e-02          1         18

Terminating training with status: iteration_limit
------------------------------------------------------------------------------</pre><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For more information on the numerical stability report, read the <a href="../06_warnings/#Numerical-stability-report">Numerical stability report</a> section.</p></div></div><h2 id="Saving-the-policy"><a class="docs-heading-anchor" href="#Saving-the-policy">Saving the policy</a><a id="Saving-the-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-the-policy" title="Permalink"></a></h2><p>Once you have finished training the policy, you can write the cuts to file using <a href="../../apireference/#SDDP.write_cuts_to_file"><code>SDDP.write_cuts_to_file</code></a>. You can read these cuts into a new model using <a href="../../apireference/#SDDP.read_cuts_from_file"><code>SDDP.read_cuts_from_file</code></a>. Note that the model must have the same number (and names) of the state variables, as well as the same number and names of the nodes.</p><p>You can also save the log to a CSV file using <a href="../../apireference/#SDDP.write_log_to_csv"><code>SDDP.write_log_to_csv</code></a>. This will create a CSV file with columns <code>iteration</code>, <code>simulation</code>, <code>bound</code>, and <code>time</code>.</p><h2 id="Simulating-the-policy"><a class="docs-heading-anchor" href="#Simulating-the-policy">Simulating the policy</a><a id="Simulating-the-policy-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-the-policy" title="Permalink"></a></h2><p>Once you have a trained policy, you can simulate it using <a href="../../apireference/#SDDP.simulate"><code>SDDP.simulate</code></a>. The return value from <code>simulate</code> is a vector with one element for each replication. Each element is itself a vector, with one element for each stage. Each element, corresponding to a particular stage in a particular replication, is a dictionary that records information from the simulation.</p><pre><code class="language-julia">simulations = SDDP.simulate(
    # The trained model to simulate.
    model,
    # The number of replications.
    1,
    # A list of names to record the values of.
    [:volume, :thermal_generation, :hydro_generation, :hydro_spill]
)

replication = 1
stage = 2
simulations[replication][stage]</code></pre><pre class="documenter-example-output">Dict{Symbol,Any} with 10 entries:
  :volume             =&gt; State{Float64}(200.0, 150.0)
  :hydro_spill        =&gt; 0.0
  :bellman_term       =&gt; 0.0
  :noise_term         =&gt; nothing
  :node_index         =&gt; 2
  :stage_objective    =&gt; 10000.0
  :objective_state    =&gt; nothing
  :thermal_generation =&gt; 100.0
  :hydro_generation   =&gt; 50.0
  :belief             =&gt; Dict(2=&gt;1.0)</pre><p>Ignore many of the entries for now;  they will be relevant later.</p><p>One element of iterest is <code>:volume</code>.</p><pre><code class="language-julia">outgoing_volume = [stage[:volume].out for stage in simulations[1]]</code></pre><pre class="documenter-example-output">3-element Array{Float64,1}:
 200.0
 150.0
   0.0</pre><p>Another is <code>:thermal_generation</code>.</p><pre><code class="language-julia">thermal_generation = [stage[:thermal_generation] for stage in simulations[1]]</code></pre><pre class="documenter-example-output">3-element Array{Float64,1}:
 150.0
 100.0
   0.0</pre><p>From this, we can see the optimal policy: in the first stage, use 150 MWh of thermal generation and 0 MWh of hydro generation. In the second stage, use 100 MWh of thermal and 50 MWh of hydro. In the third and final stage, use 0 MWh of thermal and 150 MWh of  hydro.</p><p>This concludes our first very simple tutorial for <code>SDDP.jl</code>. In the next tutorial, <a href="../02_adding_uncertainty/#Basic-II:-adding-uncertainty">Basic II: adding uncertainty</a>, we will extend this problem by adding uncertainty.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../02_adding_uncertainty/">Basic II: adding uncertainty »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 16 December 2020 19:52">Wednesday 16 December 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
