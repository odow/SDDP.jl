<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Create a general policy graph · SDDP.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SDDP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SDDP.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorial/01_first_steps/">Basic I: first steps</a></li><li><a class="tocitem" href="../../tutorial/02_adding_uncertainty/">Basic II: adding uncertainty</a></li><li><a class="tocitem" href="../../tutorial/03_objective_uncertainty/">Basic III: objective uncertainty</a></li><li><a class="tocitem" href="../../tutorial/04_markov_uncertainty/">Basic IV: Markov uncertainty</a></li><li><a class="tocitem" href="../../tutorial/05_plotting/">Basic V: plotting</a></li><li><a class="tocitem" href="../../tutorial/06_warnings/">Basic VI: words of warning</a></li><li><a class="tocitem" href="../../tutorial/11_objective_states/">Advanced I: objective states</a></li><li><a class="tocitem" href="../../tutorial/12_belief_states/">Advanced II: belief states</a></li><li><a class="tocitem" href="../../tutorial/13_integrality/">Advanced III: integrality</a></li><li><a class="tocitem" href="../../tutorial/21_theory_intro/">Theory I: an intro to SDDP</a></li><li><a class="tocitem" href="../../tutorial/22_risk/">Theory II: risk aversion</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">How-to guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../add_a_multidimensional_state_variable/">Add a multi-dimensional state variable</a></li><li><a class="tocitem" href="../add_a_risk_measure/">Add a risk measure</a></li><li><a class="tocitem" href="../add_multidimensional_noise_Terms/">Add multi-dimensional noise terms</a></li><li><a class="tocitem" href="../add_noise_in_the_constraint_matrix/">Add noise in the constraint matrix</a></li><li><a class="tocitem" href="../choose_a_stopping_rule/">Choose a stopping rule</a></li><li class="is-active"><a class="tocitem" href>Create a general policy graph</a><ul class="internal"><li><a class="tocitem" href="#Creating-a-[SDDP.Graph](@ref)"><span>Creating a <code>SDDP.Graph</code></span></a></li><li><a class="tocitem" href="#Creating-a-policy-graph"><span>Creating a policy graph</span></a></li><li><a class="tocitem" href="#Simulating-non-standard-policy-graphs"><span>Simulating non-standard policy graphs</span></a></li><li><a class="tocitem" href="#Creating-a-Markovian-graph-automatically"><span>Creating a Markovian graph automatically</span></a></li></ul></li><li><a class="tocitem" href="../debug_a_model/">Debug a model</a></li><li><a class="tocitem" href="../improve_computational_performance/">Improve computational performance</a></li><li><a class="tocitem" href="../simulate_using_a_different_sampling_scheme/">Simulate using a different sampling scheme</a></li><li><a class="tocitem" href="../upgrade_from_the_old_sddp/">Upgrade from the old SDDP.jl</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/FAST_hydro_thermal/">FAST: the hydro-thermal problem</a></li><li><a class="tocitem" href="../../examples/FAST_production_management/">FAST: the production management problem</a></li><li><a class="tocitem" href="../../examples/FAST_quickstart/">FAST: the quickstart problem</a></li><li><a class="tocitem" href="../../examples/Hydro_thermal/">Hydro-thermal scheduling</a></li><li><a class="tocitem" href="../../examples/StochDynamicProgramming.jl_multistock/">StochDynamicProgramming: the multistock problem</a></li><li><a class="tocitem" href="../../examples/StochDynamicProgramming.jl_stock/">StochDynamicProgramming: the stock problem</a></li><li><a class="tocitem" href="../../examples/StructDualDynProg.jl_prob5.2_2stages/">StructDualDynProg: Problem 5.2, 2 stages</a></li><li><a class="tocitem" href="../../examples/StructDualDynProg.jl_prob5.2_3stages/">StructDualDynProg: Problem 5.2, 3 stages</a></li><li><a class="tocitem" href="../../examples/agriculture_mccardle_farm/">The farm planning problem</a></li><li><a class="tocitem" href="../../examples/air_conditioning/">Air conditioning</a></li><li><a class="tocitem" href="../../examples/all_blacks/">Deterministic All Blacks</a></li><li><a class="tocitem" href="../../examples/asset_management_simple/">Asset management</a></li><li><a class="tocitem" href="../../examples/asset_management_stagewise/">Asset management with modifications</a></li><li><a class="tocitem" href="../../examples/belief/">Partially observable inventory management</a></li><li><a class="tocitem" href="../../examples/biobjective_hydro/">Biobjective hydro-thermal</a></li><li><a class="tocitem" href="../../examples/booking_management/">Booking management</a></li><li><a class="tocitem" href="../../examples/generation_expansion/">Generation expansion</a></li><li><a class="tocitem" href="../../examples/hydro_valley/">Hydro valleys</a></li><li><a class="tocitem" href="../../examples/infinite_horizon_hydro_thermal/">Infinite horizon hydro-thermal</a></li><li><a class="tocitem" href="../../examples/infinite_horizon_trivial/">Infinite horizon trivial</a></li><li><a class="tocitem" href="../../examples/no_strong_duality/">No strong duality</a></li><li><a class="tocitem" href="../../examples/objective_state_newsvendor/">Newsvendor</a></li><li><a class="tocitem" href="../../examples/sldp_example_one/">SLDP: example 1</a></li><li><a class="tocitem" href="../../examples/sldp_example_two/">SLDP: example 2</a></li><li><a class="tocitem" href="../../examples/stochastic_all_blacks/">Stochastic All Blacks</a></li><li><a class="tocitem" href="../../examples/the_farmers_problem/">The farmer&#39;s problem</a></li><li><a class="tocitem" href="../../examples/vehicle_location/">Vehicle location</a></li></ul></li><li><a class="tocitem" href="../../apireference/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">How-to guides</a></li><li class="is-active"><a href>Create a general policy graph</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Create a general policy graph</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/odow/SDDP.jl/blob/master/docs/src/guides/create_a_general_policy_graph.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Create-a-general-policy-graph"><a class="docs-heading-anchor" href="#Create-a-general-policy-graph">Create a general policy graph</a><a id="Create-a-general-policy-graph-1"></a><a class="docs-heading-anchor-permalink" href="#Create-a-general-policy-graph" title="Permalink"></a></h1><p>SDDP.jl uses the concept of a <em>policy graph</em> to formulate multistage stochastic programming problems. We <em>highly</em> recommend that you read the following paper before continuing with this tutorial.</p><ul><li>Dowson, O. (2018). The policy graph decomposition of multistage stochastic optimization problems. Optimization Online. <a href="http://www.optimization-online.org/DB_HTML/2018/11/6914.html">link</a></li></ul><h2 id="Creating-a-[SDDP.Graph](@ref)"><a class="docs-heading-anchor" href="#Creating-a-[SDDP.Graph](@ref)">Creating a <a href="../../apireference/#SDDP.Graph"><code>SDDP.Graph</code></a></a><a id="Creating-a-[SDDP.Graph](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-[SDDP.Graph](@ref)" title="Permalink"></a></h2><h3 id="Linear-graphs"><a class="docs-heading-anchor" href="#Linear-graphs">Linear graphs</a><a id="Linear-graphs-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-graphs" title="Permalink"></a></h3><p>Linear policy graphs can be created using the <a href="../../apireference/#SDDP.LinearGraph"><code>SDDP.LinearGraph</code></a> function.</p><pre><code class="language-julia-repl">julia&gt; graph = SDDP.LinearGraph(3)
Root
 0
Nodes
 1
 2
 3
Arcs
 0 =&gt; 1 w.p. 1.0
 1 =&gt; 2 w.p. 1.0
 2 =&gt; 3 w.p. 1.0</code></pre><p>We can add nodes to a graph using <a href="../../apireference/#SDDP.add_node"><code>SDDP.add_node</code></a> and edges using <a href="../../apireference/#SDDP.add_edge"><code>SDDP.add_edge</code></a>.</p><pre><code class="language-julia-repl">julia&gt; SDDP.add_node(graph, 4)

julia&gt; SDDP.add_edge(graph, 3 =&gt; 4, 1.0)

julia&gt; SDDP.add_edge(graph, 4 =&gt; 1, 0.9)

julia&gt; graph
Root
 0
Nodes
 1
 2
 3
 4
Arcs
 0 =&gt; 1 w.p. 1.0
 1 =&gt; 2 w.p. 1.0
 2 =&gt; 3 w.p. 1.0
 3 =&gt; 4 w.p. 1.0
 4 =&gt; 1 w.p. 0.9</code></pre><p>Look! We just made a cyclic graph! SDDP.jl can solve infinite horizon problems. The probability on the arc that completes a cycle should be interpreted as a discount factor.</p><h3 id="Markovian-policy-graphs"><a class="docs-heading-anchor" href="#Markovian-policy-graphs">Markovian policy graphs</a><a id="Markovian-policy-graphs-1"></a><a class="docs-heading-anchor-permalink" href="#Markovian-policy-graphs" title="Permalink"></a></h3><p>Markovian policy graphs can be created using the <a href="../../apireference/#SDDP.MarkovianGraph"><code>SDDP.MarkovianGraph</code></a> function.</p><pre><code class="language-julia-repl">julia&gt; SDDP.MarkovianGraph(Matrix{Float64}[[1.0]&#39;, [0.4 0.6]])
Root
 (0, 1)
Nodes
 (1, 1)
 (2, 1)
 (2, 2)
Arcs
 (0, 1) =&gt; (1, 1) w.p. 1.0
 (1, 1) =&gt; (2, 1) w.p. 0.4
 (1, 1) =&gt; (2, 2) w.p. 0.6</code></pre><h3 id="General-graphs"><a class="docs-heading-anchor" href="#General-graphs">General graphs</a><a id="General-graphs-1"></a><a class="docs-heading-anchor-permalink" href="#General-graphs" title="Permalink"></a></h3><p>Arbitrarily complicated graphs can be constructed using <a href="../../apireference/#SDDP.Graph"><code>SDDP.Graph</code></a>, <a href="../../apireference/#SDDP.add_node"><code>SDDP.add_node</code></a> and <a href="../../apireference/#SDDP.add_edge"><code>SDDP.add_edge</code></a>. For example</p><pre><code class="language-julia-repl">julia&gt; graph = SDDP.Graph(:root_node)
Root
 root_node
Nodes
Arcs

julia&gt; SDDP.add_node(graph, :decision_node)

julia&gt; SDDP.add_edge(graph, :root_node =&gt; :decision_node, 1.0)

julia&gt; SDDP.add_edge(graph, :decision_node =&gt; :decision_node, 0.9)

julia&gt; graph
Root
 root_node
Nodes
 decision_node
Arcs
 root_node =&gt; decision_node w.p. 1.0
 decision_node =&gt; decision_node w.p. 0.9</code></pre><h2 id="Creating-a-policy-graph"><a class="docs-heading-anchor" href="#Creating-a-policy-graph">Creating a policy graph</a><a id="Creating-a-policy-graph-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-policy-graph" title="Permalink"></a></h2><p>Once you have constructed an instance of [<code>SDDP.Graph</code>], you can create a policy graph by passing the graph as the first argument.</p><pre><code class="language-julia-repl">julia&gt; graph = SDDP.Graph(
           :root_node,
           [:decision_node],
           [
               (:root_node =&gt; :decision_node, 1.0),
               (:decision_node =&gt; :decision_node, 0.9)
           ]);

julia&gt; model = SDDP.PolicyGraph(
               graph,
               lower_bound = 0,
               optimizer = GLPK.Optimizer) do subproblem, node
           println(&quot;Called from node: &quot;, node)
       end;
Called from node: decision_node</code></pre><h3 id="Special-cases"><a class="docs-heading-anchor" href="#Special-cases">Special cases</a><a id="Special-cases-1"></a><a class="docs-heading-anchor-permalink" href="#Special-cases" title="Permalink"></a></h3><p>There are two special cases which cover the majority of models in the literature.</p><ul><li><p><a href="../../apireference/#SDDP.LinearPolicyGraph"><code>SDDP.LinearPolicyGraph</code></a> is a special case where a <a href="../../apireference/#SDDP.LinearGraph"><code>SDDP.LinearGraph</code></a> is passed as the first argument.</p></li><li><p><a href="../../apireference/#SDDP.MarkovianPolicyGraph"><code>SDDP.MarkovianPolicyGraph</code></a> is a special case where a <a href="../../apireference/#SDDP.MarkovianGraph"><code>SDDP.MarkovianGraph</code></a> is passed as the first argument.</p></li></ul><p>Note that the type of the names of all nodes (including the root node) must be the same. In this case, they are <code>Symbol</code>s.</p><h2 id="Simulating-non-standard-policy-graphs"><a class="docs-heading-anchor" href="#Simulating-non-standard-policy-graphs">Simulating non-standard policy graphs</a><a id="Simulating-non-standard-policy-graphs-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-non-standard-policy-graphs" title="Permalink"></a></h2><p>If you simulate a policy graph with a node that has outgoing arcs that sum to less than one, you will end up with simulations of different lengths. (The most common case is an infinite horizon stochastic program, aka a linear policy graph with a single cycle.)</p><p>To simulate a fixed number of stages, use:</p><pre><code class="language-julia">simulations = SDDP.simulate(
    model,
    1,
    sampling_scheme = SDDP.InSampleMonteCarlo(
        max_depth = 10,
        terminate_on_dummy_leaf = false
    )
)</code></pre><p>Here, <code>max_depth</code> controls the number of stages, and <code>terminate_on_dummy_leaf = false</code> stops us from terminating early.</p><p>See also <a href="../simulate_using_a_different_sampling_scheme/#Simulate-using-a-different-sampling-scheme">Simulate using a different sampling scheme</a>.</p><h2 id="Creating-a-Markovian-graph-automatically"><a class="docs-heading-anchor" href="#Creating-a-Markovian-graph-automatically">Creating a Markovian graph automatically</a><a id="Creating-a-Markovian-graph-automatically-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-Markovian-graph-automatically" title="Permalink"></a></h2><p>SDDP.jl can create a Markovian graph by automatically discretizing a one-dimensional stochastic process and fitting a Markov chain.</p><p>To access this functionality, pass a function that takes no arguments and returns a <code>Vector{Float64}</code> to <a href="../../apireference/#SDDP.MarkovianGraph"><code>SDDP.MarkovianGraph</code></a>. To keyword arguments also need to be provided: <code>budget</code> is the total number of nodes in the Markovian graph, and <code>scenarios</code> is the number of realizations of the simulator function used to approximate the graph.</p><p>In some cases, <code>scenarios</code> may be too small to provide a reasonable fit of the stochastic process. If so, SDDP.jl will automatically try to re-fit the Markov chain using more scenarios.</p><pre><code class="language-julia">function simulator()
    scenario = zeros(5)
    for i = 2:5
        scenario[i] = scenario[i - 1] + rand() - 0.5
    end
    return scenario
end

model = SDDP.PolicyGraph(
    SDDP.MarkovianGraph(simulator; budget = 10, scenarios = 100),
    sense = :Max,
    upper_bound = 1e3
) do subproblem, node
    (stage, price) = node
    @variable(subproblem, x &gt;= 0, SDDP.State, initial_value = 1)
    @constraint(subproblem, x.out &lt;= x.in)
    @stageobjective(subproblem, price * x.out)
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../choose_a_stopping_rule/">« Choose a stopping rule</a><a class="docs-footer-nextpage" href="../debug_a_model/">Debug a model »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 26 March 2021 23:40">Friday 26 March 2021</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
